///////////////////////////////////////////////////////////////////////////////
// File generated by HDevelop for HALCON/C++ Version 21.05.0.0
// Non-ASCII strings in this file are encoded in local-8-bit encoding (cp936).
// Ensure that the interface encoding is set to locale encoding by calling
// SetHcppInterfaceStringEncodingIsUtf8(false) at the beginning of the program.
// 
// Please note that non-ASCII characters in string constants are exported
// as octal codes in order to guarantee that the strings are correctly
// created on all systems, independent on any compiler settings.
// 
// Source files with different encoding should not be mixed in one project.
///////////////////////////////////////////////////////////////////////////////



#ifndef __APPLE__
#  include "HalconCpp.h"
#  include "HDevThread.h"
#else
#  ifndef HC_LARGE_IMAGES
#    include <HALCONCpp/HalconCpp.h>
#    include <HALCONCpp/HDevThread.h>
#    include <HALCON/HpThread.h>
#  else
#    include <HALCONCppxl/HalconCpp.h>
#    include <HALCONCppxl/HDevThread.h>
#    include <HALCONxl/HpThread.h>
#  endif
#  include <stdio.h>
#  include <CoreFoundation/CFRunLoop.h>
#endif



using namespace HalconCpp;

// Procedure declarations 
// External procedures 
// Chapter: Deep Learning / Evaluation
void add_colormap_to_image (HObject ho_GrayValueImage, HObject ho_Image, HObject *ho_ColoredImage, 
    HTuple hv_HeatmapColorScheme);
// Chapter: Deep Learning / Evaluation
// Short Description: Create a lookup table and convert a grey scale image. 
void apply_colorscheme_on_gray_value_image (HObject ho_InputImage, HObject *ho_ResultImage, 
    HTuple hv_Schema);
// Chapter: Deep Learning / Model
// Short Description: Checks the content of the parameter dictionary DLPreprocessParam. 
void check_dl_preprocess_param (HTuple hv_DLPreprocessParam);
// Chapter: Tools / Geometry
// Short Description: Convert the parameters of rectangles with format rectangle2 to the coordinates of its 4 corner-points. 
void convert_rect2_5to8param (HTuple hv_Row, HTuple hv_Col, HTuple hv_Length1, HTuple hv_Length2, 
    HTuple hv_Phi, HTuple *hv_Row1, HTuple *hv_Col1, HTuple *hv_Row2, HTuple *hv_Col2, 
    HTuple *hv_Row3, HTuple *hv_Col3, HTuple *hv_Row4, HTuple *hv_Col4);
// Chapter: Tools / Geometry
// Short Description: Convert for four-sided figures the coordinates of the 4 corner-points to the parameters of format rectangle2. 
void convert_rect2_8to5param (HTuple hv_Row1, HTuple hv_Col1, HTuple hv_Row2, HTuple hv_Col2, 
    HTuple hv_Row3, HTuple hv_Col3, HTuple hv_Row4, HTuple hv_Col4, HTuple hv_ForceL1LargerL2, 
    HTuple *hv_Row, HTuple *hv_Col, HTuple *hv_Length1, HTuple *hv_Length2, HTuple *hv_Phi);
// Chapter: Graphics / Window
// Short Description: Close all window handles contained in a dictionary. 
void dev_close_window_dict (HTuple hv_WindowHandleDict);
// Chapter: Graphics / Output
// Short Description: Display a map of the confidences. 
void dev_display_confidence_regions (HObject ho_ImageConfidence, HTuple hv_DrawTransparency, 
    HTuple *hv_Colors);
// Chapter: Deep Learning / Model
// Short Description: Visualize different images, annotations and inference results for a sample. 
void dev_display_dl_data (HTuple hv_DLSample, HTuple hv_DLResult, HTuple hv_DLDatasetInfo, 
    HTuple hv_KeysForDisplay, HTuple hv_GenParam, HTuple hv_WindowHandleDict);
// Chapter: Deep Learning / Anomaly Detection
// Short Description: Display the ground truth anomaly regions of the given DLSample. 
void dev_display_ground_truth_anomaly_regions (HTuple hv_SampleKeys, HTuple hv_DLSample, 
    HTuple hv_CurrentWindowHandle, HTuple hv_LineWidth, HTuple hv_AnomalyRegionLabelColor, 
    HTuple hv_AnomalyColorTransparency, HTuple *hv_AnomalyRegionExists);
// Chapter: Graphics / Output
// Short Description: Display the ground truth bounding boxes of DLSample. 
void dev_display_ground_truth_detection (HTuple hv_DLSample, HTuple hv_SampleKeys, 
    HTuple hv_LineWidthBbox, HTuple hv_ClassIDs, HTuple hv_BboxColors, HTuple hv_BboxLabelColor, 
    HTuple hv_WindowImageRatio, HTuple hv_TextColor, HTuple hv_ShowLabels, HTuple hv_ShowDirection, 
    HTuple hv_WindowHandle, HTuple *hv_BboxIDs);
// Chapter: Graphics / Output
// Short Description: Display a color bar next to an image. 
void dev_display_map_color_bar (HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_MapColorBarWidth, 
    HTuple hv_Colors, HTuple hv_MaxValue, HTuple hv_WindowImageRatio, HTuple hv_WindowHandle);
// Chapter: Deep Learning / Anomaly Detection
// Short Description: Display the detected anomaly regions. 
void dev_display_result_anomaly_regions (HObject ho_AnomalyRegion, HTuple hv_CurrentWindowHandle, 
    HTuple hv_LineWidth, HTuple hv_AnomalyRegionResultColor);
// Chapter: Graphics / Output
// Short Description: Display result bounding boxes. 
void dev_display_result_detection (HTuple hv_DLResult, HTuple hv_ResultKeys, HTuple hv_LineWidthBbox, 
    HTuple hv_ClassIDs, HTuple hv_TextConf, HTuple hv_Colors, HTuple hv_BoxLabelColor, 
    HTuple hv_WindowImageRatio, HTuple hv_TextPositionRow, HTuple hv_TextColor, HTuple hv_ShowLabels, 
    HTuple hv_ShowDirection, HTuple hv_WindowHandle, HTuple *hv_BboxClassIndices);
// Chapter: Graphics / Output
// Short Description: Display the ground truth/result segmentation as regions. 
void dev_display_segmentation_regions (HObject ho_SegmentationImage, HTuple hv_ClassIDs, 
    HTuple hv_ColorsSegmentation, HTuple hv_ExcludeClassIDs, HTuple *hv_ImageClassIDs);
// Chapter: Graphics / Output
// Short Description: Display a map of weights. 
void dev_display_weight_regions (HObject ho_ImageWeight, HTuple hv_DrawTransparency, 
    HTuple hv_SegMaxWeight, HTuple *hv_Colors);
// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle);
// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'off'. 
void dev_update_off ();
// Chapter: XLD / Creation
// Short Description: Creates an arrow shaped XLD contour. 
void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth);
// Chapter: Deep Learning / Model
// Short Description: The procedure returns DLSample dicts for given sample indices of a DLDataset. 
void gen_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_RestrictKeysDLSample, 
    HTuple hv_GenParam, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples. 
void gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch);
// Chapter: Deep Learning / Anomaly Detection
// Short Description: Get the ground truth anomaly label and label ID. 
void get_anomaly_ground_truth_label (HTuple hv_SampleKeys, HTuple hv_DLSample, HTuple *hv_AnomalyLabelGroundTruth, 
    HTuple *hv_AnomalyLabelIDGroundTruth);
// Chapter: Deep Learning / Anomaly Detection
// Short Description: Get the anomaly results out of DLResult and apply thresholds (if specified). 
void get_anomaly_result (HObject *ho_AnomalyImage, HObject *ho_AnomalyRegion, HTuple hv_DLResult, 
    HTuple hv_ResultKeys, HTuple hv_AnomalyClassThreshold, HTuple hv_AnomalyRegionThreshold, 
    HTuple *hv_AnomalyScore, HTuple *hv_AnomalyClassID, HTuple *hv_AnomalyClassThresholdDisplay, 
    HTuple *hv_AnomalyRegionThresholdDisplay);
// Chapter: Graphics / Window
// Short Description: Get the next child window that can be used for visualization. 
void get_child_window (HTuple hv_HeightImage, HTuple hv_Font, HTuple hv_FontSize, 
    HTuple hv_Text, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_WindowImageRatio, HTuple *hv_PrevWindowCoordinatesOut);
// Chapter: Deep Learning / Classification
// Short Description: Get the ground truth classification label id. 
void get_classification_ground_truth (HTuple hv_SampleKeys, HTuple hv_DLSample, HTuple *hv_ClassificationLabelIDGroundTruth);
// Chapter: Deep Learning / Classification
// Short Description: Get the predicted classification class ID. 
void get_classification_result (HTuple hv_ResultKeys, HTuple hv_DLResult, HTuple *hv_ClassificationClassID);
// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the confidences of the segmentation result. 
void get_confidence_image (HObject *ho_ImageConfidence, HTuple hv_ResultKeys, HTuple hv_DLResult);
// Chapter: Deep Learning / Model
// Short Description: Generate NumColors distinct colors 
void get_distinct_colors_dl_visualization (HTuple hv_NumColors, HTuple hv_Random, 
    HTuple hv_StartColor, HTuple hv_EndColor, HTuple *hv_Colors);
// Chapter: Deep Learning / Model
// Short Description: Generates certain colors for different ClassNames 
void get_dl_class_colors (HTuple hv_ClassNames, HTuple *hv_Colors);
// Chapter: Deep Learning / Model
// Short Description: Get the image of a sample. 
void get_image (HObject *ho_Image, HTuple hv_SampleKeys, HTuple hv_DLSample);
// Chapter: Graphics / Window
// Short Description: Get the next window that can be used for visualization. 
void get_next_window (HTuple hv_Font, HTuple hv_FontSize, HTuple hv_ShowBottomDesc, 
    HTuple hv_WidthImage, HTuple hv_HeightImage, HTuple hv_MapColorBarWidth, HTuple hv_ScaleWindows, 
    HTuple hv_ThresholdWidth, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_CurrentWindowHandle, HTuple *hv_WindowImageRatioHeight, 
    HTuple *hv_PrevWindowCoordinatesOut);
// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the ground truth segmentation image. 
void get_segmentation_image_ground_truth (HObject *ho_SegmentationImagGroundTruth, 
    HTuple hv_SampleKeys, HTuple hv_DLSample);
// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the predicted segmentation result image. 
void get_segmentation_image_result (HObject *ho_SegmentationImageResult, HTuple hv_ResultKeys, 
    HTuple hv_DLResult);
// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the weight image of a sample. 
void get_weight_image (HObject *ho_ImageWeight, HTuple hv_SampleKeys, HTuple hv_DLSample);
// Chapter: Deep Learning / Model
// Short Description: shuffles the input colors in a deterministic way 
void make_neighboring_colors_distinguishable_dl_visualization (HTuple hv_ColorsRainbow, 
    HTuple *hv_Colors);
// Chapter: Graphics / Window
// Short Description: Open a window next to the given WindowHandleFather.  
void open_child_window (HTuple hv_WindowHandleFather, HTuple hv_Font, HTuple hv_FontSize, 
    HTuple hv_Text, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_WindowHandleChild, HTuple *hv_PrevWindowCoordinatesOut);
// Chapter: Graphics / Window
// Short Description: Open a new window, either next to the last ones, or in a new row. 
void open_next_window (HTuple hv_Font, HTuple hv_FontSize, HTuple hv_ShowBottomDesc, 
    HTuple hv_WidthImage, HTuple hv_HeightImage, HTuple hv_MapColorBarWidth, HTuple hv_ScaleWindows, 
    HTuple hv_ThresholdWidth, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_WindowHandleNew, HTuple *hv_WindowImageRatioHeight, 
    HTuple *hv_PrevWindowCoordinatesOut);
// Chapter: Deep Learning / Model
// Short Description: Preprocess anomaly images for evaluation and visualization of the deep-learning-based anomaly detection. 
void preprocess_dl_model_anomaly (HObject ho_AnomalyImages, HObject *ho_AnomalyImagesPreprocessed, 
    HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Object Detection
// Short Description: This procedure preprocesses the bounding boxes of type 'rectangle1' for a given sample. 
void preprocess_dl_model_bbox_rect1 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Object Detection
// Short Description: This procedure preprocesses the bounding boxes of type 'rectangle2' for a given sample. 
void preprocess_dl_model_bbox_rect2 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Preprocess images for deep-learning-based training and inference. 
void preprocess_dl_model_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Preprocess segmentation and weight images for deep-learning-based segmentation training and inference. 
void preprocess_dl_model_segmentations (HObject ho_ImagesRaw, HObject ho_Segmentations, 
    HObject *ho_SegmentationsPreprocessed, HTuple hv_DLPreprocessParam);
// Chapter: Deep Learning / Model
// Short Description: Preprocess given DLSamples according to the preprocessing parameters given in DLPreprocessParam. 
void preprocess_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_DLPreprocessParam);
// Chapter: Image / Manipulation
// Short Description: Changes a value of ValuesToChange in Image to NewValue. 
void reassign_pixel_values (HObject ho_Image, HObject *ho_ImageOut, HTuple hv_ValuesToChange, 
    HTuple hv_NewValue);
// Chapter: Deep Learning / Model
// Short Description: This procedure replaces legacy preprocessing parameters. 
void replace_legacy_preprocessing_parameters (HTuple hv_DLPreprocessParam);
// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255] 
void scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min, 
    HTuple hv_Max);
// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold, 
    HTuple hv_Slant);
// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled);
// Chapter: Graphics / Window
// Short Description: This procedure sets and returns meta information to display images correctly. 
void update_window_meta_information (HTuple hv_WindowHandle, HTuple hv_WidthImage, 
    HTuple hv_HeightImage, HTuple hv_WindowRow1, HTuple hv_WindowColumn1, HTuple hv_MapColorBarWidth, 
    HTuple hv_MarginBottom, HTuple *hv_WindowImageRatioHeight, HTuple *hv_WindowImageRatioWidth, 
    HTuple *hv_SetPartRow2, HTuple *hv_SetPartColumn2, HTuple *hv_PrevWindowCoordinatesOut);
// Local procedures 
void check_data_availability (HTuple hv_ExampleDataDir, HTuple hv_PreprocessParamFileName, 
    HTuple hv_TrainedModelFileName, HTuple hv_UsePretrainedModel);
void create_counting_result_text (HTuple hv_NumberDetectionsPerClass, HTuple hv_ClassNames, 
    HTuple *hv_Text, HTuple *hv_TextColor, HTuple *hv_TextBoxColor);
void create_tiny_example_dataset_with_result (HTuple *hv_DLDataset, HTuple *hv_DLResult);
void dev_close_example_image_window (HTuple hv_ExampleInternals);
void dev_close_example_legend_window (HTuple hv_ExampleInternals);
void dev_close_example_text_window (HTuple hv_ExampleInternals);
void dev_close_example_windows (HTuple hv_ExampleInternals);
void dev_display_example_reset_windows (HTuple hv_ExampleInternals);
void dev_display_screen_device (HTuple hv_ExampleInternals, HTuple hv_DLDevice);
void dev_display_screen_example_images (HTuple hv_ExampleInternals);
void dev_display_screen_final (HTuple hv_ExampleInternals);
void dev_display_screen_inference_step_1 (HTuple hv_ExampleInternals);
void dev_display_screen_inference_step_2_part_1 (HTuple hv_ExampleInternals);
void dev_display_screen_inference_step_2_part_2 (HTuple hv_ExampleInternals);
void dev_display_screen_inference_step_3 (HTuple hv_ExampleInternals);
void dev_display_screen_introduction (HTuple hv_ExampleInternals);
void dev_display_screen_max_overlap (HTuple hv_ExampleInternals);
void dev_display_screen_max_overlap_class_agnostic (HTuple hv_ExampleInternals);
void dev_display_screen_min_confidence (HTuple hv_ExampleInternals);
void dev_display_screen_run_program (HTuple hv_ExampleInternals);
void dev_example_init (HTuple hv_ShowExampleScreens, HTuple hv_UsePretrainedModel, 
    HTuple *hv_ExampleInternals);
void dev_open_example_image_window (HTuple hv_ExampleInternals);
void dev_open_example_legend_window (HTuple hv_ExampleInternals, HTuple hv_WindowWidth);
void dev_open_example_text_window (HTuple hv_ExampleInternals);
void display_result_box (HObject ho_Box, HTuple hv_LineWidth, HTuple hv_Colors, HTuple hv_Text);
// Short Description: Generates NumColors distinct colors 
void get_distinct_colors (HTuple hv_NumColors, HTuple hv_Random, HTuple hv_StartColor, 
    HTuple hv_EndColor, HTuple *hv_Colors);
void get_example_inference_images (HTuple hv_ImageDir, HTuple *hv_ImageFiles);
// Short Description: shuffles the input colors in a deterministic way 
void make_neighboring_colors_distinguishable (HTuple hv_ColorsRainbow, HTuple *hv_Colors);

// Procedures 
// External procedures 
// Chapter: Deep Learning / Evaluation
void add_colormap_to_image (HObject ho_GrayValueImage, HObject ho_Image, HObject *ho_ColoredImage, 
    HTuple hv_HeatmapColorScheme)
{

  // Local iconic variables
  HObject  ho_RGBValueImage, ho_Channels, ho_ChannelsScaled;
  HObject  ho_Channel, ho_ChannelScaled, ho_ChannelScaledByte;
  HObject  ho_ImageByte, ho_ImageByteR, ho_ImageByteG, ho_ImageByteB;

  // Local control variables
  HTuple  hv_Type, hv_NumChannels, hv_ChannelIndex;
  HTuple  hv_ChannelMin, hv_ChannelMax, hv__;

  //
  //This procedure adds a gray-value image to a RGB image with a chosen colormap.
  //
  GetImageType(ho_GrayValueImage, &hv_Type);
  //The image LUT needs a byte image. Rescale real images.
  if (0 != (int(hv_Type==HTuple("real"))))
  {
    scale_image_range(ho_GrayValueImage, &ho_GrayValueImage, 0, 1);
    ConvertImageType(ho_GrayValueImage, &ho_GrayValueImage, "byte");
  }
  else if (0 != (int(hv_Type!=HTuple("byte"))))
  {
    throw HException(HTuple("For this transformation, a byte or real image is needed!"));
  }
  //
  //Apply the chosen color scheme on the gray value.
  apply_colorscheme_on_gray_value_image(ho_GrayValueImage, &ho_RGBValueImage, hv_HeatmapColorScheme);
  //
  //Convert input image to byte image for visualization.
  ImageToChannels(ho_Image, &ho_Channels);
  CountChannels(ho_Image, &hv_NumChannels);
  GenEmptyObj(&ho_ChannelsScaled);
  {
  HTuple end_val19 = hv_NumChannels;
  HTuple step_val19 = 1;
  for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val19, step_val19); hv_ChannelIndex += step_val19)
  {
    SelectObj(ho_Channels, &ho_Channel, hv_ChannelIndex);
    MinMaxGray(ho_Channel, ho_Channel, 0, &hv_ChannelMin, &hv_ChannelMax, &hv__);
    scale_image_range(ho_Channel, &ho_ChannelScaled, hv_ChannelMin, hv_ChannelMax);
    ConvertImageType(ho_ChannelScaled, &ho_ChannelScaledByte, "byte");
    ConcatObj(ho_ChannelsScaled, ho_ChannelScaledByte, &ho_ChannelsScaled);
  }
  }
  ChannelsToImage(ho_ChannelsScaled, &ho_ImageByte);
  //
  //Note that ImageByte needs to have the same number of channels as
  //RGBValueImage to display colormap image correctly.
  CountChannels(ho_ImageByte, &hv_NumChannels);
  if (0 != (int(hv_NumChannels!=3)))
  {
    //Just take the first channel and use this to generate
    //an image with 3 channels for visualization.
    AccessChannel(ho_ImageByte, &ho_ImageByteR, 1);
    CopyImage(ho_ImageByteR, &ho_ImageByteG);
    CopyImage(ho_ImageByteR, &ho_ImageByteB);
    Compose3(ho_ImageByteR, ho_ImageByteG, ho_ImageByteB, &ho_ImageByte);
  }
  //
  AddImage(ho_ImageByte, ho_RGBValueImage, &ho_RGBValueImage, 0.5, 0);
  (*ho_ColoredImage) = ho_RGBValueImage;
  //
  return;
}

// Chapter: Deep Learning / Evaluation
// Short Description: Create a lookup table and convert a grey scale image. 
void apply_colorscheme_on_gray_value_image (HObject ho_InputImage, HObject *ho_ResultImage, 
    HTuple hv_Schema)
{

  // Local iconic variables
  HObject  ho_ImageR, ho_ImageG, ho_ImageB;

  // Local control variables
  HTuple  hv_X, hv_Low, hv_High, hv_OffR, hv_OffG;
  HTuple  hv_OffB, hv_A1, hv_A0, hv_R, hv_G, hv_B, hv_A0R;
  HTuple  hv_A0G, hv_A0B;

  //
  //This procedure generates an RGB ResultImage for a grey-value InputImage.
  //In order to do so, create a color distribution as look up table
  //according to the Schema.
  //
  hv_X = HTuple::TupleGenSequence(0,255,1);
  TupleGenConst(256, 0, &hv_Low);
  TupleGenConst(256, 255, &hv_High);
  //
  if (0 != (int(hv_Schema==HTuple("jet"))))
  {
    //Scheme Jet: from blue to red
    hv_OffR = 3.0*64.0;
    hv_OffG = 2.0*64.0;
    hv_OffB = 64.0;
    hv_A1 = -4.0;
    hv_A0 = 255.0+128.0;
    hv_R = (((((hv_X-hv_OffR).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_G = (((((hv_X-hv_OffG).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_B = (((((hv_X-hv_OffB).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
    //
  }
  else if (0 != (int(hv_Schema==HTuple("inverse_jet"))))
  {
    //Scheme InvJet: from red to blue.
    hv_OffR = 64;
    hv_OffG = 2*64;
    hv_OffB = 3*64;
    hv_A1 = -4.0;
    hv_A0 = 255.0+128.0;
    hv_R = (((((hv_X-hv_OffR).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_G = (((((hv_X-hv_OffG).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_B = (((((hv_X-hv_OffB).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
    //
  }
  else if (0 != (int(hv_Schema==HTuple("hot"))))
  {
    //Scheme Hot.
    hv_A1 = 3.0;
    hv_A0R = 0.0;
    hv_A0G = ((1.0/3.0)*hv_A1)*255.0;
    hv_A0B = ((2.0/3.0)*hv_A1)*255.0;
    hv_R = (((hv_X*hv_A1)-hv_A0R).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_G = (((hv_X*hv_A1)-hv_A0G).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_B = (((hv_X*hv_A1)-hv_A0B).TupleMax2(hv_Low)).TupleMin2(hv_High);
    //
  }
  else if (0 != (int(hv_Schema==HTuple("inverse_hot"))))
  {
    //Scheme Inverse Hot.
    hv_A1 = -3.0;
    hv_A0R = hv_A1*255.0;
    hv_A0G = ((2.0/3.0)*hv_A1)*255.0;
    hv_A0B = ((1.0/3.0)*hv_A1)*255.0;
    hv_R = (((hv_X*hv_A1)-hv_A0R).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_G = (((hv_X*hv_A1)-hv_A0G).TupleMax2(hv_Low)).TupleMin2(hv_High);
    hv_B = (((hv_X*hv_A1)-hv_A0B).TupleMax2(hv_Low)).TupleMin2(hv_High);
    //
  }
  else
  {
    //
    throw HException(("Unknown color schema: "+hv_Schema)+".");
    //
  }
  //
  LutTrans(ho_InputImage, &ho_ImageR, hv_R);
  LutTrans(ho_InputImage, &ho_ImageG, hv_G);
  LutTrans(ho_InputImage, &ho_ImageB, hv_B);
  Compose3(ho_ImageR, ho_ImageG, ho_ImageB, &(*ho_ResultImage));
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Checks the content of the parameter dictionary DLPreprocessParam. 
void check_dl_preprocess_param (HTuple hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_CheckParams, hv_KeyExists, hv_DLModelType;
  HTuple  hv_Exception, hv_SupportedModelTypes, hv_Index;
  HTuple  hv_ParamNamesGeneral, hv_ParamNamesSegmentation;
  HTuple  hv_ParamNamesDetectionOptional, hv_ParamNamesPreprocessingOptional;
  HTuple  hv_ParamNamesAll, hv_ParamNames, hv_KeysExists;
  HTuple  hv_I, hv_Exists, hv_InputKeys, hv_Key, hv_Value;
  HTuple  hv_Indices, hv_ValidValues, hv_ValidTypes, hv_V;
  HTuple  hv_T, hv_IsInt, hv_ValidTypesListing, hv_ValidValueListing;
  HTuple  hv_EmptyStrings, hv_ImageRangeMinExists, hv_ImageRangeMaxExists;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_IndexParam;
  HTuple  hv_SetBackgroundID, hv_ClassIDsBackground, hv_Intersection;
  HTuple  hv_IgnoreClassIDs, hv_KnownClasses, hv_IgnoreClassID;
  HTuple  hv_OptionalKeysExist, hv_InstanceType, hv_IgnoreDirection;
  HTuple  hv_ClassIDsNoOrientation, hv_SemTypes;

  //
  //This procedure checks a dictionary with parameters for DL preprocessing.
  //
  hv_CheckParams = 1;
  //If check_params is set to false, do not check anything.
  GetDictParam(hv_DLPreprocessParam, "key_exists", "check_params", &hv_KeyExists);
  if (0 != hv_KeyExists)
  {
    GetDictTuple(hv_DLPreprocessParam, "check_params", &hv_CheckParams);
    if (0 != (hv_CheckParams.TupleNot()))
    {
      return;
    }
  }
  //
  try
  {
    GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_DLModelType);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    throw HException(HTuple(HTuple("DLPreprocessParam needs the parameter: '")+"model_type")+"'");
  }
  //
  //Check for correct model type.
  hv_SupportedModelTypes.Clear();
  hv_SupportedModelTypes[0] = "anomaly_detection";
  hv_SupportedModelTypes[1] = "classification";
  hv_SupportedModelTypes[2] = "detection";
  hv_SupportedModelTypes[3] = "segmentation";
  TupleFind(hv_SupportedModelTypes, hv_DLModelType, &hv_Index);
  if (0 != (HTuple(int(hv_Index==-1)).TupleOr(int(hv_Index==HTuple()))))
  {
    throw HException(HTuple("Only models of type 'anomaly_detection', 'classification', 'detection', or 'segmentation' are supported"));
    return;
  }
  //
  //Parameter names that are required.
  //General parameters.
  hv_ParamNamesGeneral.Clear();
  hv_ParamNamesGeneral[0] = "model_type";
  hv_ParamNamesGeneral[1] = "image_width";
  hv_ParamNamesGeneral[2] = "image_height";
  hv_ParamNamesGeneral[3] = "image_num_channels";
  hv_ParamNamesGeneral[4] = "image_range_min";
  hv_ParamNamesGeneral[5] = "image_range_max";
  hv_ParamNamesGeneral[6] = "normalization_type";
  hv_ParamNamesGeneral[7] = "domain_handling";
  //Segmentation specific parameters.
  hv_ParamNamesSegmentation.Clear();
  hv_ParamNamesSegmentation[0] = "ignore_class_ids";
  hv_ParamNamesSegmentation[1] = "set_background_id";
  hv_ParamNamesSegmentation[2] = "class_ids_background";
  //Detection specific parameters.
  hv_ParamNamesDetectionOptional.Clear();
  hv_ParamNamesDetectionOptional[0] = "instance_type";
  hv_ParamNamesDetectionOptional[1] = "ignore_direction";
  hv_ParamNamesDetectionOptional[2] = "class_ids_no_orientation";
  //Normalization specific parameters.
  hv_ParamNamesPreprocessingOptional.Clear();
  hv_ParamNamesPreprocessingOptional[0] = "mean_values_normalization";
  hv_ParamNamesPreprocessingOptional[1] = "deviation_values_normalization";
  //All parameters
  hv_ParamNamesAll.Clear();
  hv_ParamNamesAll.Append(hv_ParamNamesGeneral);
  hv_ParamNamesAll.Append(hv_ParamNamesSegmentation);
  hv_ParamNamesAll.Append(hv_ParamNamesDetectionOptional);
  hv_ParamNamesAll.Append(hv_ParamNamesPreprocessingOptional);
  hv_ParamNames = hv_ParamNamesGeneral;
  if (0 != (int(hv_DLModelType==HTuple("segmentation"))))
  {
    //Extend ParamNames for models of type segmentation.
    hv_ParamNames = hv_ParamNames.TupleConcat(hv_ParamNamesSegmentation);
  }
  //
  //Check if legacy parameter exist.
  //Otherwise map it to the legal parameter.
  replace_legacy_preprocessing_parameters(hv_DLPreprocessParam);
  //
  //Check that all necessary parameters are included.
  //
  GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNames, &hv_KeysExists);
  if (0 != (int(((hv_KeysExists.TupleEqualElem(0)).TupleSum())>0)))
  {
    {
    HTuple end_val52 = hv_KeysExists.TupleLength();
    HTuple step_val52 = 1;
    for (hv_I=0; hv_I.Continue(end_val52, step_val52); hv_I += step_val52)
    {
      hv_Exists = HTuple(hv_KeysExists[hv_I]);
      if (0 != (hv_Exists.TupleNot()))
      {
        throw HException(("DLPreprocessParam needs the parameter: '"+HTuple(hv_ParamNames[hv_I]))+"'");
      }
    }
    }
  }
  //
  //Check the keys provided.
  GetDictParam(hv_DLPreprocessParam, "keys", HTuple(), &hv_InputKeys);
  {
  HTuple end_val62 = (hv_InputKeys.TupleLength())-1;
  HTuple step_val62 = 1;
  for (hv_I=0; hv_I.Continue(end_val62, step_val62); hv_I += step_val62)
  {
    hv_Key = HTuple(hv_InputKeys[hv_I]);
    GetDictTuple(hv_DLPreprocessParam, hv_Key, &hv_Value);
    //Check that the key is known.
    TupleFind(hv_ParamNamesAll, hv_Key, &hv_Indices);
    if (0 != (int(hv_Indices==-1)))
    {
      throw HException(("Unknown key for DLPreprocessParam: '"+HTuple(hv_InputKeys[hv_I]))+"'");
      return;
    }
    //Set expected values and types.
    hv_ValidValues = HTuple();
    hv_ValidTypes = HTuple();
    if (0 != (int(hv_Key==HTuple("normalization_type"))))
    {
      hv_ValidValues.Clear();
      hv_ValidValues[0] = "all_channels";
      hv_ValidValues[1] = "first_channel";
      hv_ValidValues[2] = "constant_values";
      hv_ValidValues[3] = "none";
    }
    else if (0 != (int(hv_Key==HTuple("domain_handling"))))
    {
      if (0 != (int(hv_DLModelType==HTuple("anomaly_detection"))))
      {
        hv_ValidValues.Clear();
        hv_ValidValues[0] = "full_domain";
        hv_ValidValues[1] = "crop_domain";
        hv_ValidValues[2] = "keep_domain";
      }
      else
      {
        hv_ValidValues.Clear();
        hv_ValidValues[0] = "full_domain";
        hv_ValidValues[1] = "crop_domain";
      }
    }
    else if (0 != (int(hv_Key==HTuple("model_type"))))
    {
      hv_ValidValues.Clear();
      hv_ValidValues[0] = "anomaly_detection";
      hv_ValidValues[1] = "classification";
      hv_ValidValues[2] = "detection";
      hv_ValidValues[3] = "segmentation";
    }
    else if (0 != (int(hv_Key==HTuple("set_background_id"))))
    {
      hv_ValidTypes = "int";
    }
    else if (0 != (int(hv_Key==HTuple("class_ids_background"))))
    {
      hv_ValidTypes = "int";
    }
    //Check that type is valid.
    if (0 != (int((hv_ValidTypes.TupleLength())>0)))
    {
      {
      HTuple end_val91 = (hv_ValidTypes.TupleLength())-1;
      HTuple step_val91 = 1;
      for (hv_V=0; hv_V.Continue(end_val91, step_val91); hv_V += step_val91)
      {
        hv_T = HTuple(hv_ValidTypes[hv_V]);
        if (0 != (int(hv_T==HTuple("int"))))
        {
          TupleIsInt(hv_Value, &hv_IsInt);
          if (0 != (hv_IsInt.TupleNot()))
          {
            hv_ValidTypes = ("'"+hv_ValidTypes)+"'";
            if (0 != (int((hv_ValidTypes.TupleLength())<2)))
            {
              hv_ValidTypesListing = hv_ValidTypes;
            }
            else
            {
              hv_ValidTypesListing = (((hv_ValidTypes.TupleSelectRange(0,HTuple(0).TupleMax2((hv_ValidTypes.TupleLength())-2)))+HTuple(", "))+HTuple(hv_ValidTypes[(hv_ValidTypes.TupleLength())-1])).TupleSum();
            }
            throw HException(((((("The value given in the key '"+hv_Key)+"' of DLPreprocessParam is invalid. Valid types are: ")+hv_ValidTypesListing)+". The given value was '")+hv_Value)+"'.");
            return;
          }
        }
        else
        {
          throw HException("Internal error. Unknown valid type.");
        }
      }
      }
    }
    //Check that value is valid.
    if (0 != (int((hv_ValidValues.TupleLength())>0)))
    {
      TupleFindFirst(hv_ValidValues, hv_Value, &hv_Index);
      if (0 != (int(hv_Index==-1)))
      {
        hv_ValidValues = ("'"+hv_ValidValues)+"'";
        if (0 != (int((hv_ValidValues.TupleLength())<2)))
        {
          hv_ValidValueListing = hv_ValidValues;
        }
        else
        {
          hv_EmptyStrings = HTuple((hv_ValidValues.TupleLength())-2,"");
          hv_ValidValueListing = (((hv_ValidValues.TupleSelectRange(0,HTuple(0).TupleMax2((hv_ValidValues.TupleLength())-2)))+HTuple(", "))+(hv_EmptyStrings.TupleConcat(HTuple(hv_ValidValues[(hv_ValidValues.TupleLength())-1])))).TupleSum();
        }
        throw HException(((((("The value given in the key '"+hv_Key)+"' of DLPreprocessParam is invalid. Valid values are: ")+hv_ValidValueListing)+". The given value was '")+hv_Value)+"'.");
      }
    }
  }
  }
  //
  //Check the correct setting of ImageRangeMin and ImageRangeMax.
  if (0 != (HTuple(int(hv_DLModelType==HTuple("classification"))).TupleOr(int(hv_DLModelType==HTuple("detection")))))
  {
    //Check ImageRangeMin and ImageRangeMax.
    GetDictParam(hv_DLPreprocessParam, "key_exists", "image_range_min", &hv_ImageRangeMinExists);
    GetDictParam(hv_DLPreprocessParam, "key_exists", "image_range_max", &hv_ImageRangeMaxExists);
    //If they are present, check that they are set correctly.
    if (0 != hv_ImageRangeMinExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
      if (0 != (int(hv_ImageRangeMin!=-127)))
      {
        throw HException(("For model type "+hv_DLModelType)+" ImageRangeMin has to be -127.");
      }
    }
    if (0 != hv_ImageRangeMaxExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
      if (0 != (int(hv_ImageRangeMax!=128)))
      {
        throw HException(("For model type "+hv_DLModelType)+" ImageRangeMax has to be 128.");
      }
    }
  }
  //
  //Check segmentation specific parameters.
  if (0 != (int(hv_DLModelType==HTuple("segmentation"))))
  {
    //Check if detection specific parameters are set.
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional, 
        &hv_KeysExists);
    //If they are present, check that they are [].
    {
    HTuple end_val151 = (hv_ParamNamesDetectionOptional.TupleLength())-1;
    HTuple step_val151 = 1;
    for (hv_IndexParam=0; hv_IndexParam.Continue(end_val151, step_val151); hv_IndexParam += step_val151)
    {
      if (0 != (HTuple(hv_KeysExists[hv_IndexParam])))
      {
        GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[hv_IndexParam]), 
            &hv_Value);
        if (0 != (int(hv_Value!=HTuple())))
        {
          throw HException(((("The preprocessing parameter '"+HTuple(hv_ParamNamesDetectionOptional[hv_IndexParam]))+"' was set to ")+hv_Value)+HTuple(" but for segmentation it should be set to [], as it is not used for this method."));
        }
      }
    }
    }
    //Check 'set_background_id'.
    GetDictTuple(hv_DLPreprocessParam, "set_background_id", &hv_SetBackgroundID);
    if (0 != (int((hv_SetBackgroundID.TupleLength())>1)))
    {
      throw HException("Only one class_id as 'set_background_id' allowed.");
    }
    //Check 'class_ids_background'.
    GetDictTuple(hv_DLPreprocessParam, "class_ids_background", &hv_ClassIDsBackground);
    if (0 != (HTuple(HTuple(int((hv_SetBackgroundID.TupleLength())>0)).TupleAnd(HTuple(int((hv_ClassIDsBackground.TupleLength())>0)).TupleNot())).TupleOr(HTuple(int((hv_ClassIDsBackground.TupleLength())>0)).TupleAnd(HTuple(int((hv_SetBackgroundID.TupleLength())>0)).TupleNot()))))
    {
      throw HException("Both keys 'set_background_id' and 'class_ids_background' are required.");
    }
    //Check that 'class_ids_background' and 'set_background_id' are disjoint.
    if (0 != (int((hv_SetBackgroundID.TupleLength())>0)))
    {
      TupleIntersection(hv_SetBackgroundID, hv_ClassIDsBackground, &hv_Intersection);
      if (0 != (hv_Intersection.TupleLength()))
      {
        throw HException("Class IDs in 'set_background_id' and 'class_ids_background' need to be disjoint.");
      }
    }
    //Check 'ignore_class_ids'.
    GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
    hv_KnownClasses.Clear();
    hv_KnownClasses.Append(hv_SetBackgroundID);
    hv_KnownClasses.Append(hv_ClassIDsBackground);
    {
    HTuple end_val179 = (hv_IgnoreClassIDs.TupleLength())-1;
    HTuple step_val179 = 1;
    for (hv_I=0; hv_I.Continue(end_val179, step_val179); hv_I += step_val179)
    {
      hv_IgnoreClassID = HTuple(hv_IgnoreClassIDs[hv_I]);
      TupleFindFirst(hv_KnownClasses, hv_IgnoreClassID, &hv_Index);
      if (0 != (HTuple(int((hv_Index.TupleLength())>0)).TupleAnd(int(hv_Index!=-1))))
      {
        throw HException("The given 'ignore_class_ids' must not be included in the 'class_ids_background' or 'set_background_id'.");
      }
    }
    }
  }
  else if (0 != (int(hv_DLModelType==HTuple("detection"))))
  {
    //Check if segmentation specific parameters are set.
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesSegmentation, &hv_KeysExists);
    //If they are present, check that they are [].
    {
    HTuple end_val190 = (hv_ParamNamesSegmentation.TupleLength())-1;
    HTuple step_val190 = 1;
    for (hv_IndexParam=0; hv_IndexParam.Continue(end_val190, step_val190); hv_IndexParam += step_val190)
    {
      if (0 != (HTuple(hv_KeysExists[hv_IndexParam])))
      {
        GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesSegmentation[hv_IndexParam]), 
            &hv_Value);
        if (0 != (int(hv_Value!=HTuple())))
        {
          throw HException(((("The preprocessing parameter '"+HTuple(hv_ParamNamesSegmentation[hv_IndexParam]))+"' was set to ")+hv_Value)+HTuple(" but for detection it should be set to [], as it is not used for this method."));
        }
      }
    }
    }
    //Check optional parameters.
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional, 
        &hv_OptionalKeysExist);
    if (0 != (HTuple(hv_OptionalKeysExist[0])))
    {
      //Check 'instance_type'.
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[0]), 
          &hv_InstanceType);
      if (0 != (int(((HTuple("rectangle1").Append("rectangle2")).TupleFind(hv_InstanceType))==-1)))
      {
        throw HException(("Invalid generic parameter for 'instance_type': "+hv_InstanceType)+HTuple(", only 'rectangle1' and 'rectangle2' are allowed"));
      }
    }
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional, 
        &hv_OptionalKeysExist);
    if (0 != (HTuple(hv_OptionalKeysExist[1])))
    {
      //Check 'ignore_direction'.
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[1]), 
          &hv_IgnoreDirection);
      if (0 != (int(((HTuple(1).Append(0)).TupleFind(hv_IgnoreDirection))==-1)))
      {
        throw HException(("Invalid generic parameter for 'ignore_direction': "+hv_IgnoreDirection)+HTuple(", only true and false are allowed"));
      }
    }
    if (0 != (HTuple(hv_OptionalKeysExist[2])))
    {
      //Check 'class_ids_no_orientation'.
      GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[2]), 
          &hv_ClassIDsNoOrientation);
      TupleSemTypeElem(hv_ClassIDsNoOrientation, &hv_SemTypes);
      if (0 != (HTuple(int(hv_ClassIDsNoOrientation!=HTuple())).TupleAnd(int(((hv_SemTypes.TupleEqualElem("integer")).TupleSum())!=(hv_ClassIDsNoOrientation.TupleLength())))))
      {
        throw HException(("Invalid generic parameter for 'class_ids_no_orientation': "+hv_ClassIDsNoOrientation)+HTuple(", only integers are allowed"));
      }
      else
      {
        if (0 != (HTuple(int(hv_ClassIDsNoOrientation!=HTuple())).TupleAnd(int(((hv_ClassIDsNoOrientation.TupleGreaterEqualElem(0)).TupleSum())!=(hv_ClassIDsNoOrientation.TupleLength())))))
        {
          throw HException(("Invalid generic parameter for 'class_ids_no_orientation': "+hv_ClassIDsNoOrientation)+HTuple(", only non-negative integers are allowed"));
        }
      }
    }
  }
  //
  return;
}

// Chapter: Tools / Geometry
// Short Description: Convert the parameters of rectangles with format rectangle2 to the coordinates of its 4 corner-points. 
void convert_rect2_5to8param (HTuple hv_Row, HTuple hv_Col, HTuple hv_Length1, HTuple hv_Length2, 
    HTuple hv_Phi, HTuple *hv_Row1, HTuple *hv_Col1, HTuple *hv_Row2, HTuple *hv_Col2, 
    HTuple *hv_Row3, HTuple *hv_Col3, HTuple *hv_Row4, HTuple *hv_Col4)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Co1, hv_Co2, hv_Si1, hv_Si2;

  //This procedure takes the parameters for a rectangle of type 'rectangle2'
  //and returns the coordinates of the four corners.
  //
  hv_Co1 = (hv_Phi.TupleCos())*hv_Length1;
  hv_Co2 = (hv_Phi.TupleCos())*hv_Length2;
  hv_Si1 = (hv_Phi.TupleSin())*hv_Length1;
  hv_Si2 = (hv_Phi.TupleSin())*hv_Length2;

  (*hv_Col1) = (hv_Co1-hv_Si2)+hv_Col;
  (*hv_Row1) = ((-hv_Si1)-hv_Co2)+hv_Row;
  (*hv_Col2) = ((-hv_Co1)-hv_Si2)+hv_Col;
  (*hv_Row2) = (hv_Si1-hv_Co2)+hv_Row;
  (*hv_Col3) = ((-hv_Co1)+hv_Si2)+hv_Col;
  (*hv_Row3) = (hv_Si1+hv_Co2)+hv_Row;
  (*hv_Col4) = (hv_Co1+hv_Si2)+hv_Col;
  (*hv_Row4) = ((-hv_Si1)+hv_Co2)+hv_Row;

  return;
}

// Chapter: Tools / Geometry
// Short Description: Convert for four-sided figures the coordinates of the 4 corner-points to the parameters of format rectangle2. 
void convert_rect2_8to5param (HTuple hv_Row1, HTuple hv_Col1, HTuple hv_Row2, HTuple hv_Col2, 
    HTuple hv_Row3, HTuple hv_Col3, HTuple hv_Row4, HTuple hv_Col4, HTuple hv_ForceL1LargerL2, 
    HTuple *hv_Row, HTuple *hv_Col, HTuple *hv_Length1, HTuple *hv_Length2, HTuple *hv_Phi)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Hor, hv_Vert, hv_IdxSwap, hv_Tmp;

  //This procedure takes the corners of four-sided figures
  //and returns the parameters of type 'rectangle2'.
  //
  //Calculate center row and column.
  (*hv_Row) = (((hv_Row1+hv_Row2)+hv_Row3)+hv_Row4)/4.0;
  (*hv_Col) = (((hv_Col1+hv_Col2)+hv_Col3)+hv_Col4)/4.0;
  //Length1 and Length2.
  (*hv_Length1) = ((((hv_Row1-hv_Row2)*(hv_Row1-hv_Row2))+((hv_Col1-hv_Col2)*(hv_Col1-hv_Col2))).TupleSqrt())/2.0;
  (*hv_Length2) = ((((hv_Row2-hv_Row3)*(hv_Row2-hv_Row3))+((hv_Col2-hv_Col3)*(hv_Col2-hv_Col3))).TupleSqrt())/2.0;
  //Calculate the angle phi.
  hv_Hor = hv_Col1-hv_Col2;
  hv_Vert = hv_Row2-hv_Row1;
  if (0 != hv_ForceL1LargerL2)
  {
    //Swap length1 and length2 if necessary.
    hv_IdxSwap = (((*hv_Length2)-(*hv_Length1)).TupleGreaterElem(1e-9)).TupleFind(1);
    if (0 != (int(hv_IdxSwap!=-1)))
    {
      hv_Tmp = HTuple((*hv_Length1)[hv_IdxSwap]);
      (*hv_Length1)[hv_IdxSwap] = HTuple((*hv_Length2)[hv_IdxSwap]);
      (*hv_Length2)[hv_IdxSwap] = hv_Tmp;
      hv_Hor[hv_IdxSwap] = HTuple(hv_Col2[hv_IdxSwap])-HTuple(hv_Col3[hv_IdxSwap]);
      hv_Vert[hv_IdxSwap] = HTuple(hv_Row3[hv_IdxSwap])-HTuple(hv_Row2[hv_IdxSwap]);
    }
  }
  (*hv_Phi) = hv_Vert.TupleAtan2(hv_Hor);
  //
  return;
}

// Chapter: Graphics / Window
// Short Description: Close all window handles contained in a dictionary. 
void dev_close_window_dict (HTuple hv_WindowHandleDict)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHandleKeys, hv_Index, hv_WindowHandles;
  HTuple  hv_Exception, hv_RemovedWindowIndices, hv_WindowHandleIndex;

  //
  //This procedure closes all window handles
  //that are contained in the dictionary WindowHandleDict.
  //
  GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeys);
  {
  HTuple end_val5 = (hv_WindowHandleKeys.TupleLength())-1;
  HTuple step_val5 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val5, step_val5); hv_Index += step_val5)
  {
    try
    {
      GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]), &hv_WindowHandles);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      continue;
    }
    hv_RemovedWindowIndices = HTuple();
    {
    HTuple end_val12 = (hv_WindowHandles.TupleLength())-1;
    HTuple step_val12 = 1;
    for (hv_WindowHandleIndex=0; hv_WindowHandleIndex.Continue(end_val12, step_val12); hv_WindowHandleIndex += step_val12)
    {
      //Not every entry has to be a window handle, therefore use try-catch.
      try
      {
        //Call set_window_param to check if the handle is a window handle.
        SetWindowParam(HTuple(hv_WindowHandles[hv_WindowHandleIndex]), "flush", "true");
        HDevWindowStack::SetActive(HTuple(hv_WindowHandles[hv_WindowHandleIndex]));
        if (HDevWindowStack::IsOpen())
          CloseWindow(HDevWindowStack::Pop());
        hv_RemovedWindowIndices = hv_RemovedWindowIndices.TupleConcat(hv_WindowHandleIndex);
      }
      // catch (Exception) 
      catch (HException &HDevExpDefaultException)
      {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
      }
    }
    }
    TupleRemove(hv_WindowHandles, hv_RemovedWindowIndices, &hv_WindowHandles);
    //If some entries remained, set reduced tuple. Otherwise, remove whole key entry.
    if (0 != (int((hv_WindowHandles.TupleLength())>0)))
    {
      SetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]), hv_WindowHandles);
    }
    else
    {
      RemoveDictKey(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]));
    }
  }
  }
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Display a map of the confidences. 
void dev_display_confidence_regions (HObject ho_ImageConfidence, HTuple hv_DrawTransparency, 
    HTuple *hv_Colors)
{

  // Local iconic variables
  HObject  ho_Region;

  // Local control variables
  HTuple  hv_NumColors, hv_WeightsColorsAlpha, hv_ColorIndex;
  HTuple  hv_Threshold, hv_MinGray, hv_MaxGray;

  //
  //This procedure displays a map of the confidences
  //given in ImageConfidence as regions.
  //DrawTransparency determines the alpha value of the colors.
  //The used colors are returned.
  //
  //Define colors.
  hv_NumColors = 20;
  get_distinct_colors_dl_visualization(hv_NumColors, 0, 0, 100, &(*hv_Colors));
  hv_WeightsColorsAlpha = (*hv_Colors)+hv_DrawTransparency;
  hv_ColorIndex = 0;
  //
  //Threshold the image according to
  //the number of colors and
  //display resulting regions.
  {
  HTuple end_val15 = hv_NumColors-1;
  HTuple step_val15 = 1;
  for (hv_ColorIndex=0; hv_ColorIndex.Continue(end_val15, step_val15); hv_ColorIndex += step_val15)
  {
    hv_Threshold = hv_ColorIndex*(1.0/hv_NumColors);
    hv_MinGray = hv_Threshold;
    hv_MaxGray = hv_Threshold+(1/hv_NumColors);
    Threshold(ho_ImageConfidence, &ho_Region, hv_Threshold, hv_Threshold+(1.0/hv_NumColors));
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_WeightsColorsAlpha[hv_ColorIndex]));
    if (HDevWindowStack::IsOpen())
      DispObj(ho_Region, HDevWindowStack::GetActive());
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Visualize different images, annotations and inference results for a sample. 
void dev_display_dl_data (HTuple hv_DLSample, HTuple hv_DLResult, HTuple hv_DLDatasetInfo, 
    HTuple hv_KeysForDisplay, HTuple hv_GenParam, HTuple hv_WindowHandleDict)
{

  // Local iconic variables
  HObject  ho_Image, ho_AnomalyImage, ho_AnomalyRegion;
  HObject  ho_PredictionColorFrame, ho_ImageHeatmap, ho_ImageWeight;
  HObject  ho_ImageConfidence, ho_SegmentationImagGroundTruth;
  HObject  ho_SegmentationImageResult, ho_ImageAbsDiff, ho_DiffRegion;

  // Local control variables
  HTuple  hv_ThresholdWidth, hv_ScaleWindows, hv_Font;
  HTuple  hv_FontSize, hv_LineWidth, hv_MapTransparency, hv_MapColorBarWidth;
  HTuple  hv_AnomalyRegionThreshold, hv_AnomalyClassificationThreshold;
  HTuple  hv_AnomalyRegionLabelColor, hv_AnomalyColorTransparency;
  HTuple  hv_AnomalyRegionResultColor, hv_SegMaxWeight, hv_SegDraw;
  HTuple  hv_SegTransparency, hv_SegExcludeClassIDs, hv_BboxLabelColor;
  HTuple  hv_BboxDisplayConfidence, hv_BboxTextColor, hv_ShowBottomDesc;
  HTuple  hv_ShowLegend, hv_ShowGroundTruthAnomalyRegions;
  HTuple  hv_ShowClassificationIDs, hv_ShowClassificationColorFrame;
  HTuple  hv_ShowLabels, hv_ShowDirection, hv_HeatmapColorScheme;
  HTuple  hv_GenParamNames, hv_ParamIndex, hv_GenParamName;
  HTuple  hv_GenParamValue, hv_SampleKeys, hv_ResultKeys;
  HTuple  hv_ImageIDExists, hv_ImageID, hv_ImageIDString;
  HTuple  hv_ImageIDStringBraces, hv_ImageIDStringCapital;
  HTuple  hv_NeededKeys, hv_Index, hv_DLDatasetInfoKeys, hv_ClassNames;
  HTuple  hv_ClassIDs, hv_Colors, hv_ClassesLegend, hv_PrevWindowCoordinates;
  HTuple  hv_Keys, hv_Exception, hv_MetaInfoIndex, hv_MetaInfo;
  HTuple  hv_FlushValues, hv_WindowHandleKeys, hv_KeyIndex;
  HTuple  hv_WindowHandles, hv_WindowIndex, hv_FlushValue;
  HTuple  hv_WidthImage, hv_HeightImage, hv_CurrentWindowHandle;
  HTuple  hv_WindowImageRatio, hv_AnomalyLabelGroundTruth;
  HTuple  hv_AnomalyLabelIDGroundTruth, hv_AnomalyRegionExists;
  HTuple  hv_Text, hv_AnomalyScore, hv_AnomalyClassID, hv_AnomalyClassThresholdDisplay;
  HTuple  hv_AnomalyRegionThresholdDisplay, hv_AnomalyRegionGroundTruthExists;
  HTuple  hv_PredictionColor, hv_LineColors, hv_ResultColorOffset;
  HTuple  hv_ClassificationLabelIDGroundTruth, hv_ClassificationLabelIDResult;
  HTuple  hv_MarginBottom, hv_WindowCoordinates, hv_CurrentWindowHeight;
  HTuple  hv__, hv_MaxHeight, hv_PredictionText, hv_BoarderOffset;
  HTuple  hv_WindowImageRatioHeight, hv_WindowImageRatioWidth;
  HTuple  hv_BoarderOffsetRow, hv_BoarderOffsetCol, hv_SelectedHeatmapMethod;
  HTuple  hv_DictHeatmap, hv_MethodName, hv_HeatmapKeys, hv_HeatmapImageName;
  HTuple  hv_TargetClassID, hv_Confidences, hv_MaxDeviation;
  HTuple  hv_ClassificationLabelNameResult, hv_TargetClassConfidence;
  HTuple  hv_ClassificationLabelNamesGroundTruth, hv_BboxIDs;
  HTuple  hv_BboxColors, hv_BboxIDsUniq, hv_BboxConfidences;
  HTuple  hv_TextConf, hv_BboxClassIndex, hv_BboxColorsResults;
  HTuple  hv_BboxClassIndexUniq, hv_BboxLabelIndex, hv_BboxColorsBoth;
  HTuple  hv_BboxClassLabelIndexUniq, hv_ColorsSegmentation;
  HTuple  hv_DrawMode, hv_Width, hv_ImageClassIDs, hv_ImageClassIDsUniq;
  HTuple  hv_ImageClassIDsIndices, hv_ImageClassIDsIndex;
  HTuple  hv_ColorsResults, hv_GroundTruthIDs, hv_ResultIDs;
  HTuple  hv_StringSegExcludeClassIDs, hv_StringIndex, hv_Min;
  HTuple  hv_Max, hv_Range, hv_MinWeight, hv_WeightsColors;
  HTuple  hv_ConfidenceColors, hv_Indices, hv_WindowHandleKeysNew;

  //
  //This procedure displays the content of the provided DLSample and/or DLResult
  //depending on the input string KeysForDisplay.
  //DLDatasetInfo is a dictionary containing the information about the dataset.
  //The visualization can be adapted with GenParam.
  //
  //** Set the default values: ***
  //
  //Define the screen width when a new window row is started.
  hv_ThresholdWidth = 1024;
  //Since potentially a lot of windows are opened,
  //scale the windows consistently.
  hv_ScaleWindows = 0.8;
  //Set a font and a font size.
  hv_Font = "mono";
  hv_FontSize = 14;
  //
  hv_LineWidth = 2;
  hv_MapTransparency = "cc";
  hv_MapColorBarWidth = 140;
  //
  //Define anomaly detection-specific parameter values.
  hv_AnomalyRegionThreshold = -1;
  hv_AnomalyClassificationThreshold = -1;
  hv_AnomalyRegionLabelColor = "#40e0d0";
  hv_AnomalyColorTransparency = "40";
  hv_AnomalyRegionResultColor = "#ff0000c0";
  //
  //Define segmentation-specific parameter values.
  hv_SegMaxWeight = 0;
  hv_SegDraw = "fill";
  hv_SegTransparency = "aa";
  hv_SegExcludeClassIDs = HTuple();
  //
  //Define bounding box-specific parameter values.
  hv_BboxLabelColor = HTuple("#000000")+"99";
  hv_BboxDisplayConfidence = 1;
  hv_BboxTextColor = "#eeeeee";
  //
  //By default, display a description on the bottom.
  hv_ShowBottomDesc = 1;
  //
  //By default, show a legend with class IDs.
  hv_ShowLegend = 1;
  //
  //By default, show the anomaly ground truth regions.
  hv_ShowGroundTruthAnomalyRegions = 1;
  //
  //By default, show class IDs and color frames for classification ground truth/results.
  hv_ShowClassificationIDs = 1;
  hv_ShowClassificationColorFrame = 1;
  //
  //By default, show class labels for detection ground truth/results.
  hv_ShowLabels = 1;
  //
  //By default, show direction of the ground truth/results instances for detection with instance_type 'rectangle2'.
  hv_ShowDirection = 1;
  //
  //By default, use color scheme 'Jet' for the heatmap display.
  hv_HeatmapColorScheme = "jet";
  //** Set user defined values: ***
  //
  //Overwrite default values by given generic parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamNames);
    {
    HTuple end_val65 = (hv_GenParamNames.TupleLength())-1;
    HTuple step_val65 = 1;
    for (hv_ParamIndex=0; hv_ParamIndex.Continue(end_val65, step_val65); hv_ParamIndex += step_val65)
    {
      hv_GenParamName = HTuple(hv_GenParamNames[hv_ParamIndex]);
      GetDictTuple(hv_GenParam, hv_GenParamName, &hv_GenParamValue);
      if (0 != (int(hv_GenParamName==HTuple("threshold_width"))))
      {
        hv_ThresholdWidth = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("scale_windows"))))
      {
        hv_ScaleWindows = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("font"))))
      {
        hv_Font = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("font_size"))))
      {
        hv_FontSize = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("line_width"))))
      {
        hv_LineWidth = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("map_transparency"))))
      {
        hv_MapTransparency = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("map_color_bar_width"))))
      {
        hv_MapColorBarWidth = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("segmentation_max_weight"))))
      {
        hv_SegMaxWeight = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("segmentation_draw"))))
      {
        hv_SegDraw = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("segmentation_transparency"))))
      {
        hv_SegTransparency = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("segmentation_exclude_class_ids"))))
      {
        hv_SegExcludeClassIDs = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("bbox_label_color"))))
      {
        hv_BboxLabelColor = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("bbox_display_confidence"))))
      {
        hv_BboxDisplayConfidence = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("bbox_text_color"))))
      {
        hv_BboxTextColor = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_bottom_desc"))))
      {
        hv_ShowBottomDesc = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_legend"))))
      {
        hv_ShowLegend = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_classification_ids"))))
      {
        hv_ShowClassificationIDs = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_classification_color_frame"))))
      {
        hv_ShowClassificationColorFrame = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_labels"))))
      {
        hv_ShowLabels = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_direction"))))
      {
        hv_ShowDirection = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("heatmap_color_scheme"))))
      {
        hv_HeatmapColorScheme = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("display_ground_truth_anomaly_regions"))))
      {
        hv_ShowGroundTruthAnomalyRegions = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("anomaly_region_threshold"))))
      {
        hv_AnomalyRegionThreshold = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("anomaly_classification_threshold"))))
      {
        hv_AnomalyClassificationThreshold = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("anomaly_region_label_color"))))
      {
        hv_AnomalyRegionLabelColor = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("anomaly_region_result_color"))))
      {
        hv_AnomalyRegionResultColor = hv_GenParamValue;
      }
      else if (0 != (int(hv_GenParamName==HTuple("anomaly_color_transparency"))))
      {
        hv_AnomalyColorTransparency = hv_GenParamValue;
      }
      else
      {
        throw HException(("Unknown generic parameter: "+hv_GenParamName)+".");
      }
    }
    }
  }
  //
  //Get the dictionary keys.
  GetDictParam(hv_DLSample, "keys", HTuple(), &hv_SampleKeys);
  if (0 != (int(hv_DLResult!=HTuple())))
  {
    GetDictParam(hv_DLResult, "keys", HTuple(), &hv_ResultKeys);
  }
  //
  //Get image ID if it is available.
  GetDictParam(hv_DLSample, "key_exists", "image_id", &hv_ImageIDExists);
  if (0 != hv_ImageIDExists)
  {
    GetDictTuple(hv_DLSample, "image_id", &hv_ImageID);
    hv_ImageIDString = "image ID "+hv_ImageID;
    hv_ImageIDStringBraces = ("(image ID "+hv_ImageID)+")";
    hv_ImageIDStringCapital = "Image ID "+hv_ImageID;
  }
  else
  {
    hv_ImageIDString = "";
    hv_ImageIDStringBraces = hv_ImageIDString;
    hv_ImageIDStringCapital = hv_ImageIDString;
  }
  //
  //Check if DLDatasetInfo is valid.
  if (0 != (int(hv_DLDatasetInfo==HTuple())))
  {
    //If DLDatasetInfo is empty, 'image' is the only key allowed in KeysForDisplay.
    if (0 != (HTuple(int((hv_KeysForDisplay.TupleLength())!=1)).TupleOr(int(HTuple(hv_KeysForDisplay[0])!=HTuple("image")))))
    {
      throw HException("DLDatasetInfo is needed for requested keys in KeysForDisplay.");
    }
  }
  else
  {
    //Check if DLDatasetInfo contains necessary keys.
    hv_NeededKeys.Clear();
    hv_NeededKeys[0] = "class_names";
    hv_NeededKeys[1] = "class_ids";
    {
    HTuple end_val156 = (hv_NeededKeys.TupleLength())-1;
    HTuple step_val156 = 1;
    for (hv_Index=0; hv_Index.Continue(end_val156, step_val156); hv_Index += step_val156)
    {
      GetDictParam(hv_DLDatasetInfo, "keys", HTuple(), &hv_DLDatasetInfoKeys);
      if (0 != (int((hv_DLDatasetInfoKeys.TupleFindFirst(HTuple(hv_NeededKeys[hv_Index])))==-1)))
      {
        throw HException(("Key "+HTuple(hv_NeededKeys[hv_Index]))+" is missing in DLDatasetInfo.");
      }
    }
    }
    //
    //Get the general dataset information, if available.
    GetDictTuple(hv_DLDatasetInfo, "class_names", &hv_ClassNames);
    GetDictTuple(hv_DLDatasetInfo, "class_ids", &hv_ClassIDs);
    //
    //Define distinct colors for the classes.
    get_dl_class_colors(hv_ClassNames, &hv_Colors);
    //
    hv_ClassesLegend = (hv_ClassIDs+" : ")+hv_ClassNames;
  }
  //
  //** Set window parameters: ***
  //
  //Set previous window coordinates.
  hv_PrevWindowCoordinates.Clear();
  hv_PrevWindowCoordinates[0] = 0;
  hv_PrevWindowCoordinates[1] = 0;
  hv_PrevWindowCoordinates[2] = 0;
  hv_PrevWindowCoordinates[3] = 0;
  hv_PrevWindowCoordinates[4] = 1;
  //
  //Check that the WindowHandleDict is of type dictionary.
  try
  {
    GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_Keys);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    if (0 != (int(HTuple(hv_Exception[0])==1401)))
    {
      throw HException("WindowHandleDict has to be of type dictionary. Use create_dict to create an empty dictionary.");
    }
    else
    {
      throw HException(hv_Exception);
    }
  }
  //For better usage, add meta information about the window handles in WindowHandleDict.
  TupleFind(hv_Keys, "meta_information", &hv_MetaInfoIndex);
  if (0 != (HTuple(int(hv_MetaInfoIndex==-1)).TupleOr(int(hv_MetaInfoIndex==HTuple()))))
  {
    CreateDict(&hv_MetaInfo);
    SetDictTuple(hv_WindowHandleDict, "meta_information", hv_MetaInfo);
  }
  //
  //For each window, set 'flush' to 'false' to avoid flickering.
  hv_FlushValues = HTuple();
  GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeys);
  {
  HTuple end_val198 = (hv_WindowHandleKeys.TupleLength())-1;
  HTuple step_val198 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val198, step_val198); hv_Index += step_val198)
  {
    //Only consider the WindowHandleKeys that are needed for the current visualization.
    hv_KeyIndex = hv_KeysForDisplay.TupleFind(HTuple(hv_WindowHandleKeys[hv_Index]));
    if (0 != (HTuple(int(hv_KeyIndex!=-1)).TupleAnd(int(hv_KeyIndex!=HTuple()))))
    {
      GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]), &hv_WindowHandles);
      {
      HTuple end_val203 = (hv_WindowHandles.TupleLength())-1;
      HTuple step_val203 = 1;
      for (hv_WindowIndex=0; hv_WindowIndex.Continue(end_val203, step_val203); hv_WindowIndex += step_val203)
      {
        GetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", &hv_FlushValue);
        hv_FlushValues = hv_FlushValues.TupleConcat(hv_FlushValue);
        SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", "false");
      }
      }
    }
  }
  }
  //
  //** Display the data: ***
  //
  //Display data dictionaries.
  {
  HTuple end_val214 = (hv_KeysForDisplay.TupleLength())-1;
  HTuple step_val214 = 1;
  for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val214, step_val214); hv_KeyIndex += step_val214)
  {
    if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("image"))))
    {
      //
      //Image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window", 
              "bottom", "left", "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_ground_truth"))))
    {
      //Image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_anomaly_ground_truth_label(hv_SampleKeys, hv_DLSample, &hv_AnomalyLabelGroundTruth, 
          &hv_AnomalyLabelIDGroundTruth);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualize image.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      hv_AnomalyRegionExists = "false";
      if (0 != hv_ShowGroundTruthAnomalyRegions)
      {
        //Show the ground truth region.
        dev_display_ground_truth_anomaly_regions(hv_SampleKeys, hv_DLSample, hv_CurrentWindowHandle, 
            hv_LineWidth, hv_AnomalyRegionLabelColor, hv_AnomalyColorTransparency, 
            &hv_AnomalyRegionExists);
      }
      //
      hv_Text = "Ground truth anomalies "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = ((hv_AnomalyLabelIDGroundTruth+" : '")+hv_AnomalyLabelGroundTruth)+"'";
        if (0 != (HTuple(HTuple(int(hv_AnomalyRegionExists==HTuple("false"))).TupleAnd(int(hv_AnomalyLabelIDGroundTruth==1))).TupleAnd(hv_ShowGroundTruthAnomalyRegions)))
        {
          hv_Text[hv_Text.TupleLength()] = "";
          hv_Text[hv_Text.TupleLength()] = "No 'anomaly_ground_truth' exists!";
        }
        //
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_result"))))
    {
      //
      //Get image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      //Get the anomaly results either by applying the specified thresholds or out of DLResult.
      get_anomaly_result(&ho_AnomalyImage, &ho_AnomalyRegion, hv_DLResult, hv_ResultKeys, 
          hv_AnomalyClassificationThreshold, hv_AnomalyRegionThreshold, &hv_AnomalyScore, 
          &hv_AnomalyClassID, &hv_AnomalyClassThresholdDisplay, &hv_AnomalyRegionThresholdDisplay);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualize image.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      //Display anomaly regions defined by the specified threshold or from DLResult.
      if (0 != (HTuple(int(hv_AnomalyRegionThreshold!=-1)).TupleOr(int((hv_ResultKeys.TupleFind("anomaly_region"))!=-1))))
      {
        dev_display_result_anomaly_regions(ho_AnomalyRegion, hv_CurrentWindowHandle, 
            hv_LineWidth, hv_AnomalyRegionResultColor);
      }
      //
      hv_Text = "Detected anomalies "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "---------------";
        hv_Text[hv_Text.TupleLength()] = "Results ";
        hv_Text[hv_Text.TupleLength()] = "---------------";
        if (0 != (int(hv_AnomalyClassID==1)))
        {
          hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'nok'";
        }
        else if (0 != (int(hv_AnomalyClassID==0)))
        {
          hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'ok'";
        }
        else
        {
          hv_Text[hv_Text.TupleLength()] = "No classification result found";
        }
        if (0 != (HTuple(int(hv_AnomalyRegionThreshold==-1)).TupleAnd(int((hv_ResultKeys.TupleFind("anomaly_region"))==-1))))
        {
          hv_Text[hv_Text.TupleLength()] = "";
          hv_Text[hv_Text.TupleLength()] = "No segmentation result found";
        }
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Anomaly score: "+(hv_AnomalyScore.TupleString(".2f"));
        hv_Text[hv_Text.TupleLength()] = "";
        if (0 != (HTuple(int(hv_AnomalyClassThresholdDisplay!=-1)).TupleOr(int(hv_AnomalyRegionThresholdDisplay!=-1))))
        {
          hv_Text[hv_Text.TupleLength()] = "---------------";
          hv_Text[hv_Text.TupleLength()] = "Thresholds ";
          hv_Text[hv_Text.TupleLength()] = "---------------";
        }
        //
        if (0 != (int(hv_AnomalyClassThresholdDisplay!=-1)))
        {
          hv_Text[hv_Text.TupleLength()] = "Classification: "+(hv_AnomalyClassThresholdDisplay.TupleString(".2f"));
          hv_Text[hv_Text.TupleLength()] = "";
        }
        if (0 != (int(hv_AnomalyRegionThresholdDisplay!=-1)))
        {
          hv_Text[hv_Text.TupleLength()] = "Segmentation: "+(hv_AnomalyRegionThresholdDisplay.TupleString(".2f"));
          hv_Text[hv_Text.TupleLength()] = "";
        }
        //
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_both"))))
    {
      //
      //Get image and ground truth.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_anomaly_ground_truth_label(hv_SampleKeys, hv_DLSample, &hv_AnomalyLabelGroundTruth, 
          &hv_AnomalyLabelIDGroundTruth);
      //
      //Get the anomaly results either by applying the specified thresholds or out of DLResult.
      get_anomaly_result(&ho_AnomalyImage, &ho_AnomalyRegion, hv_DLResult, hv_ResultKeys, 
          hv_AnomalyClassificationThreshold, hv_AnomalyRegionThreshold, &hv_AnomalyScore, 
          &hv_AnomalyClassID, &hv_AnomalyClassThresholdDisplay, &hv_AnomalyRegionThresholdDisplay);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualize image, ground truth (if available), and result regions.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      hv_AnomalyRegionGroundTruthExists = "false";
      if (0 != hv_ShowGroundTruthAnomalyRegions)
      {
        dev_display_ground_truth_anomaly_regions(hv_SampleKeys, hv_DLSample, hv_CurrentWindowHandle, 
            hv_LineWidth, hv_AnomalyRegionLabelColor, hv_AnomalyColorTransparency, 
            &hv_AnomalyRegionGroundTruthExists);
      }
      //
      //Display anomaly regions defined by the specified threshold or from DLResult.
      if (0 != (HTuple(int(hv_AnomalyRegionThreshold!=-1)).TupleOr(int((hv_ResultKeys.TupleFind("anomaly_region"))!=-1))))
      {
        dev_display_result_anomaly_regions(ho_AnomalyRegion, hv_CurrentWindowHandle, 
            hv_LineWidth, hv_AnomalyRegionResultColor);
      }
      //
      hv_Text = "GT and detected anomalies "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Get prediction color.
      hv_PredictionColor = "white";
      if (0 != (int(hv_AnomalyLabelIDGroundTruth==hv_AnomalyClassID)))
      {
        hv_PredictionColor = "green";
      }
      else if (0 != (int(hv_AnomalyClassID!=-1)))
      {
        hv_PredictionColor = "red";
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "---------------";
        hv_Text[hv_Text.TupleLength()] = "Ground truth ";
        hv_Text[hv_Text.TupleLength()] = "---------------";
        hv_Text[hv_Text.TupleLength()] = ((hv_AnomalyLabelIDGroundTruth+" : '")+hv_AnomalyLabelGroundTruth)+"'";
        if (0 != (HTuple(HTuple(int(hv_AnomalyRegionGroundTruthExists==HTuple("false"))).TupleAnd(int(hv_AnomalyLabelIDGroundTruth==1))).TupleAnd(hv_ShowGroundTruthAnomalyRegions)))
        {
          hv_Text[hv_Text.TupleLength()] = "";
          hv_Text[hv_Text.TupleLength()] = "No segmentation ground truth found";
        }
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "---------------";
        hv_Text[hv_Text.TupleLength()] = "Results ";
        hv_Text[hv_Text.TupleLength()] = "---------------";
        if (0 != (int(hv_AnomalyClassID==1)))
        {
          hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'nok'";
        }
        else if (0 != (int(hv_AnomalyClassID==0)))
        {
          hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'ok'";
        }
        else
        {
          hv_Text[hv_Text.TupleLength()] = "No classification result found";
        }
        if (0 != (HTuple(int(hv_AnomalyRegionThreshold==-1)).TupleAnd(int((hv_ResultKeys.TupleFind("anomaly_region"))==-1))))
        {
          hv_Text[hv_Text.TupleLength()] = "";
          hv_Text[hv_Text.TupleLength()] = "No segmentation result found";
        }
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Anomaly score: "+(hv_AnomalyScore.TupleString(".2f"));
        hv_Text[hv_Text.TupleLength()] = "";
        if (0 != (HTuple(int(hv_AnomalyClassThresholdDisplay!=-1)).TupleOr(int(hv_AnomalyRegionThresholdDisplay!=-1))))
        {
          hv_Text[hv_Text.TupleLength()] = "---------------";
          hv_Text[hv_Text.TupleLength()] = "Thresholds ";
          hv_Text[hv_Text.TupleLength()] = "---------------";
        }
        //
        if (0 != (int(hv_AnomalyClassThresholdDisplay!=-1)))
        {
          hv_Text[hv_Text.TupleLength()] = "Classification: "+(hv_AnomalyClassThresholdDisplay.TupleString(".2f"));
          hv_Text[hv_Text.TupleLength()] = "";
        }
        if (0 != (int(hv_AnomalyRegionThresholdDisplay!=-1)))
        {
          hv_Text[hv_Text.TupleLength()] = "Segmentation: "+(hv_AnomalyRegionThresholdDisplay.TupleString(".2f"));
          hv_Text[hv_Text.TupleLength()] = "";
        }
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        TupleGenConst(hv_Text.TupleLength(), "white", &hv_LineColors);
        hv_ResultColorOffset = 10;
        if (0 != (HTuple(HTuple(int(hv_AnomalyRegionGroundTruthExists==HTuple("false"))).TupleAnd(int(hv_AnomalyLabelIDGroundTruth==1))).TupleAnd(hv_ShowGroundTruthAnomalyRegions)))
        {
          hv_ResultColorOffset += 2;
        }
        hv_LineColors[hv_ResultColorOffset] = hv_PredictionColor;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              hv_LineColors, "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_image"))))
    {
      //
      //Image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      get_anomaly_result(&ho_AnomalyImage, &ho_AnomalyRegion, hv_DLResult, hv_ResultKeys, 
          hv_AnomalyClassificationThreshold, hv_AnomalyRegionThreshold, &hv_AnomalyScore, 
          &hv_AnomalyClassID, &hv_AnomalyClassThresholdDisplay, &hv_AnomalyRegionThresholdDisplay);
      //
      //Read in input image.
      GetDictObject(&ho_Image, hv_DLSample, "image");
      //Add the anomaly image to the input image.
      add_colormap_to_image(ho_AnomalyImage, ho_Image, &ho_AnomalyImage, hv_HeatmapColorScheme);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      if (HDevWindowStack::IsOpen())
        DispObj(ho_AnomalyImage, HDevWindowStack::GetActive());
      hv_Text = "Anomaly image "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text[hv_Text.TupleLength()] = "";
        if (0 != (int(hv_AnomalyClassID==1)))
        {
          hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'nok'";
        }
        else if (0 != (int(hv_AnomalyClassID==0)))
        {
          hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'ok'";
        }
        else
        {
          hv_Text[hv_Text.TupleLength()] = "No classification result found";
        }
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Anomaly score: "+(hv_AnomalyScore.TupleString(".2f"));
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("classification_ground_truth"))))
    {
      //
      //Ground truth classification image and class label.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      get_classification_ground_truth(hv_SampleKeys, hv_DLSample, &hv_ClassificationLabelIDGroundTruth);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      if (0 != hv_ShowClassificationIDs)
      {
        hv_Text = "GT label ID: "+hv_ClassificationLabelIDGroundTruth;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              "white", "box", "false");
      }
      //
      if (0 != hv_ShowBottomDesc)
      {
        hv_Text = "Ground truth classification "+hv_ImageIDStringBraces;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text = "Ground truth class ID "+hv_ImageIDStringBraces;
        hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ClassificationLabelIDGroundTruth]));
        //
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ClassificationLabelIDGroundTruth])), 
              "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("classification_result"))))
    {
      //
      //Ground truth classification image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      get_classification_result(hv_ResultKeys, hv_DLResult, &hv_ClassificationLabelIDResult);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      //Display the class IDs.
      if (0 != hv_ShowClassificationIDs)
      {
        GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
        GetDictTuple(hv_MetaInfo, "classification_result_margin_bottom", &hv_MarginBottom);
        GetDictTuple(hv_MetaInfo, "classification_result_window_coordinates", &hv_WindowCoordinates);
        hv_CurrentWindowHeight = HTuple(hv_WindowCoordinates[3])-HTuple(hv_WindowCoordinates[0]);
        GetFontExtents(hv_CurrentWindowHandle, &hv__, &hv__, &hv__, &hv_MaxHeight);
        hv_Text = "Result class ID: "+hv_ClassificationLabelIDResult;
        if (0 != hv_ShowBottomDesc)
        {
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_CurrentWindowHeight-((hv_MarginBottom+hv_MaxHeight)+10), 
                "left", "white", "box", "false");
        }
        else
        {
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
                "white", "box", "false");
        }
      }
      //
      if (0 != hv_ShowBottomDesc)
      {
        hv_Text = "Result classification "+hv_ImageIDStringBraces;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text = "Result class ID "+hv_ImageIDStringBraces;
        if (0 != (int(hv_ClassificationLabelIDResult==HTuple())))
        {
          hv_Text[hv_Text.TupleLength()] = "No classification result is given!";
        }
        else
        {
          hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ClassificationLabelIDResult]));
        }
        //
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ClassificationLabelIDResult])), 
              "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("classification_both"))))
    {
      //
      //Ground truth and result classification image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      get_classification_ground_truth(hv_SampleKeys, hv_DLSample, &hv_ClassificationLabelIDGroundTruth);
      get_classification_result(hv_ResultKeys, hv_DLResult, &hv_ClassificationLabelIDResult);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      //
      //Get prediction color.
      hv_PredictionColor = "white";
      if (0 != (int(hv_ClassificationLabelIDGroundTruth==hv_ClassificationLabelIDResult)))
      {
        hv_PredictionText = "Correct";
        hv_PredictionColor = "green";
      }
      else
      {
        hv_PredictionText = "Wrong";
        hv_PredictionColor = "red";
      }
      //
      //Generate prediction color frame and show image.
      if (0 != hv_ShowClassificationColorFrame)
      {
        //Create a frame with line width 7 that is completely displayed in the window.
        hv_BoarderOffset = 7/2.;
        GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
        GetDictTuple(hv_MetaInfo, "classification_both_window_image_ratio_height", 
            &hv_WindowImageRatioHeight);
        GetDictTuple(hv_MetaInfo, "classification_both_window_image_ratio_width", 
            &hv_WindowImageRatioWidth);
        hv_BoarderOffsetRow = hv_BoarderOffset/hv_WindowImageRatioHeight;
        hv_BoarderOffsetCol = hv_BoarderOffset/hv_WindowImageRatioWidth;
        GenContourPolygonXld(&ho_PredictionColorFrame, ((((hv_BoarderOffsetRow-0.5).TupleConcat(hv_BoarderOffsetRow-0.5)).TupleConcat((hv_HeightImage+0.5)-hv_BoarderOffsetRow)).TupleConcat((hv_HeightImage+0.5)-hv_BoarderOffsetRow)).TupleConcat(hv_BoarderOffsetRow-0.5), 
            ((((hv_BoarderOffsetCol-0.5).TupleConcat((hv_WidthImage+0.5)-hv_BoarderOffsetCol)).TupleConcat((hv_WidthImage+0.5)-hv_BoarderOffsetCol)).TupleConcat(hv_BoarderOffsetCol-0.5)).TupleConcat(hv_BoarderOffsetCol-0.5));
        if (HDevWindowStack::IsOpen())
          SetLineWidth(HDevWindowStack::GetActive(),7);
        if (HDevWindowStack::IsOpen())
          SetColor(HDevWindowStack::GetActive(),hv_PredictionColor);
        if (HDevWindowStack::IsOpen())
          DispObj(ho_Image, HDevWindowStack::GetActive());
        if (HDevWindowStack::IsOpen())
          DispObj(ho_PredictionColorFrame, HDevWindowStack::GetActive());
      }
      else
      {
        if (HDevWindowStack::IsOpen())
          DispObj(ho_Image, HDevWindowStack::GetActive());
      }
      //
      if (0 != hv_ShowClassificationIDs)
      {
        GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
        GetDictTuple(hv_MetaInfo, HTuple(hv_KeysForDisplay[hv_KeyIndex])+"_margin_bottom", 
            &hv_MarginBottom);
        GetDictTuple(hv_MetaInfo, HTuple(hv_KeysForDisplay[hv_KeyIndex])+"_window_coordinates", 
            &hv_WindowCoordinates);
        hv_CurrentWindowHeight = HTuple(hv_WindowCoordinates[3])-HTuple(hv_WindowCoordinates[0]);
        GetFontExtents(hv_CurrentWindowHandle, &hv__, &hv__, &hv__, &hv_MaxHeight);
        hv_Text = "GT label ID: "+hv_ClassificationLabelIDGroundTruth;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              "white", "box", "false");
        hv_Text = "Result class ID: "+hv_ClassificationLabelIDResult;
        if (0 != hv_ShowBottomDesc)
        {
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_CurrentWindowHeight-((hv_MarginBottom+hv_MaxHeight)+10), 
                "left", "white", "box", "false");
        }
        else
        {
          if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
                "white", "box", "false");
        }
      }
      //
      if (0 != hv_ShowBottomDesc)
      {
        hv_Text = "Result/Ground truth classification "+hv_ImageIDStringBraces;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_Text = "Ground truth class ID "+hv_ImageIDStringBraces;
        hv_Text[hv_Text.TupleLength()] = HTuple(hv_ClassesLegend[hv_ClassificationLabelIDGroundTruth]);
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Result class ID";
        if (0 != (int(hv_ClassificationLabelIDResult==HTuple())))
        {
          hv_Text[hv_Text.TupleLength()] = "No classification result is given!";
        }
        else
        {
          hv_Text[hv_Text.TupleLength()] = HTuple(hv_ClassesLegend[hv_ClassificationLabelIDResult]);
          hv_Text[hv_Text.TupleLength()] = "";
          hv_Text[hv_Text.TupleLength()] = "";
          hv_Text[hv_Text.TupleLength()] = "Prediction ";
          hv_Text[hv_Text.TupleLength()] = hv_PredictionText;
        }
        //
        //Get or open next child window.
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        TupleGenConst(hv_Text.TupleLength(), "white", &hv_LineColors);
        hv_LineColors[1] = HTuple(hv_Colors[hv_ClassificationLabelIDGroundTruth]);
        if (0 != (int(hv_ClassificationLabelIDResult!=HTuple())))
        {
          hv_LineColors[5] = HTuple(hv_Colors[hv_ClassificationLabelIDResult]);
          hv_LineColors[9] = hv_PredictionColor;
        }
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              hv_LineColors, "box", "false");
      }
      //
    }
    else if (0 != (HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("heatmap_grad_cam"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("heatmap_confidence_based")))))
    {
      //
      //Display the heatmap image (method 'heatmap_grad_cam' or 'heatmap_confidence_based')
      //in the selected color scheme.
      //Retrieve heatmap image, inferred image, and inference results.
      hv_SelectedHeatmapMethod = HTuple(hv_KeysForDisplay[hv_KeyIndex]);
      if (0 != (HTuple(int((hv_ResultKeys.TupleFind("heatmap_grad_cam"))!=-1)).TupleOr(int((hv_ResultKeys.TupleFind("heatmap_confidence_based"))!=-1))))
      {
        if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_grad_cam"))))
        {
          GetDictTuple(hv_DLResult, "heatmap_grad_cam", &hv_DictHeatmap);
          hv_MethodName = "Grad-CAM";
        }
        else
        {
          GetDictTuple(hv_DLResult, "heatmap_confidence_based", &hv_DictHeatmap);
          hv_MethodName = "Confidence based";
        }
        GetDictParam(hv_DictHeatmap, "keys", HTuple(), &hv_HeatmapKeys);
        hv_HeatmapImageName = hv_HeatmapKeys.TupleRegexpSelect("heatmap_image_class_[0-9]*");
        hv_TargetClassID = hv_HeatmapImageName.TupleRegexpMatch("heatmap_image_class_([0-9]+)$");
        GetDictObject(&ho_ImageHeatmap, hv_DictHeatmap, hv_HeatmapImageName);
      }
      else
      {
        throw HException("Heatmap image could not be found in DLResult.");
      }
      //
      if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_grad_cam"))))
      {
        //Read in input image.
        GetDictObject(&ho_Image, hv_DLSample, "image");
        //Add the heatmap to the input image.
        add_colormap_to_image(ho_ImageHeatmap, ho_Image, &ho_ImageHeatmap, hv_HeatmapColorScheme);
      }
      //
      //Get or open next window.
      GetImageSize(ho_ImageHeatmap, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageHeatmap, HDevWindowStack::GetActive());
      if (0 != hv_ShowBottomDesc)
      {
        hv_Text = "Classification heatmap "+hv_ImageIDStringBraces;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        GetDictTuple(hv_DLResult, "classification_class_names", &hv_ClassNames);
        GetDictTuple(hv_DLResult, "classification_class_ids", &hv_ClassIDs);
        GetDictTuple(hv_DLResult, "classification_confidences", &hv_Confidences);
        if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_confidence_based"))))
        {
          GetDictTuple(hv_DictHeatmap, "classification_heatmap_maxdeviation", &hv_MaxDeviation);
        }
        hv_ClassificationLabelNameResult = ((const HTuple&)hv_ClassNames)[0];
        hv_ClassificationLabelIDResult = ((const HTuple&)hv_ClassIDs)[0];
        hv_TargetClassConfidence = HTuple(hv_Confidences[hv_ClassIDs.TupleFind(hv_TargetClassID.TupleNumber())]);
        hv_Text = "--------- ";
        hv_Text[hv_Text.TupleLength()] = "Image ";
        hv_Text[hv_Text.TupleLength()] = "--------- ";
        hv_Text[hv_Text.TupleLength()] = "";
        if (0 != (int((hv_SampleKeys.TupleFind("image_label_id"))!=-1)))
        {
          GetDictTuple(hv_DLSample, "image_label_id", &hv_ClassificationLabelIDGroundTruth);
          GetDictTuple(hv_DLDatasetInfo, "class_names", &hv_ClassificationLabelNamesGroundTruth);
          //Get prediction color.
          if (0 != (int(hv_ClassificationLabelIDGroundTruth==hv_ClassificationLabelIDResult)))
          {
            hv_PredictionColor = "green";
          }
          else
          {
            hv_PredictionColor = "red";
          }
          hv_Text[hv_Text.TupleLength()] = "Ground truth class: ";
          hv_Text[hv_Text.TupleLength()] = HTuple(hv_ClassificationLabelNamesGroundTruth[hv_ClassificationLabelIDGroundTruth]);
          hv_Text[hv_Text.TupleLength()] = "";
        }
        hv_Text[hv_Text.TupleLength()] = "Predicted class: ";
        hv_Text[hv_Text.TupleLength()] = hv_ClassificationLabelNameResult;
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Confidence: "+(HTuple(hv_Confidences[0]).TupleString(".2f"));
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "--------- ";
        hv_Text[hv_Text.TupleLength()] = "Heatmap ";
        hv_Text[hv_Text.TupleLength()] = "--------- ";
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Method: "+hv_MethodName;
        hv_Text[hv_Text.TupleLength()] = "Target class: "+hv_TargetClassID;
        hv_Text[hv_Text.TupleLength()] = "";
        hv_Text[hv_Text.TupleLength()] = "Target class confidence: "+(hv_TargetClassConfidence.TupleString(".2f"));
        if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_confidence_based"))))
        {
          hv_Text[hv_Text.TupleLength()] = "Maximum deviation: "+(hv_MaxDeviation.TupleString(".2f"));
        }
        //
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        TupleGenConst(hv_Text.TupleLength(), "white", &hv_LineColors);
        if (0 != (int((hv_SampleKeys.TupleFind("image_label_id"))!=-1)))
        {
          hv_LineColors[8] = hv_PredictionColor;
        }
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              hv_LineColors, "box", "false");
      }
      //
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_weight"))))
    {
      //
      //Weight image.
      get_weight_image(&ho_ImageWeight, hv_SampleKeys, hv_DLSample);
      //
      //Get or open next window.
      GetImageSize(ho_ImageWeight, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageWeight, HDevWindowStack::GetActive());
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),"Weight image "+hv_ImageIDStringBraces, 
              "window", "bottom", "left", "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_confidence"))))
    {
      //
      //Segmentation confidences.
      get_confidence_image(&ho_ImageConfidence, hv_ResultKeys, hv_DLResult);
      //
      //Get or open next window.
      GetImageSize(ho_ImageConfidence, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageConfidence, HDevWindowStack::GetActive());
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),"Confidence image "+hv_ImageIDStringBraces, 
              "window", "bottom", "left", "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("bbox_ground_truth"))))
    {
      //
      //Sample bounding boxes on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      dev_display_ground_truth_detection(hv_DLSample, hv_SampleKeys, hv_LineWidth, 
          hv_ClassIDs, hv_Colors, hv_BboxLabelColor, hv_WindowImageRatio, hv_BboxTextColor, 
          hv_ShowLabels, hv_ShowDirection, hv_CurrentWindowHandle, &hv_BboxIDs);
      hv_Text = "Ground truth "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_BboxColors = "white";
        if (0 != (hv_BboxIDs.TupleLength()))
        {
          hv_BboxIDsUniq = (hv_BboxIDs.TupleSort()).TupleUniq();
          hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_BboxIDsUniq]));
          hv_BboxColors = hv_BboxColors.TupleConcat(HTuple(hv_Colors[hv_BboxIDsUniq]));
        }
        else
        {
          hv_Text = hv_Text.TupleConcat("No ground truth bounding boxes present.");
        }
        //
        //Get or open next child window.
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              hv_BboxColors, "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("bbox_result"))))
    {
      //
      //Result bounding boxes on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      if (0 != (int((hv_ResultKeys.TupleFind("bbox_confidence"))!=-1)))
      {
        GetDictTuple(hv_DLResult, "bbox_confidence", &hv_BboxConfidences);
      }
      else
      {
        throw HException("Result bounding box data could not be found in DLResult.");
      }
      if (0 != hv_BboxDisplayConfidence)
      {
        hv_TextConf = (" ("+(hv_BboxConfidences.TupleString(".2f")))+")";
      }
      else
      {
        hv_TextConf = HTuple(hv_BboxConfidences.TupleLength(),"");
      }
      dev_display_result_detection(hv_DLResult, hv_ResultKeys, hv_LineWidth, hv_ClassIDs, 
          hv_TextConf, hv_Colors, hv_BboxLabelColor, hv_WindowImageRatio, "top", 
          hv_BboxTextColor, hv_ShowLabels, hv_ShowDirection, hv_CurrentWindowHandle, 
          &hv_BboxClassIndex);
      hv_Text = "Result bounding boxes "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_BboxColorsResults = "white";
        if (0 != (int((hv_BboxClassIndex.TupleLength())>0)))
        {
          hv_BboxClassIndexUniq = (hv_BboxClassIndex.TupleSort()).TupleUniq();
          hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_BboxClassIndexUniq]));
          hv_BboxColorsResults = hv_BboxColorsResults.TupleConcat(HTuple(hv_Colors[hv_BboxClassIndexUniq]));
        }
        else
        {
          hv_Text = hv_Text.TupleConcat("No result bounding boxes present.");
        }
        //
        //Get or open next child window.
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              hv_BboxColorsResults, "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("bbox_both"))))
    {
      //
      //Ground truth and result bounding boxes on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      //Visualization.
      dev_display_ground_truth_detection(hv_DLSample, hv_SampleKeys, hv_LineWidth, 
          hv_ClassIDs, hv_Colors, hv_BboxLabelColor, hv_WindowImageRatio, hv_BboxTextColor, 
          hv_ShowLabels, hv_ShowDirection, hv_CurrentWindowHandle, &hv_BboxLabelIndex);
      if (0 != (int((hv_ResultKeys.TupleFind("bbox_confidence"))!=-1)))
      {
        GetDictTuple(hv_DLResult, "bbox_confidence", &hv_BboxConfidences);
      }
      else
      {
        throw HException("Result bounding box data could not be found in DLResult.");
      }
      if (0 != hv_BboxDisplayConfidence)
      {
        hv_TextConf = (" ("+(hv_BboxConfidences.TupleString(".2f")))+")";
      }
      else
      {
        hv_TextConf = HTuple(hv_BboxConfidences.TupleLength(),"");
      }
      dev_display_result_detection(hv_DLResult, hv_ResultKeys, hv_LineWidth, hv_ClassIDs, 
          hv_TextConf, hv_Colors, hv_BboxLabelColor, hv_WindowImageRatio, "bottom", 
          hv_BboxTextColor, hv_ShowLabels, hv_ShowDirection, hv_CurrentWindowHandle, 
          &hv_BboxClassIndex);
      hv_Text = "Ground truth and result bounding boxes "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      hv_Text = "Ground truth and";
      hv_Text[hv_Text.TupleLength()] = "result bounding boxes "+hv_ImageIDStringBraces;
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_BboxColorsBoth.Clear();
        hv_BboxColorsBoth[0] = "white";
        hv_BboxColorsBoth[1] = "white";
        if (0 != (int(((hv_BboxClassIndex.TupleLength())+(hv_BboxLabelIndex.TupleLength()))>0)))
        {
          hv_BboxClassLabelIndexUniq = ((hv_BboxClassIndex.TupleConcat(hv_BboxLabelIndex)).TupleSort()).TupleUniq();
          hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_BboxClassLabelIndexUniq]));
          hv_BboxColorsBoth = hv_BboxColorsBoth.TupleConcat(HTuple(hv_Colors[hv_BboxClassLabelIndexUniq]));
        }
        else
        {
          hv_Text = hv_Text.TupleConcat("No ground truth nor result bounding boxes present.");
        }
        //
        //Get or open next child window.
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              hv_BboxColorsBoth, "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_ground_truth"))))
    {
      //
      //Ground truth segmentation image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_segmentation_image_ground_truth(&ho_SegmentationImagGroundTruth, hv_SampleKeys, 
          hv_DLSample);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      //Display segmentation regions.
      hv_ColorsSegmentation = hv_Colors+hv_SegTransparency;
      GetDraw(hv_CurrentWindowHandle, &hv_DrawMode);
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),hv_SegDraw);
      GetLineWidth(hv_CurrentWindowHandle, &hv_Width);
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth);
      dev_display_segmentation_regions(ho_SegmentationImagGroundTruth, hv_ClassIDs, 
          hv_ColorsSegmentation, hv_SegExcludeClassIDs, &hv_ImageClassIDs);
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),hv_Width.TupleInt());
      hv_Text = "Ground truth segmentation "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_ImageClassIDsUniq = (hv_ImageClassIDs.TupleSort()).TupleUniq();
        //Get Indices according to image class IDs.
        TupleGenConst(hv_ImageClassIDsUniq.TupleLength(), 0, &hv_ImageClassIDsIndices);
        {
        HTuple end_val900 = (hv_ImageClassIDsUniq.TupleLength())-1;
        HTuple step_val900 = 1;
        for (hv_ImageClassIDsIndex=0; hv_ImageClassIDsIndex.Continue(end_val900, step_val900); hv_ImageClassIDsIndex += step_val900)
        {
          hv_ImageClassIDsIndices[hv_ImageClassIDsIndex] = hv_ClassIDs.TupleFindFirst(HTuple(hv_ImageClassIDsUniq[hv_ImageClassIDsIndex]));
        }
        }
        hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ImageClassIDsIndices]));
        //
        //Get or open next child window
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ImageClassIDsIndices])), 
              "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_result"))))
    {
      //
      //Result segmentation on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_segmentation_image_result(&ho_SegmentationImageResult, hv_ResultKeys, hv_DLResult);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      //Display result segmentation regions.
      hv_ColorsResults = hv_Colors+hv_SegTransparency;
      GetDraw(hv_CurrentWindowHandle, &hv_DrawMode);
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),hv_SegDraw);
      GetLineWidth(hv_CurrentWindowHandle, &hv_Width);
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth);
      dev_display_segmentation_regions(ho_SegmentationImageResult, hv_ClassIDs, hv_ColorsResults, 
          hv_SegExcludeClassIDs, &hv_ImageClassIDs);
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),hv_Width.TupleInt());
      hv_Text = "Result segmentation "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_ImageClassIDsUniq = (hv_ImageClassIDs.TupleSort()).TupleUniq();
        //Get Indices according to image class IDs.
        TupleGenConst(hv_ImageClassIDsUniq.TupleLength(), 0, &hv_ImageClassIDsIndices);
        {
        HTuple end_val941 = (hv_ImageClassIDsUniq.TupleLength())-1;
        HTuple step_val941 = 1;
        for (hv_ImageClassIDsIndex=0; hv_ImageClassIDsIndex.Continue(end_val941, step_val941); hv_ImageClassIDsIndex += step_val941)
        {
          hv_ImageClassIDsIndices[hv_ImageClassIDsIndex] = hv_ClassIDs.TupleFindFirst(HTuple(hv_ImageClassIDsUniq[hv_ImageClassIDsIndex]));
        }
        }
        hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ImageClassIDsIndices]));
        //
        //Get or open next child window.
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ImageClassIDsIndices])), 
              "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_both"))))
    {
      //
      //Ground truth and result segmentation on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_segmentation_image_ground_truth(&ho_SegmentationImagGroundTruth, hv_SampleKeys, 
          hv_DLSample);
      get_segmentation_image_result(&ho_SegmentationImageResult, hv_ResultKeys, hv_DLResult);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      //
      //Display regions.
      hv_ColorsResults = hv_Colors+hv_SegTransparency;
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),"margin");
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),2);
      dev_display_segmentation_regions(ho_SegmentationImagGroundTruth, hv_ClassIDs, 
          hv_ColorsResults, hv_SegExcludeClassIDs, &hv_GroundTruthIDs);
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),6);
      dev_display_segmentation_regions(ho_SegmentationImageResult, hv_ClassIDs, hv_ColorsResults, 
          hv_SegExcludeClassIDs, &hv_ResultIDs);
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),"fill");
      hv_Text = "Ground truth and result segmentation "+hv_ImageIDStringBraces;
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
      //
      //Display the legend.
      if (0 != hv_ShowLegend)
      {
        hv_ImageClassIDsUniq = ((hv_GroundTruthIDs.TupleConcat(hv_ResultIDs)).TupleSort()).TupleUniq();
        //Get Indices according to image class IDs.
        TupleGenConst(hv_ImageClassIDsUniq.TupleLength(), 0, &hv_ImageClassIDsIndices);
        {
        HTuple end_val982 = (hv_ImageClassIDsUniq.TupleLength())-1;
        HTuple step_val982 = 1;
        for (hv_ImageClassIDsIndex=0; hv_ImageClassIDsIndex.Continue(end_val982, step_val982); hv_ImageClassIDsIndex += step_val982)
        {
          hv_ImageClassIDsIndices[hv_ImageClassIDsIndex] = hv_ClassIDs.TupleFindFirst(HTuple(hv_ImageClassIDsUniq[hv_ImageClassIDsIndex]));
        }
        }
        hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ImageClassIDsIndices]));
        hv_Text[(hv_Text.TupleLength())+1] = HTuple("- thicker line: result, thinner lines: ground truth");
        hv_Text[hv_Text.TupleLength()] = "  (you may have to zoom in for a more detailed view)";
        hv_StringSegExcludeClassIDs = "";
        {
        HTuple end_val989 = (hv_SegExcludeClassIDs.TupleLength())-1;
        HTuple step_val989 = 1;
        for (hv_StringIndex=0; hv_StringIndex.Continue(end_val989, step_val989); hv_StringIndex += step_val989)
        {
          if (0 != (int(hv_StringIndex==((hv_SegExcludeClassIDs.TupleLength())-1))))
          {
            hv_StringSegExcludeClassIDs += HTuple(hv_SegExcludeClassIDs[hv_StringIndex]);
          }
          else
          {
            hv_StringSegExcludeClassIDs = (hv_StringSegExcludeClassIDs+HTuple(hv_SegExcludeClassIDs[hv_StringIndex]))+HTuple(", ");
          }
        }
        }
        if (0 != (int(hv_SegExcludeClassIDs!=HTuple())))
        {
          hv_Text[hv_Text.TupleLength()] = ("- (excluded classID(s) "+hv_StringSegExcludeClassIDs)+" from visualization)";
        }
        //
        get_child_window(hv_HeightImage, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_WindowImageRatio, 
            &hv_PrevWindowCoordinates);
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", 
              (HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ImageClassIDsIndices]))).TupleConcat(((HTuple("white").Append("white")).Append("white"))), 
              "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_diff"))))
    {
      //
      //Difference of ground truth and result segmentation on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_segmentation_image_ground_truth(&ho_SegmentationImagGroundTruth, hv_SampleKeys, 
          hv_DLSample);
      get_segmentation_image_result(&ho_SegmentationImageResult, hv_ResultKeys, hv_DLResult);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          0, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, hv_WindowHandleDict, 
          HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, &hv_WindowImageRatio, 
          &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      AbsDiffImage(ho_SegmentationImagGroundTruth, ho_SegmentationImageResult, &ho_ImageAbsDiff, 
          1);
      MinMaxGray(ho_SegmentationImageResult, ho_ImageAbsDiff, 0, &hv_Min, &hv_Max, 
          &hv_Range);
      if (0 != (int(hv_Min!=hv_Max)))
      {
        Threshold(ho_ImageAbsDiff, &ho_DiffRegion, 0.00001, hv_Max);
        if (HDevWindowStack::IsOpen())
          SetColor(HDevWindowStack::GetActive(),"#ff0000"+hv_SegTransparency);
        if (HDevWindowStack::IsOpen())
          DispObj(ho_DiffRegion, HDevWindowStack::GetActive());
      }
      else
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),"No difference found.", "window", 
              "top", "left", "black", HTuple(), HTuple());
      }
      if (0 != hv_ShowBottomDesc)
      {
        hv_Text = "Difference of ground truth and result segmentation "+hv_ImageIDStringBraces;
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left", 
              "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_weight_map"))))
    {
      //
      //Weight map on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_weight_image(&ho_ImageWeight, hv_SampleKeys, hv_DLSample);
      //
      if (0 != (int(hv_SegMaxWeight==0)))
      {
        //Calculate SegMaxWeight if not given in GenParam.
        MinMaxGray(ho_ImageWeight, ho_ImageWeight, 0, &hv_MinWeight, &hv_SegMaxWeight, 
            &hv_Range);
      }
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          hv_MapColorBarWidth, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, 
          hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, 
          &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      dev_display_weight_regions(ho_ImageWeight, hv_MapTransparency, hv_SegMaxWeight, 
          &hv_WeightsColors);
      dev_display_map_color_bar(hv_WidthImage, hv_HeightImage, hv_MapColorBarWidth, 
          hv_WeightsColors, hv_SegMaxWeight, hv_WindowImageRatio, hv_CurrentWindowHandle);
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),"Weight map "+hv_ImageIDStringBraces, 
              "window", "bottom", "left", "white", "box", "false");
      }
    }
    else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_confidence_map"))))
    {
      //
      //Segmentation confidence map on image.
      get_image(&ho_Image, hv_SampleKeys, hv_DLSample);
      get_confidence_image(&ho_ImageConfidence, hv_ResultKeys, hv_DLResult);
      //
      //Get or open next window.
      GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
      get_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
          hv_MapColorBarWidth, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, 
          hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle, 
          &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
      //
      //Visualization.
      if (HDevWindowStack::IsOpen())
        DispObj(ho_Image, HDevWindowStack::GetActive());
      dev_display_confidence_regions(ho_ImageConfidence, hv_MapTransparency, &hv_ConfidenceColors);
      dev_display_map_color_bar(hv_WidthImage, hv_HeightImage, hv_MapColorBarWidth, 
          hv_ConfidenceColors, 1.0, hv_WindowImageRatio, hv_CurrentWindowHandle);
      if (0 != hv_ShowBottomDesc)
      {
        if (HDevWindowStack::IsOpen())
          DispText(HDevWindowStack::GetActive(),"Confidence map "+hv_ImageIDStringBraces, 
              "window", "bottom", "left", "white", "box", "false");
      }
    }
    else
    {
      //Reset flush buffer of existing windows before throwing an exception.
      GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeys);
      {
      HTuple end_val1071 = (hv_WindowHandleKeys.TupleLength())-1;
      HTuple step_val1071 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val1071, step_val1071); hv_Index += step_val1071)
      {
        //Only consider the WindowHandleKeys that are needed for the current visualization.
        hv_Indices = hv_KeysForDisplay.TupleFind(HTuple(hv_WindowHandleKeys[hv_Index]));
        if (0 != (HTuple(int(hv_Indices!=-1)).TupleAnd(int(hv_Indices!=HTuple()))))
        {
          GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]), 
              &hv_WindowHandles);
          {
          HTuple end_val1076 = (hv_WindowHandles.TupleLength())-1;
          HTuple step_val1076 = 1;
          for (hv_WindowIndex=0; hv_WindowIndex.Continue(end_val1076, step_val1076); hv_WindowIndex += step_val1076)
          {
            //Reset values of windows that have been changed temporarily.
            SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", HTuple(hv_FlushValues[hv_Index]));
          }
          }
        }
      }
      }
      throw HException("Key for display unknown: "+HTuple(hv_KeysForDisplay[hv_KeyIndex]));
    }
  }
  }
  //
  //Display results.
  GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeysNew);
  {
  HTuple end_val1088 = (hv_WindowHandleKeysNew.TupleLength())-1;
  HTuple step_val1088 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val1088, step_val1088); hv_Index += step_val1088)
  {
    //Only consider the WindowHandleKeys that are needed for the current visualization.
    hv_KeyIndex = hv_KeysForDisplay.TupleFind(HTuple(hv_WindowHandleKeysNew[hv_Index]));
    if (0 != (HTuple(int(hv_KeyIndex!=-1)).TupleAnd(int(hv_KeyIndex!=HTuple()))))
    {
      GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeysNew[hv_Index]), 
          &hv_WindowHandles);
      {
      HTuple end_val1093 = (hv_WindowHandles.TupleLength())-1;
      HTuple step_val1093 = 1;
      for (hv_WindowIndex=0; hv_WindowIndex.Continue(end_val1093, step_val1093); hv_WindowIndex += step_val1093)
      {
        //Display content of window handle.
        if (0 != (int((hv_WindowHandleKeys.TupleLength())==(hv_WindowHandleKeysNew.TupleLength()))))
        {
          //Reset values of windows that have been changed temporarily.
          if (0 != (int(HTuple(hv_FlushValues[hv_WindowIndex])==HTuple("true"))))
          {
            FlushBuffer(HTuple(hv_WindowHandles[hv_WindowIndex]));
          }
          SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", HTuple(hv_FlushValues[hv_WindowIndex]));
        }
        else
        {
          //Per default, 'flush' of new windows should be set to 'true'.
          FlushBuffer(HTuple(hv_WindowHandles[hv_WindowIndex]));
          SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", "true");
        }
      }
      }
    }
  }
  }
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection
// Short Description: Display the ground truth anomaly regions of the given DLSample. 
void dev_display_ground_truth_anomaly_regions (HTuple hv_SampleKeys, HTuple hv_DLSample, 
    HTuple hv_CurrentWindowHandle, HTuple hv_LineWidth, HTuple hv_AnomalyRegionLabelColor, 
    HTuple hv_AnomalyColorTransparency, HTuple *hv_AnomalyRegionExists)
{

  // Local iconic variables
  HObject  ho_AnomalyImage, ho_AnomalyRegion;

  // Local control variables
  HTuple  hv_Red, hv_Green, hv_Blue, hv_Alpha, hv_InitialColor;
  HTuple  hv_IndexColor, hv_Color_RGBA, hv_Area;

  //
  //This procedure visualizes the ground truth anomalies
  //if there is an anomaly_ground_truth in DLSample.
  //
  //Get current set color.
  GetRgba(hv_CurrentWindowHandle, &hv_Red, &hv_Green, &hv_Blue, &hv_Alpha);
  hv_InitialColor = HTuple();
  {
  HTuple end_val7 = (hv_Red.TupleLength())-1;
  HTuple step_val7 = 1;
  for (hv_IndexColor=0; hv_IndexColor.Continue(end_val7, step_val7); hv_IndexColor += step_val7)
  {
    hv_Color_RGBA = ((("#"+(HTuple(hv_Red[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Green[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Blue[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Alpha[hv_IndexColor]).TupleString("2x"));
    TupleRegexpReplace(hv_Color_RGBA, (HTuple(" ").Append("replace_all")), "0", &hv_Color_RGBA);
    hv_InitialColor = hv_InitialColor.TupleConcat(hv_Color_RGBA);
  }
  }
  //
  if (0 != (int((hv_SampleKeys.TupleFind("anomaly_ground_truth"))!=-1)))
  {
    GetDictObject(&ho_AnomalyImage, hv_DLSample, "anomaly_ground_truth");
    Threshold(ho_AnomalyImage, &ho_AnomalyRegion, 1, 255);
    //Get non-empty regions.
    RegionFeatures(ho_AnomalyRegion, "area", &hv_Area);
    if (0 != (int(hv_Area>0)))
    {
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),hv_AnomalyRegionLabelColor+hv_AnomalyColorTransparency);
      //Display the anomaly region.
      if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),"fill");
      if (HDevWindowStack::IsOpen())
        DispObj(ho_AnomalyRegion, HDevWindowStack::GetActive());
    }
    (*hv_AnomalyRegionExists) = "true";
  }
  else
  {
    (*hv_AnomalyRegionExists) = "false";
  }
  //
  //Reset colors.
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),hv_InitialColor);
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Display the ground truth bounding boxes of DLSample. 
void dev_display_ground_truth_detection (HTuple hv_DLSample, HTuple hv_SampleKeys, 
    HTuple hv_LineWidthBbox, HTuple hv_ClassIDs, HTuple hv_BboxColors, HTuple hv_BboxLabelColor, 
    HTuple hv_WindowImageRatio, HTuple hv_TextColor, HTuple hv_ShowLabels, HTuple hv_ShowDirection, 
    HTuple hv_WindowHandle, HTuple *hv_BboxIDs)
{

  // Local iconic variables
  HObject  ho_BboxRectangle, ho_OrientationArrows;
  HObject  ho_RectangleSelected, ho_ArrowSelected;

  // Local control variables
  HTuple  hv_InstanceType, hv_BboxRow1, hv_BboxCol1;
  HTuple  hv_BboxRow2, hv_BboxCol2, hv_BboxLabels, hv_BboxRow;
  HTuple  hv_BboxCol, hv_BboxLength1, hv_BboxLength2, hv_BboxPhi;
  HTuple  hv_Text, hv_Ascent, hv_Descent, hv__, hv_TextOffset;
  HTuple  hv_LabelRow, hv_LabelCol, hv_HeadSize, hv_ContourStyle;
  HTuple  hv_Style, hv_IndexBbox, hv_ClassID, hv_TextColorClasses;

  //
  //This procedure displays the ground truth bounding boxes of DLSample.
  //
  hv_InstanceType = "rectangle1";
  if (0 != (int((hv_SampleKeys.TupleFind("bbox_row1"))!=-1)))
  {
    GetDictTuple(hv_DLSample, "bbox_row1", &hv_BboxRow1);
    GetDictTuple(hv_DLSample, "bbox_col1", &hv_BboxCol1);
    GetDictTuple(hv_DLSample, "bbox_row2", &hv_BboxRow2);
    GetDictTuple(hv_DLSample, "bbox_col2", &hv_BboxCol2);
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BboxLabels);
  }
  else if (0 != (int((hv_SampleKeys.TupleFind("bbox_phi"))!=-1)))
  {
    GetDictTuple(hv_DLSample, "bbox_row", &hv_BboxRow);
    GetDictTuple(hv_DLSample, "bbox_col", &hv_BboxCol);
    GetDictTuple(hv_DLSample, "bbox_length1", &hv_BboxLength1);
    GetDictTuple(hv_DLSample, "bbox_length2", &hv_BboxLength2);
    GetDictTuple(hv_DLSample, "bbox_phi", &hv_BboxPhi);
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BboxLabels);
    hv_InstanceType = "rectangle2";
  }
  else
  {
    throw HException("Ground truth bounding box data could not be found in DLSample.");
  }
  if (0 != (int((hv_BboxLabels.TupleLength())>0)))
  {
    //
    //Get text and text size for correct positioning of label IDs.
    if (0 != hv_ShowLabels)
    {
      hv_Text = hv_BboxLabels;
      GetStringExtents(hv_WindowHandle, hv_Text, &hv_Ascent, &hv_Descent, &hv__, 
          &hv__);
      hv_TextOffset = (hv_Ascent+hv_Descent)/hv_WindowImageRatio;
    }
    //
    //Generate bounding box XLDs.
    if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
    {
      TupleGenConst(hv_BboxRow1.TupleLength(), 0.0, &hv_BboxPhi);
      GenRectangle2ContourXld(&ho_BboxRectangle, 0.5*(hv_BboxRow1+hv_BboxRow2), 0.5*(hv_BboxCol1+hv_BboxCol2), 
          hv_BboxPhi, 0.5*(hv_BboxCol2-hv_BboxCol1), 0.5*(hv_BboxRow2-hv_BboxRow1));
      if (0 != hv_ShowLabels)
      {
        hv_LabelRow = hv_BboxRow1;
        hv_LabelCol = hv_BboxCol1;
      }
    }
    else
    {
      GenRectangle2ContourXld(&ho_BboxRectangle, hv_BboxRow, hv_BboxCol, hv_BboxPhi, 
          hv_BboxLength1, hv_BboxLength2);
      if (0 != hv_ShowLabels)
      {
        hv_LabelRow = hv_BboxRow-hv_TextOffset;
        hv_LabelCol = hv_BboxCol;
      }
      if (0 != hv_ShowDirection)
      {
        hv_HeadSize = 20.0;
        gen_arrow_contour_xld(&ho_OrientationArrows, hv_BboxRow, hv_BboxCol, hv_BboxRow-((hv_BboxLength1+hv_HeadSize)*(hv_BboxPhi.TupleSin())), 
            hv_BboxCol+((hv_BboxLength1+hv_HeadSize)*(hv_BboxPhi.TupleCos())), hv_HeadSize, 
            hv_HeadSize);
      }
    }
    //
    //Collect the ClassIDs of the bounding boxes.
    TupleGenConst(hv_BboxLabels.TupleLength(), 0, &(*hv_BboxIDs));
    //
    //Draw the bounding boxes.
    GetContourStyle(hv_WindowHandle, &hv_ContourStyle);
    if (HDevWindowStack::IsOpen())
      SetContourStyle(HDevWindowStack::GetActive(),"stroke_and_fill");
    GetLineStyle(hv_WindowHandle, &hv_Style);
    if (HDevWindowStack::IsOpen())
      SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidthBbox);
    {
    HTuple end_val58 = (hv_BboxLabels.TupleLength())-1;
    HTuple step_val58 = 1;
    for (hv_IndexBbox=0; hv_IndexBbox.Continue(end_val58, step_val58); hv_IndexBbox += step_val58)
    {
      SelectObj(ho_BboxRectangle, &ho_RectangleSelected, hv_IndexBbox+1);
      hv_ClassID = hv_ClassIDs.TupleFind(HTuple(hv_BboxLabels[hv_IndexBbox]));
      (*hv_BboxIDs)[hv_IndexBbox] = hv_ClassID;
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_BboxColors[hv_ClassID])+"60");
      if (HDevWindowStack::IsOpen())
        DispObj(ho_RectangleSelected, HDevWindowStack::GetActive());
      if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(hv_ShowDirection)))
      {
        SelectObj(ho_OrientationArrows, &ho_ArrowSelected, hv_IndexBbox+1);
        if (HDevWindowStack::IsOpen())
          SetColor(HDevWindowStack::GetActive(),HTuple(hv_BboxColors[hv_ClassID])+"FF");
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ArrowSelected, HDevWindowStack::GetActive());
        if (HDevWindowStack::IsOpen())
          SetColor(HDevWindowStack::GetActive(),HTuple(hv_BboxColors[hv_ClassID])+"60");
      }
    }
    }
    //
    //Write text to the bounding boxes.
    if (0 != hv_ShowLabels)
    {
      //For better visibility the text is displayed after all bounding boxes are drawn.
      //Select text color.
      if (0 != (int(hv_TextColor==HTuple(""))))
      {
        hv_TextColorClasses = HTuple(hv_BboxColors[(*hv_BboxIDs)]);
      }
      else
      {
        TupleGenConst((*hv_BboxIDs).TupleLength(), hv_TextColor, &hv_TextColorClasses);
      }
      //Display text.
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_BboxLabels, "image", hv_LabelRow, 
            hv_LabelCol, hv_TextColorClasses, ((HTuple("box_color").Append("shadow")).Append("border_radius")), 
            hv_BboxLabelColor.TupleConcat((HTuple("false").Append(0))));
    }
    //
    if (HDevWindowStack::IsOpen())
      SetContourStyle(HDevWindowStack::GetActive(),hv_ContourStyle);
    SetLineStyle(hv_WindowHandle, hv_Style);
  }
  else
  {
    //Do nothing if there are no ground truth bounding boxes.
    (*hv_BboxIDs) = HTuple();
  }
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Display a color bar next to an image. 
void dev_display_map_color_bar (HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_MapColorBarWidth, 
    HTuple hv_Colors, HTuple hv_MaxValue, HTuple hv_WindowImageRatio, HTuple hv_WindowHandle)
{

  // Local iconic variables
  HObject  ho_Rectangle;

  // Local control variables
  HTuple  hv_ClipRegion, hv_ColorIndex, hv_RectHeight;
  HTuple  hv_DrawMode, hv_Row, hv_Row1, hv_Column1, hv_Row2;
  HTuple  hv_Column2, hv__, hv_TextHeight, hv_Index, hv_Text;

  //
  //This procedure displays a color bar next to the image
  //specified with ImageWidth and ImageHeight.
  //
  GetSystem("clip_region", &hv_ClipRegion);
  SetSystem("clip_region", "false");
  //
  //Display the color bar.
  hv_ColorIndex = 0;
  hv_RectHeight = (1.0*hv_ImageHeight)/(hv_Colors.TupleLength());
  //Set draw mode to fill
  GetDraw(hv_WindowHandle, &hv_DrawMode);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"fill");
  {
  HTuple end_val13 = 0;
  HTuple step_val13 = -hv_RectHeight;
  for (hv_Row=hv_ImageHeight-1; hv_Row.Continue(end_val13, step_val13); hv_Row += step_val13)
  {
    //The color bar consists of multiple rectangle1.
    hv_Row1 = hv_Row-hv_RectHeight;
    hv_Column1 = hv_ImageWidth+(20/hv_WindowImageRatio);
    hv_Row2 = hv_Row;
    hv_Column2 = (hv_ImageWidth+20)+(hv_MapColorBarWidth/hv_WindowImageRatio);
    GenRectangle1(&ho_Rectangle, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_ColorIndex]));
    if (HDevWindowStack::IsOpen())
      DispObj(ho_Rectangle, HDevWindowStack::GetActive());
    hv_ColorIndex += 1;
  }
  }
  //
  //Display labels for color bar.
  GetStringExtents(hv_WindowHandle, "0123456789", &hv__, &hv__, &hv__, &hv_TextHeight);
  for (hv_Index=0; hv_Index<=1; hv_Index+=0.2)
  {
    hv_Text = (hv_MaxValue-(hv_Index*hv_MaxValue)).TupleString(".1f");
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_Text, "image", hv_Index*(hv_ImageHeight-(2*(hv_TextHeight/hv_WindowImageRatio))), 
          hv_ImageWidth+(40/hv_WindowImageRatio), "black", "box", "false");
  }
  //
  SetSystem("clip_region", hv_ClipRegion);
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
  return;
}

// Chapter: Deep Learning / Anomaly Detection
// Short Description: Display the detected anomaly regions. 
void dev_display_result_anomaly_regions (HObject ho_AnomalyRegion, HTuple hv_CurrentWindowHandle, 
    HTuple hv_LineWidth, HTuple hv_AnomalyRegionResultColor)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Red, hv_Green, hv_Blue, hv_Alpha, hv_InitialColor;
  HTuple  hv_IndexColor, hv_Color_RGBA, hv_Area;

  //
  //This procedure displays the result anomaly regions.
  //
  //Get current set color.
  GetRgba(hv_CurrentWindowHandle, &hv_Red, &hv_Green, &hv_Blue, &hv_Alpha);
  hv_InitialColor = HTuple();
  {
  HTuple end_val6 = (hv_Red.TupleLength())-1;
  HTuple step_val6 = 1;
  for (hv_IndexColor=0; hv_IndexColor.Continue(end_val6, step_val6); hv_IndexColor += step_val6)
  {
    hv_Color_RGBA = ((("#"+(HTuple(hv_Red[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Green[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Blue[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Alpha[hv_IndexColor]).TupleString("2x"));
    TupleRegexpReplace(hv_Color_RGBA, (HTuple(" ").Append("replace_all")), "0", &hv_Color_RGBA);
    hv_InitialColor = hv_InitialColor.TupleConcat(hv_Color_RGBA);
  }
  }
  //
  //Display anomaly regions.
  //Get non-empty regions.
  RegionFeatures(ho_AnomalyRegion, "area", &hv_Area);
  //
  //Display all non-empty class regions in distinct colors.
  if (0 != (int(hv_Area>0)))
  {
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_AnomalyRegionResultColor);
    if (HDevWindowStack::IsOpen())
      SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth);
    if (HDevWindowStack::IsOpen())
      SetDraw(HDevWindowStack::GetActive(),"margin");
    if (HDevWindowStack::IsOpen())
      DispObj(ho_AnomalyRegion, HDevWindowStack::GetActive());
  }
  //
  //Reset colors.
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),hv_InitialColor);
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Display result bounding boxes. 
void dev_display_result_detection (HTuple hv_DLResult, HTuple hv_ResultKeys, HTuple hv_LineWidthBbox, 
    HTuple hv_ClassIDs, HTuple hv_TextConf, HTuple hv_Colors, HTuple hv_BoxLabelColor, 
    HTuple hv_WindowImageRatio, HTuple hv_TextPositionRow, HTuple hv_TextColor, HTuple hv_ShowLabels, 
    HTuple hv_ShowDirection, HTuple hv_WindowHandle, HTuple *hv_BboxClassIndices)
{

  // Local iconic variables
  HObject  ho_BboxRectangle, ho_OrientationArrows;
  HObject  ho_RectangleSelected, ho_ArrowSelected;

  // Local control variables
  HTuple  hv_InstanceType, hv_BboxRow1, hv_BboxCol1;
  HTuple  hv_BboxRow2, hv_BboxCol2, hv_BboxClasses, hv_BboxRow;
  HTuple  hv_BboxCol, hv_BboxLength1, hv_BboxLength2, hv_BboxPhi;
  HTuple  hv_Text, hv_Ascent, hv_Descent, hv__, hv_TextOffset;
  HTuple  hv_LabelRowTop, hv_LabelRowBottom, hv_LabelCol;
  HTuple  hv_HeadSize, hv_ContourStyle, hv_Style, hv_IndexBbox;
  HTuple  hv_ClassID, hv_LineWidth, hv_TextColorClasses, hv_LabelRow;

  //
  //This procedure displays the bounding boxes defined by DLResult.
  //The ClassIDs are necessary to display bounding boxes from the same class
  //always with the same color.
  //
  hv_InstanceType = "rectangle1";
  if (0 != (int((hv_ResultKeys.TupleFind("bbox_row1"))!=-1)))
  {
    GetDictTuple(hv_DLResult, "bbox_row1", &hv_BboxRow1);
    GetDictTuple(hv_DLResult, "bbox_col1", &hv_BboxCol1);
    GetDictTuple(hv_DLResult, "bbox_row2", &hv_BboxRow2);
    GetDictTuple(hv_DLResult, "bbox_col2", &hv_BboxCol2);
    GetDictTuple(hv_DLResult, "bbox_class_id", &hv_BboxClasses);
  }
  else if (0 != (int((hv_ResultKeys.TupleFind("bbox_phi"))!=-1)))
  {
    GetDictTuple(hv_DLResult, "bbox_row", &hv_BboxRow);
    GetDictTuple(hv_DLResult, "bbox_col", &hv_BboxCol);
    GetDictTuple(hv_DLResult, "bbox_length1", &hv_BboxLength1);
    GetDictTuple(hv_DLResult, "bbox_length2", &hv_BboxLength2);
    GetDictTuple(hv_DLResult, "bbox_phi", &hv_BboxPhi);
    GetDictTuple(hv_DLResult, "bbox_class_id", &hv_BboxClasses);
    hv_InstanceType = "rectangle2";
  }
  else
  {
    throw HException("Result bounding box data could not be found in DLResult.");
  }
  //
  if (0 != (int((hv_BboxClasses.TupleLength())>0)))
  {
    //
    //Get text and text size for correct positioning of result class IDs.
    if (0 != hv_ShowLabels)
    {
      hv_Text = hv_BboxClasses+hv_TextConf;
      GetStringExtents(hv_WindowHandle, hv_Text, &hv_Ascent, &hv_Descent, &hv__, 
          &hv__);
      hv_TextOffset = (hv_Ascent+hv_Descent)/hv_WindowImageRatio;
    }
    //
    //Generate bounding box XLDs.
    if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
    {
      TupleGenConst(hv_BboxRow1.TupleLength(), 0.0, &hv_BboxPhi);
      GenRectangle2ContourXld(&ho_BboxRectangle, 0.5*(hv_BboxRow1+hv_BboxRow2), 0.5*(hv_BboxCol1+hv_BboxCol2), 
          hv_BboxPhi, 0.5*(hv_BboxCol2-hv_BboxCol1), 0.5*(hv_BboxRow2-hv_BboxRow1));
      if (0 != hv_ShowLabels)
      {
        hv_LabelRowTop = hv_BboxRow1;
        hv_LabelRowBottom = hv_BboxRow2-hv_TextOffset;
        hv_LabelCol = hv_BboxCol1;
      }
    }
    else
    {
      GenRectangle2ContourXld(&ho_BboxRectangle, hv_BboxRow, hv_BboxCol, hv_BboxPhi, 
          hv_BboxLength1, hv_BboxLength2);
      if (0 != hv_ShowLabels)
      {
        hv_LabelRowTop = hv_BboxRow-hv_TextOffset;
        hv_LabelRowBottom = hv_BboxRow;
        hv_LabelCol = hv_BboxCol;
      }
      if (0 != hv_ShowDirection)
      {
        hv_HeadSize = 20.0;
        gen_arrow_contour_xld(&ho_OrientationArrows, hv_BboxRow, hv_BboxCol, hv_BboxRow-((hv_BboxLength1+hv_HeadSize)*(hv_BboxPhi.TupleSin())), 
            hv_BboxCol+((hv_BboxLength1+hv_HeadSize)*(hv_BboxPhi.TupleCos())), hv_HeadSize, 
            hv_HeadSize);
      }
    }
    //
    GetContourStyle(hv_WindowHandle, &hv_ContourStyle);
    if (HDevWindowStack::IsOpen())
      SetContourStyle(HDevWindowStack::GetActive(),"stroke");
    GetLineStyle(hv_WindowHandle, &hv_Style);
    if (HDevWindowStack::IsOpen())
      SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidthBbox);
    //
    //Collect ClassIDs of the bounding boxes.
    TupleGenConst(hv_BboxClasses.TupleLength(), 0, &(*hv_BboxClassIndices));
    //
    //Draw bounding boxes.
    {
    HTuple end_val64 = (hv_BboxClasses.TupleLength())-1;
    HTuple step_val64 = 1;
    for (hv_IndexBbox=0; hv_IndexBbox.Continue(end_val64, step_val64); hv_IndexBbox += step_val64)
    {
      SelectObj(ho_BboxRectangle, &ho_RectangleSelected, hv_IndexBbox+1);
      hv_ClassID = hv_ClassIDs.TupleFind(HTuple(hv_BboxClasses[hv_IndexBbox]));
      (*hv_BboxClassIndices)[hv_IndexBbox] = hv_ClassID;
      GetLineWidth(hv_WindowHandle, &hv_LineWidth);
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),(hv_LineWidth+2).TupleInt());
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),"black");
      if (HDevWindowStack::IsOpen())
        DispObj(ho_RectangleSelected, HDevWindowStack::GetActive());
      if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(hv_ShowDirection)))
      {
        SelectObj(ho_OrientationArrows, &ho_ArrowSelected, hv_IndexBbox+1);
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ArrowSelected, HDevWindowStack::GetActive());
      }
      if (HDevWindowStack::IsOpen())
        SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth.TupleInt());
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_ClassID]));
      if (HDevWindowStack::IsOpen())
        DispObj(ho_RectangleSelected, HDevWindowStack::GetActive());
      if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(hv_ShowDirection)))
      {
        if (HDevWindowStack::IsOpen())
          DispObj(ho_ArrowSelected, HDevWindowStack::GetActive());
      }
    }
    }
    //
    //Draw text of bounding boxes.
    if (0 != hv_ShowLabels)
    {
      //For better visibility the text is displayed after all bounding boxes are drawn.
      //Get text and text size for correct positioning of result class IDs.
      hv_Text = hv_BboxClasses+hv_TextConf;
      //Select text color.
      if (0 != (int(hv_TextColor==HTuple(""))))
      {
        hv_TextColorClasses = HTuple(hv_Colors[(*hv_BboxClassIndices)]);
      }
      else
      {
        TupleGenConst((*hv_BboxClassIndices).TupleLength(), hv_TextColor, &hv_TextColorClasses);
      }
      //Select correct position of the text.
      hv_LabelRow = hv_LabelRowTop;
      if (0 != (int(hv_TextPositionRow==HTuple("bottom"))))
      {
        hv_LabelRow = hv_LabelRowBottom;
      }
      //Display text.
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "image", hv_LabelRow, hv_LabelCol, 
            hv_TextColorClasses, ((HTuple("box_color").Append("shadow")).Append("border_radius")), 
            hv_BoxLabelColor.TupleConcat((HTuple("false").Append(0))));
    }
    //
    if (HDevWindowStack::IsOpen())
      SetContourStyle(HDevWindowStack::GetActive(),hv_ContourStyle);
    SetLineStyle(hv_WindowHandle, hv_Style);
  }
  else
  {
    //Do nothing if no results are present.
    (*hv_BboxClassIndices) = HTuple();
  }
  //
  return;
}

// Chapter: Graphics / Output
// Short Description: Display the ground truth/result segmentation as regions. 
void dev_display_segmentation_regions (HObject ho_SegmentationImage, HTuple hv_ClassIDs, 
    HTuple hv_ColorsSegmentation, HTuple hv_ExcludeClassIDs, HTuple *hv_ImageClassIDs)
{

  // Local iconic variables
  HObject  ho_Regions, ho_SelectedRegion;

  // Local control variables
  HTuple  hv_IncludedClassIDs, hv_Area, hv_Index;
  HTuple  hv_ClassID, hv_IndexColor;

  //
  //This procedure displays the ground truth/result segmentation
  //given in SegmentationImage as regions. The ClassIDs are necessary to
  //display ground truth/result segmentations from the same class
  //always with the same color. It is possible to exclude certain ClassIDs
  //from being displayed. The displayed classes are returned in ImageClassIDs.
  //
  //
  //Remove excluded class IDs from the list.
  hv_IncludedClassIDs = hv_ClassIDs.TupleDifference(hv_ExcludeClassIDs);
  //
  //Get a region for each class ID.
  Threshold(ho_SegmentationImage, &ho_Regions, hv_IncludedClassIDs, hv_IncludedClassIDs);
  //
  //Get classes with non-empty regions.
  RegionFeatures(ho_Regions, "area", &hv_Area);
  if (0 != (int((hv_Area.TupleLength())!=(hv_IncludedClassIDs.TupleLength()))))
  {
    throw HException("No equal number of class IDs and segmentation regions.");
  }
  TupleSelectMask(hv_IncludedClassIDs, hv_Area.TupleGreaterElem(0), &(*hv_ImageClassIDs));
  //
  //Display all non-empty class regions in distinct colors.
  {
  HTuple end_val22 = (hv_IncludedClassIDs.TupleLength())-1;
  HTuple step_val22 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val22, step_val22); hv_Index += step_val22)
  {
    if (0 != (int(HTuple(hv_Area[hv_Index])>0)))
    {
      //Use class ID to determine region color.
      hv_ClassID = HTuple(hv_IncludedClassIDs[hv_Index]);
      hv_IndexColor = hv_ClassIDs.TupleFindFirst(hv_ClassID);
      if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),HTuple(hv_ColorsSegmentation[hv_IndexColor]));
      //Display the segmentation region.
      SelectObj(ho_Regions, &ho_SelectedRegion, hv_Index+1);
      if (HDevWindowStack::IsOpen())
        DispObj(ho_SelectedRegion, HDevWindowStack::GetActive());
    }
  }
  }
  return;
}

// Chapter: Graphics / Output
// Short Description: Display a map of weights. 
void dev_display_weight_regions (HObject ho_ImageWeight, HTuple hv_DrawTransparency, 
    HTuple hv_SegMaxWeight, HTuple *hv_Colors)
{

  // Local iconic variables
  HObject  ho_Domain, ho_WeightsRegion;

  // Local control variables
  HTuple  hv_NumColors, hv_WeightsColorsAlpha, hv_Rows;
  HTuple  hv_Columns, hv_GrayVal, hv_GrayValWeight, hv_ColorIndex;
  HTuple  hv_ClassColor;

  //
  //This procedure displays a map of the weights
  //given in ImageWeight as regions.
  //The transparency can be adjusted.
  //The used colors are returned.
  //
  //Define colors.
  hv_NumColors = 20;
  get_distinct_colors_dl_visualization(hv_NumColors, 0, 0, 160, &(*hv_Colors));
  TupleInverse((*hv_Colors), &(*hv_Colors));
  hv_WeightsColorsAlpha = (*hv_Colors)+hv_DrawTransparency;
  //
  //Get gay values of ImageWeight.
  GetDomain(ho_ImageWeight, &ho_Domain);
  GetRegionPoints(ho_Domain, &hv_Rows, &hv_Columns);
  GetGrayval(ho_ImageWeight, hv_Rows, hv_Columns, &hv_GrayVal);
  //
  //Check that the gray values of the image
  //are below the specified maximum.
  if (0 != (int((hv_GrayVal.TupleMax())>hv_SegMaxWeight)))
  {
    throw HException(((("The maximum weight ("+(hv_GrayVal.TupleMax()))+") in the weight image is greater than the given SegMaxWeight (")+hv_SegMaxWeight)+").");
  }
  //
  while (0 != (int(hv_GrayVal!=HTuple())))
  {
    //Go through all gray value 'groups',
    //starting from the maximum.
    hv_GrayValWeight = hv_GrayVal.TupleMax();
    hv_GrayVal = hv_GrayVal.TupleRemove(hv_GrayVal.TupleFind(hv_GrayValWeight));
    Threshold(ho_ImageWeight, &ho_WeightsRegion, hv_GrayValWeight, hv_GrayValWeight);
    //
    //Visualize the respective group.
    hv_ColorIndex = (((hv_GrayValWeight/hv_SegMaxWeight)*(hv_NumColors-1)).TupleCeil()).TupleInt();
    hv_ClassColor = HTuple(hv_WeightsColorsAlpha[hv_ColorIndex]);
    if (HDevWindowStack::IsOpen())
      SetColor(HDevWindowStack::GetActive(),hv_ClassColor);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_WeightsRegion, HDevWindowStack::GetActive());
  }
  return;
}

// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size. 
void dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width, 
    HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
  HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
  HTuple  hv_WindowWidth, hv_WindowHeight;

  //This procedure open a new graphic window
  //such that it fits into the limits specified by WidthLimit
  //and HeightLimit, but also maintains the correct aspect ratio
  //given by Width and Height.
  //
  //If it is impossible to match the minimum and maximum extent requirements
  //at the same time (f.e. if the image is very long but narrow),
  //the maximum value gets a higher priority.
  //
  //Parse input tuple WidthLimit
  if (0 != (HTuple(int((hv_WidthLimit.TupleLength())==0)).TupleOr(int(hv_WidthLimit<0))))
  {
    hv_MinWidth = 500;
    hv_MaxWidth = 800;
  }
  else if (0 != (int((hv_WidthLimit.TupleLength())==1)))
  {
    hv_MinWidth = 0;
    hv_MaxWidth = hv_WidthLimit;
  }
  else
  {
    hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
    hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
  }
  //Parse input tuple HeightLimit
  if (0 != (HTuple(int((hv_HeightLimit.TupleLength())==0)).TupleOr(int(hv_HeightLimit<0))))
  {
    hv_MinHeight = 400;
    hv_MaxHeight = 600;
  }
  else if (0 != (int((hv_HeightLimit.TupleLength())==1)))
  {
    hv_MinHeight = 0;
    hv_MaxHeight = hv_HeightLimit;
  }
  else
  {
    hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
    hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
  }
  //
  //Test, if window size has to be changed.
  hv_ResizeFactor = 1;
  //First, expand window to the minimum extents (if necessary).
  if (0 != (HTuple(int(hv_MinWidth>hv_Width)).TupleOr(int(hv_MinHeight>hv_Height))))
  {
    hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
  }
  hv_TempWidth = hv_Width*hv_ResizeFactor;
  hv_TempHeight = hv_Height*hv_ResizeFactor;
  //Then, shrink window to maximum extents (if necessary).
  if (0 != (HTuple(int(hv_MaxWidth<hv_TempWidth)).TupleOr(int(hv_MaxHeight<hv_TempHeight))))
  {
    hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
  }
  hv_WindowWidth = hv_Width*hv_ResizeFactor;
  hv_WindowHeight = hv_Height*hv_ResizeFactor;
  //Resize window
  SetWindowAttr("background_color","black");
  OpenWindow(hv_Row,hv_Column,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandle));
  HDevWindowStack::Push((*hv_WindowHandle));
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  return;
}

// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var and dev_update_window to 'off'. 
void dev_update_off ()
{

  //This procedure sets different update settings to 'off'.
  //This is useful to get the best performance and reduce overhead.
  //
  // dev_update_pc(...); only in hdevelop
  // dev_update_var(...); only in hdevelop
  // dev_update_window(...); only in hdevelop
  return;
}

// Chapter: XLD / Creation
// Short Description: Creates an arrow shaped XLD contour. 
void gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1, 
    HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth)
{

  // Local iconic variables
  HObject  ho_TempArrow;

  // Local control variables
  HTuple  hv_Length, hv_ZeroLengthIndices, hv_DR;
  HTuple  hv_DC, hv_HalfHeadWidth, hv_RowP1, hv_ColP1, hv_RowP2;
  HTuple  hv_ColP2, hv_Index;

  //This procedure generates arrow shaped XLD contours,
  //pointing from (Row1, Column1) to (Row2, Column2).
  //If starting and end point are identical, a contour consisting
  //of a single point is returned.
  //
  //input parameteres:
  //Row1, Column1: Coordinates of the arrows' starting points
  //Row2, Column2: Coordinates of the arrows' end points
  //HeadLength, HeadWidth: Size of the arrow heads in pixels
  //
  //output parameter:
  //Arrow: The resulting XLD contour
  //
  //The input tuples Row1, Column1, Row2, and Column2 have to be of
  //the same length.
  //HeadLength and HeadWidth either have to be of the same length as
  //Row1, Column1, Row2, and Column2 or have to be a single element.
  //If one of the above restrictions is violated, an error will occur.
  //
  //
  //Init
  GenEmptyObj(&(*ho_Arrow));
  //
  //Calculate the arrow length
  DistancePp(hv_Row1, hv_Column1, hv_Row2, hv_Column2, &hv_Length);
  //
  //Mark arrows with identical start and end point
  //(set Length to -1 to avoid division-by-zero exception)
  hv_ZeroLengthIndices = hv_Length.TupleFind(0);
  if (0 != (int(hv_ZeroLengthIndices!=-1)))
  {
    hv_Length[hv_ZeroLengthIndices] = -1;
  }
  //
  //Calculate auxiliary variables.
  hv_DR = (1.0*(hv_Row2-hv_Row1))/hv_Length;
  hv_DC = (1.0*(hv_Column2-hv_Column1))/hv_Length;
  hv_HalfHeadWidth = hv_HeadWidth/2.0;
  //
  //Calculate end points of the arrow head.
  hv_RowP1 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))+(hv_HalfHeadWidth*hv_DC);
  hv_ColP1 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))-(hv_HalfHeadWidth*hv_DR);
  hv_RowP2 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))-(hv_HalfHeadWidth*hv_DC);
  hv_ColP2 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))+(hv_HalfHeadWidth*hv_DR);
  //
  //Finally create output XLD contour for each input point pair
  {
  HTuple end_val45 = (hv_Length.TupleLength())-1;
  HTuple step_val45 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val45, step_val45); hv_Index += step_val45)
  {
    if (0 != (int(HTuple(hv_Length[hv_Index])==-1)))
    {
      //Create_ single points for arrows with identical start and end point
      GenContourPolygonXld(&ho_TempArrow, HTuple(hv_Row1[hv_Index]), HTuple(hv_Column1[hv_Index]));
    }
    else
    {
      //Create arrow contour
      GenContourPolygonXld(&ho_TempArrow, ((((HTuple(hv_Row1[hv_Index]).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP1[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP2[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index])), 
          ((((HTuple(hv_Column1[hv_Index]).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP1[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP2[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index])));
    }
    ConcatObj((*ho_Arrow), ho_TempArrow, &(*ho_Arrow));
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: The procedure returns DLSample dicts for given sample indices of a DLDataset. 
void gen_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple hv_RestrictKeysDLSample, 
    HTuple hv_GenParam, HTuple *hv_DLSampleBatch)
{

  // Local iconic variables
  HObject  ho_ImageRaw, ho_ImageAnomaly, ho_RegionAnomaly;
  HObject  ho_ImageSegmentation;

  // Local control variables
  HTuple  hv_ImageDir, hv_DLSamples, hv_MinIndex;
  HTuple  hv_MaxIndex, hv_InstanceType, hv_IgnoreMissing;
  HTuple  hv_GenParamName, hv_IndexGenParam, hv_DLSamplesProc;
  HTuple  hv_BboxKeyList, hv_ImageIndex, hv_DLSample, hv_ImageID;
  HTuple  hv_ImageName, hv_FileName, hv_Exception, hv_AnomalyLabelExists;
  HTuple  hv_AnomalyLabel, hv_AnomalyFileNameExists, hv_AnomalyDir;
  HTuple  hv_AnomalyFileName, hv_ExceptionImageAnomaly, hv_ExceptionRegionAnomaly;
  HTuple  hv_Width, hv_Height, hv_ImageLabelIDExists, hv_ImageLabelID;
  HTuple  hv_BboxExists, hv_BboxLabels, hv_KeysExist, hv_MissingKeyIndices;
  HTuple  hv_IndexParam, hv_BboxCoord, hv_SegKeyExists, hv_SegmentationDir;
  HTuple  hv_SegmentationName, hv_ExceptionSegmentation;

  //
  //This procedure creates DLSampleBatch, a tuple of DLSample dictionaries, with
  //the image data for each DLDataset sample, that was selected through SampleIndices.
  //The keys to be transferred can be restricted using RestrictKeysDLSample,
  //which is switched off ('off') by default.
  //The procedure returns all generated DLSample dictionaries in the tuple
  //DLSampleBatch.
  //Setting the GenParam 'ignore_missing_labels' controls whether an error is thrown,
  //if no ground truth annotation information is available for a given image.
  //
  //Get the image directory.
  GetDictTuple(hv_DLDataset, "image_dir", &hv_ImageDir);
  //
  //Get the samples from the DLDataset.
  GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
  //
  //Check the input values.
  //
  //Check that the given indices are valid.
  TupleMin(hv_SampleIndices, &hv_MinIndex);
  TupleMax(hv_SampleIndices, &hv_MaxIndex);
  if (0 != (HTuple(int(hv_MinIndex<0)).TupleOr(int(hv_MaxIndex>((hv_DLSamples.TupleLength())-1)))))
  {
    throw HException("The given SampleIndices are not within the range of available samples in DLDataset.");
  }
  //
  //Check if the given method is valid.
  if (0 != (int((hv_RestrictKeysDLSample.TupleLength())==1)))
  {
    if (0 != (int((HTuple((((((HTuple("anomaly_detection").Append("detection")).Append("segmentation")).Append("classification")).Append("image_only")).Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())==-1)))
    {
      throw HException("Unknown RestrictKeysDLSample : "+hv_RestrictKeysDLSample);
    }
  }
  else
  {
    throw HException("RestrictKeysDLSample must be specified by one string.");
  }
  //
  //Generic Parameters.
  //Set default values.
  hv_InstanceType = "rectangle1";
  //For missing labels an error is thrown.
  if (0 != (int(hv_RestrictKeysDLSample==HTuple("off"))))
  {
    hv_IgnoreMissing = 1;
  }
  else
  {
    hv_IgnoreMissing = 0;
  }
  //
  //Transfer generic parameters.
  if (0 != (int(hv_GenParam!=HTuple())))
  {
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamName);
    {
    HTuple end_val47 = (hv_GenParamName.TupleLength())-1;
    HTuple step_val47 = 1;
    for (hv_IndexGenParam=0; hv_IndexGenParam.Continue(end_val47, step_val47); hv_IndexGenParam += step_val47)
    {
      if (0 != (int(HTuple(hv_GenParamName[hv_IndexGenParam])==HTuple("ignore_missing_labels"))))
      {
        GetDictTuple(hv_GenParam, "ignore_missing_labels", &hv_IgnoreMissing);
        if (0 != (HTuple(HTuple(int(hv_IgnoreMissing==1)).TupleOr(int(hv_IgnoreMissing==0))).TupleNot()))
        {
          throw HException("The GenParam ignore_missing_labels must be true or false.");
        }
      }
      else if (0 != (int(HTuple(hv_GenParamName[hv_IndexGenParam])==HTuple("instance_type"))))
      {
        if (0 != (int((HTuple((HTuple("detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())==-1)))
        {
          throw HException("The GenParam instance_type can only be set for RestrictKeysDLSample detection or off.");
        }
        GetDictTuple(hv_GenParam, "instance_type", &hv_InstanceType);
        if (0 != (int((HTuple((HTuple("rectangle1").Append("rectangle2")).TupleFind(hv_InstanceType)).TupleMax())==-1)))
        {
          throw HException("The GenParam instance_type must be either 'rectangle1' or 'rectangle2'.");
        }
      }
      else
      {
        throw HException("Unknown GenParam key : "+HTuple(hv_GenParamName[hv_IndexGenParam]));
      }
    }
    }
  }
  //
  //Get the samples to be processed.
  hv_DLSamplesProc = HTuple(hv_DLSamples[hv_SampleIndices]);
  //
  //Initialize the tuple for collection the DLSample dictionaries.
  (*hv_DLSampleBatch) = HTuple(hv_SampleIndices.TupleLength(),HTuple(HNULL));
  //
  //Set the BboxKeyList according to the InstanceType.
  if (0 != (int((HTuple((HTuple("detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
  {
    hv_BboxKeyList.Clear();
    hv_BboxKeyList[0] = "bbox_col1";
    hv_BboxKeyList[1] = "bbox_row1";
    hv_BboxKeyList[2] = "bbox_col2";
    hv_BboxKeyList[3] = "bbox_row2";
    if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
    {
      hv_BboxKeyList.Clear();
      hv_BboxKeyList[0] = "bbox_row";
      hv_BboxKeyList[1] = "bbox_col";
      hv_BboxKeyList[2] = "bbox_length1";
      hv_BboxKeyList[3] = "bbox_length2";
      hv_BboxKeyList[4] = "bbox_phi";
    }
  }
  //Loop over all selected samples and create a DLSample dictionary
  //for each dictionary in the DLDataset samples.
  {
  HTuple end_val82 = (hv_SampleIndices.TupleLength())-1;
  HTuple step_val82 = 1;
  for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val82, step_val82); hv_ImageIndex += step_val82)
  {
    //
    //Create the DLSample dictionary
    CreateDict(&hv_DLSample);
    //
    //Set the image key.
    GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "image_id", &hv_ImageID);
    SetDictTuple(hv_DLSample, "image_id", hv_ImageID);
    //
    //Read image.
    //The relative file path of the image is specified in image_name.
    GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "image_file_name", &hv_ImageName);
    //
    if (0 != (int((hv_ImageDir.TupleStrlen())==0)))
    {
      hv_FileName = hv_ImageName;
    }
    else
    {
      hv_FileName = (hv_ImageDir+"/")+hv_ImageName;
    }
    try
    {
      ReadImage(&ho_ImageRaw, hv_FileName);
      //Insert image into dictionary.
      SetDictObject(ho_ImageRaw, hv_DLSample, "image");
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      throw HException((((("Error for reading/setting image "+hv_FileName)+" with ID ")+hv_ImageID)+" : Error code ")+HTuple(hv_Exception[0]));
    }
    //
    //Read specific data.
    //
    if (0 != (int(hv_RestrictKeysDLSample!=HTuple("image_only"))))
    {
      //
      //Transfer anomaly detection relevant data.
      if (0 != (int((HTuple((HTuple("anomaly_detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the label key.
        GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "anomaly_label", 
            &hv_AnomalyLabelExists);
        if (0 != hv_AnomalyLabelExists)
        {
          //Get the image label.
          GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "anomaly_label", 
              &hv_AnomalyLabel);
          //Check the existence of the anomaly file name key. If not found it is just ignored.
          GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "anomaly_file_name", 
              &hv_AnomalyFileNameExists);
          if (0 != hv_AnomalyFileNameExists)
          {
            //Get the ground truth anomaly directory.
            GetDictTuple(hv_DLDataset, "anomaly_dir", &hv_AnomalyDir);
            //Get the image file name.
            GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "anomaly_file_name", 
                &hv_AnomalyFileName);
            //Read the ground truth anomaly image.
            try
            {
              ReadImage(&ho_ImageAnomaly, (hv_AnomalyDir+"/")+hv_AnomalyFileName);
            }
            // catch (ExceptionImageAnomaly) 
            catch (HException &HDevExpDefaultException)
            {
              HDevExpDefaultException.ToHTuple(&hv_ExceptionImageAnomaly);
              //If the file is not an image, try to read the ground truth anomaly region.
              //Then, convert this region to a ground truth anomaly image.
              try
              {
                ReadRegion(&ho_RegionAnomaly, (hv_AnomalyDir+"/")+hv_AnomalyFileName);
              }
              // catch (ExceptionRegionAnomaly) 
              catch (HException &HDevExpDefaultException)
              {
                HDevExpDefaultException.ToHTuple(&hv_ExceptionRegionAnomaly);
                throw HException((("Error: Could not read the anomaly ground truth information of image_id "+hv_ImageID)+" : Error code ")+HTuple(hv_ExceptionImageAnomaly[0]));
              }
              GetImageSize(ho_ImageRaw, &hv_Width, &hv_Height);
              GenImageConst(&ho_ImageAnomaly, "byte", hv_Width, hv_Height);
              OverpaintRegion(ho_ImageAnomaly, ho_ImageAnomaly, 0, "fill");
              OverpaintRegion(ho_ImageAnomaly, ho_RegionAnomaly, 1, "fill");
            }
            //Insert anomaly image into DLSample dictionary.
            SetDictObject(ho_ImageAnomaly, hv_DLSample, "anomaly_ground_truth");
          }
          //
          //Insert anomaly label into DLSample dictionary.
          SetDictTuple(hv_DLSample, "anomaly_label", hv_AnomalyLabel);
          //Insert anomaly label id into DLSample dictionary.
          if (0 != (int(hv_AnomalyLabel==HTuple("nok"))))
          {
            SetDictTuple(hv_DLSample, "anomaly_label_id", 1);
          }
          else
          {
            SetDictTuple(hv_DLSample, "anomaly_label_id", 0);
          }
        }
        else if (0 != (HTuple(hv_AnomalyLabelExists.TupleNot()).TupleAnd(hv_IgnoreMissing.TupleNot())))
        {
          throw HException(("For image_id "+hv_ImageID)+" the key 'anomaly_label' is missing. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //
      //Transfer classification relevant data.
      if (0 != (int((HTuple((HTuple("classification").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the required key.
        GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "image_label_id", 
            &hv_ImageLabelIDExists);
        if (0 != hv_ImageLabelIDExists)
        {
          //Transfer the image label.
          GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "image_label_id", 
              &hv_ImageLabelID);
          SetDictTuple(hv_DLSample, "image_label_id", hv_ImageLabelID);
        }
        else if (0 != (HTuple(hv_ImageLabelIDExists.TupleNot()).TupleAnd(hv_IgnoreMissing.TupleNot())))
        {
          throw HException(("For image_id "+hv_ImageID)+" the key 'image_label_id' is missing. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //
      //Transfer detection relevant data.
      if (0 != (int((HTuple((HTuple("detection").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the required key.
        GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "bbox_label_id", 
            &hv_BboxExists);
        if (0 != hv_BboxExists)
        {
          //Transfer the bounding box labels.
          GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "bbox_label_id", 
              &hv_BboxLabels);
          SetDictTuple(hv_DLSample, "bbox_label_id", hv_BboxLabels);
          //Transfer the bounding box coordinates.
          GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", hv_BboxKeyList, 
              &hv_KeysExist);
          if (0 != (HTuple(int((hv_KeysExist.TupleSum())!=(hv_KeysExist.TupleLength()))).TupleAnd(hv_IgnoreMissing.TupleNot())))
          {
            hv_MissingKeyIndices = (hv_KeysExist.TupleEqualElem(0)).TupleFind(1);
            throw HException((("For image_id "+hv_ImageID)+HTuple(", an error has occurred when transferring the key "))+HTuple(hv_BboxKeyList[hv_MissingKeyIndices]));
          }
          {
          HTuple end_val186 = (hv_BboxKeyList.TupleLength())-1;
          HTuple step_val186 = 1;
          for (hv_IndexParam=0; hv_IndexParam.Continue(end_val186, step_val186); hv_IndexParam += step_val186)
          {
            GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), HTuple(hv_BboxKeyList[hv_IndexParam]), 
                &hv_BboxCoord);
            SetDictTuple(hv_DLSample, HTuple(hv_BboxKeyList[hv_IndexParam]), hv_BboxCoord);
          }
          }
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key bbox_label_id. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
      //
      //Transfer segmentation relevant data.
      if (0 != (int((HTuple((HTuple("segmentation").Append("off")).TupleFind(hv_RestrictKeysDLSample)).TupleMax())!=-1)))
      {
        //Check the existence of the required keys.
        GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "segmentation_file_name", 
            &hv_SegKeyExists);
        if (0 != hv_SegKeyExists)
        {
          //Get the ground truth segmentation directory.
          GetDictTuple(hv_DLDataset, "segmentation_dir", &hv_SegmentationDir);
          //Get the image file name.
          GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "segmentation_file_name", 
              &hv_SegmentationName);
          //Read the ground truth segmentation image.
          try
          {
            ReadImage(&ho_ImageSegmentation, (hv_SegmentationDir+"/")+hv_SegmentationName);
          }
          // catch (ExceptionSegmentation) 
          catch (HException &HDevExpDefaultException)
          {
            HDevExpDefaultException.ToHTuple(&hv_ExceptionSegmentation);
            throw HException((("Error for reading segmentation file of image_id "+hv_ImageID)+" : Error code ")+HTuple(hv_ExceptionSegmentation[0]));
          }
          //Insert image into DLSample dictionary.
          SetDictObject(ho_ImageSegmentation, hv_DLSample, "segmentation_image");
        }
        else if (0 != (hv_IgnoreMissing.TupleNot()))
        {
          throw HException(("For image_id "+hv_ImageID)+" there is no key segmentation_file_name. Missing keys can be ignored using the GenParam ignore_missing_labels.");
        }
      }
    }
    //
    //Collect all data dictionaries of all processed indices.
    (*hv_DLSampleBatch)[hv_ImageIndex] = hv_DLSample;
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples. 
void gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch)
{

  // Local iconic variables
  HObject  ho_Image;

  // Local control variables
  HTuple  hv_NumImages, hv_ImageIndex, hv_DLSample;

  //
  //This procedure creates DLSampleBatch, a tuple
  //containing a dictionary DLSample
  //for every image given in Images.
  //
  //Initialize output tuple.
  CountObj(ho_Images, &hv_NumImages);
  (*hv_DLSampleBatch) = HTuple(hv_NumImages,-1);
  //
  //Loop through all given images.
  {
  HTuple end_val10 = hv_NumImages-1;
  HTuple step_val10 = 1;
  for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val10, step_val10); hv_ImageIndex += step_val10)
  {
    SelectObj(ho_Images, &ho_Image, hv_ImageIndex+1);
    //Create DLSample from image.
    CreateDict(&hv_DLSample);
    SetDictObject(ho_Image, hv_DLSample, "image");
    //
    //Collect the DLSamples.
    (*hv_DLSampleBatch)[hv_ImageIndex] = hv_DLSample;
  }
  }
  return;
}

// Chapter: Deep Learning / Anomaly Detection
// Short Description: Get the ground truth anomaly label and label ID. 
void get_anomaly_ground_truth_label (HTuple hv_SampleKeys, HTuple hv_DLSample, HTuple *hv_AnomalyLabelGroundTruth, 
    HTuple *hv_AnomalyLabelIDGroundTruth)
{

  //
  //This procedure returns the anomaly ground truth label.
  //
  if (0 != (int((hv_SampleKeys.TupleFind("anomaly_label"))!=-1)))
  {
    GetDictTuple(hv_DLSample, "anomaly_label", &(*hv_AnomalyLabelGroundTruth));
  }
  else
  {
    throw HException("Ground truth class label cannot be found in DLSample.");
  }
  if (0 != (int((hv_SampleKeys.TupleFind("anomaly_label_id"))!=-1)))
  {
    GetDictTuple(hv_DLSample, "anomaly_label_id", &(*hv_AnomalyLabelIDGroundTruth));
  }
  else
  {
    throw HException("Ground truth class label id cannot be found in DLSample.");
  }
  //
  return;
}

// Chapter: Deep Learning / Anomaly Detection
// Short Description: Get the anomaly results out of DLResult and apply thresholds (if specified). 
void get_anomaly_result (HObject *ho_AnomalyImage, HObject *ho_AnomalyRegion, HTuple hv_DLResult, 
    HTuple hv_ResultKeys, HTuple hv_AnomalyClassThreshold, HTuple hv_AnomalyRegionThreshold, 
    HTuple *hv_AnomalyScore, HTuple *hv_AnomalyClassID, HTuple *hv_AnomalyClassThresholdDisplay, 
    HTuple *hv_AnomalyRegionThresholdDisplay)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_AnomalyImageExists;

  //
  //This procedure returns the inference results in DLResult which are
  //the anomaly image and the anomaly score. It also returns the
  //classification of the anomaly score and segmentation of anomalous
  //pixels in the anomaly image by applying the specified thresholds if
  //given. Otherwise the results from DLResult are used.
  //
  if (0 != (int((hv_ResultKeys.TupleFind("anomaly_image"))!=-1)))
  {
    GetDictParam(hv_DLResult, "key_exists", "anomaly_image", &hv_AnomalyImageExists);
    if (0 != hv_AnomalyImageExists)
    {
      GetDictObject(&(*ho_AnomalyImage), hv_DLResult, "anomaly_image");
    }
    else
    {
      throw HException("Result anomaly image could not be found in DLResult.");
    }
  }
  else
  {
    throw HException("Result anomaly image could not be found in DLResult.");
  }
  //
  if (0 != (int((hv_ResultKeys.TupleFind("anomaly_score"))!=-1)))
  {
    GetDictTuple(hv_DLResult, "anomaly_score", &(*hv_AnomalyScore));
  }
  else
  {
    throw HException("Result anomaly score could not be found in DLResult.");
  }
  //
  (*hv_AnomalyRegionThresholdDisplay) = -1;
  if (0 != (int(hv_AnomalyRegionThreshold!=-1)))
  {
    //Apply threshold for segmentation result.
    if (0 != (int((hv_AnomalyRegionThreshold.TupleLength())!=1)))
    {
      throw HException("Selected 'anomaly_region_threshold' must be specified by exactly one value.");
    }
    if (0 != (HTuple(int(hv_AnomalyRegionThreshold>1)).TupleOr(int(hv_AnomalyRegionThreshold<0))))
    {
      throw HException("Selected 'anomaly_region_threshold' out of range. It must be between 0 and 1.");
    }
    Threshold((*ho_AnomalyImage), &(*ho_AnomalyRegion), hv_AnomalyRegionThreshold, 
        1);
    (*hv_AnomalyRegionThresholdDisplay) = hv_AnomalyRegionThreshold;
  }
  else
  {
    //If no threshold is given, use the threshold and resulting anomaly region out of DLResult.
    if (0 != (int((hv_ResultKeys.TupleFind("anomaly_region"))!=-1)))
    {
      GetDictObject(&(*ho_AnomalyRegion), hv_DLResult, "anomaly_region");
      GetDictTuple(hv_DLResult, "anomaly_segmentation_threshold", &(*hv_AnomalyRegionThresholdDisplay));
    }
    else
    {
      GenEmptyObj(&(*ho_AnomalyRegion));
    }
  }
  //
  (*hv_AnomalyClassThresholdDisplay) = -1;
  (*hv_AnomalyClassID) = -1;
  if (0 != (int(hv_AnomalyClassThreshold!=-1)))
  {
    //Apply threshold for classification result.
    if (0 != (int((hv_AnomalyClassThreshold.TupleLength())!=1)))
    {
      throw HException("Selected 'anomaly_classification_threshold' must be specified by exactly one value.");
    }
    if (0 != (int(hv_AnomalyClassThreshold<0.0)))
    {
      throw HException("Selected 'anomaly_classification_threshold' cannot be negative.");
    }
    if (0 != (int((*hv_AnomalyScore)<hv_AnomalyClassThreshold)))
    {
      (*hv_AnomalyClassID) = 0;
    }
    else
    {
      (*hv_AnomalyClassID) = 1;
    }
    (*hv_AnomalyClassThresholdDisplay) = hv_AnomalyClassThreshold;
  }
  else
  {
    //If no threshold is given, use the threshold and resulting class id out of DLResult.
    if (0 != (int((hv_ResultKeys.TupleFind("anomaly_class_id"))!=-1)))
    {
      GetDictTuple(hv_DLResult, "anomaly_class_id", &(*hv_AnomalyClassID));
      GetDictTuple(hv_DLResult, "anomaly_classification_threshold", &(*hv_AnomalyClassThresholdDisplay));
    }
    else
    {
      (*hv_AnomalyClassID) = -1;
    }
  }
  //
  return;
}

// Chapter: Graphics / Window
// Short Description: Get the next child window that can be used for visualization. 
void get_child_window (HTuple hv_HeightImage, HTuple hv_Font, HTuple hv_FontSize, 
    HTuple hv_Text, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_WindowImageRatio, HTuple *hv_PrevWindowCoordinatesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OpenNewWindow, hv_WindowHandles, hv_ParentWindowHandle;
  HTuple  hv_ChildWindowHandle, hv_Exception, hv_MetaInfo;
  HTuple  hv_WindowRow, hv_WindowColumn, hv_WindowWidth, hv_WindowHeight;

  //
  //This procedure returns the next child window that
  //is used for visualization. If ReuseWindows is true
  //and WindowHandleList is suitable, the window handles
  //that are passed over are used. Else, this procedure
  //opens a new window, either next to the last ones, or
  //in a new row.
  //
  //First, check if the requested window is already available.
  hv_OpenNewWindow = 0;
  try
  {
    GetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, &hv_WindowHandles);
    hv_ParentWindowHandle = ((const HTuple&)hv_WindowHandles)[0];
    hv_ChildWindowHandle = ((const HTuple&)hv_WindowHandles)[1];
    //Check if window handle is valid.
    try
    {
      FlushBuffer(hv_ChildWindowHandle);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //Since there is something wrong with the current window, create a new one.
      hv_OpenNewWindow = 1;
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_OpenNewWindow = 1;
  }
  //
  //Get next child window.
  if (0 != (hv_OpenNewWindow.TupleNot()))
  {
    //
    //If possible, reuse existing window handles.
    HDevWindowStack::SetActive(hv_ChildWindowHandle);
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    set_display_font(hv_ChildWindowHandle, hv_FontSize, hv_Font, "true", "false");
    //
    GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
    //
    //Get previous window coordinates.
    GetWindowExtents(hv_ParentWindowHandle, &hv_WindowRow, &hv_WindowColumn, &hv_WindowWidth, 
        &hv_WindowHeight);
    (*hv_WindowImageRatio) = hv_WindowHeight/(hv_HeightImage*1.0);
    //
    try
    {
      //
      //Get WindowImageRatio from parent window.
      GetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_height", 
          &(*hv_WindowImageRatio));
      //
      //Get previous window coordinates.
      GetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_child_window_coordinates", &(*hv_PrevWindowCoordinatesOut));
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //
      //Set WindowImageRatio from parent window.
      GetWindowExtents(hv_ParentWindowHandle, &hv_WindowRow, &hv_WindowColumn, &hv_WindowWidth, 
          &hv_WindowHeight);
      (*hv_WindowImageRatio) = hv_WindowHeight/(hv_HeightImage*1.0);
      //
      //Set previous window coordinates.
      (*hv_PrevWindowCoordinatesOut)[0] = hv_WindowRow;
      (*hv_PrevWindowCoordinatesOut)[1] = hv_WindowColumn;
      (*hv_PrevWindowCoordinatesOut)[2] = hv_WindowWidth;
      (*hv_PrevWindowCoordinatesOut)[3] = hv_WindowHeight;
    }
  }
  else
  {
    //
    //Open a new child window.
    open_child_window(hv_ParentWindowHandle, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates, 
        hv_WindowHandleDict, hv_WindowHandleKey, &hv_ChildWindowHandle, &(*hv_PrevWindowCoordinatesOut));
    SetWindowParam(hv_ChildWindowHandle, "flush", "false");
    SetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, hv_ParentWindowHandle.TupleConcat(hv_ChildWindowHandle));
  }
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Get the ground truth classification label id. 
void get_classification_ground_truth (HTuple hv_SampleKeys, HTuple hv_DLSample, HTuple *hv_ClassificationLabelIDGroundTruth)
{

  //
  //This procedure returns the classification ground truth label ID.
  //
  if (0 != (int((hv_SampleKeys.TupleFind("image_label_id"))!=-1)))
  {
    GetDictTuple(hv_DLSample, "image_label_id", &(*hv_ClassificationLabelIDGroundTruth));
  }
  else
  {
    throw HException("Ground truth class label cannot be found in DLSample.");
  }
  //
  return;
}

// Chapter: Deep Learning / Classification
// Short Description: Get the predicted classification class ID. 
void get_classification_result (HTuple hv_ResultKeys, HTuple hv_DLResult, HTuple *hv_ClassificationClassID)
{

  // Local iconic variables

  //
  //This procedure returns the predicted classification class ID.
  //
  if (0 != (int((hv_ResultKeys.TupleFind("classification_class_ids"))!=-1)))
  {
    GetDictTuple(hv_DLResult, "classification_class_ids", &(*hv_ClassificationClassID));
    if (0 != (int(((*hv_ClassificationClassID).TupleLength())>0)))
    {
      (*hv_ClassificationClassID) = ((const HTuple&)(*hv_ClassificationClassID))[0];
    }
  }
  else
  {
    throw HException("Key entry 'classification_class_ids' could not be found in DLResult.");
  }
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the confidences of the segmentation result. 
void get_confidence_image (HObject *ho_ImageConfidence, HTuple hv_ResultKeys, HTuple hv_DLResult)
{

  //
  //This procedure returns confidences of the segmentation result.
  //
  if (0 != (int((hv_ResultKeys.TupleFind("segmentation_confidence"))!=-1)))
  {
    GetDictObject(&(*ho_ImageConfidence), hv_DLResult, "segmentation_confidence");
  }
  else if (0 != (int((hv_ResultKeys.TupleFind("segmentation_confidences"))!=-1)))
  {
    GetDictObject(&(*ho_ImageConfidence), hv_DLResult, "segmentation_confidences");
  }
  else
  {
    throw HException("Confidence image could not be found in DLSample.");
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Generate NumColors distinct colors 
void get_distinct_colors_dl_visualization (HTuple hv_NumColors, HTuple hv_Random, 
    HTuple hv_StartColor, HTuple hv_EndColor, HTuple *hv_Colors)
{

  // Local iconic variables
  HObject  ho_HLSImageH, ho_HLSImageL, ho_HLSImageS;
  HObject  ho_ImageR, ho_ImageG, ho_ImageB;

  // Local control variables
  HTuple  hv_IsString, hv_Hue, hv_Lightness, hv_Saturation;
  HTuple  hv_Rows, hv_Columns, hv_Red, hv_Green, hv_Blue;

  //
  //We get distinct color-values first in HLS color-space.
  //Assumes hue [0, EndColor), lightness [0, 1), saturation [0, 1).
  //
  //Parameter checks.
  //NumColors.
  if (0 != (int(hv_NumColors<1)))
  {
    throw HException("NumColors should be at least 1");
  }
  if (0 != ((hv_NumColors.TupleIsInt()).TupleNot()))
  {
    throw HException("NumColors should be of type int");
  }
  if (0 != (int((hv_NumColors.TupleLength())!=1)))
  {
    throw HException("NumColors should have length 1");
  }
  //Random.
  if (0 != (HTuple(int(hv_Random!=0)).TupleAnd(int(hv_Random!=1))))
  {
    TupleIsString(hv_Random, &hv_IsString);
    if (0 != hv_IsString)
    {
      hv_Random = HTuple(int(hv_Random==HTuple("true"))).TupleOr("false");
    }
    else
    {
      throw HException("Random should be either true or false");
    }
  }
  //StartColor.
  if (0 != (int((hv_StartColor.TupleLength())!=1)))
  {
    throw HException("StartColor should have length 1");
  }
  if (0 != (HTuple(int(hv_StartColor<0)).TupleOr(int(hv_StartColor>255))))
  {
    throw HException(HTuple("StartColor should be in the range [0, 255]"));
  }
  if (0 != ((hv_StartColor.TupleIsInt()).TupleNot()))
  {
    throw HException("StartColor should be of type int");
  }
  //EndColor.
  if (0 != (int((hv_EndColor.TupleLength())!=1)))
  {
    throw HException("EndColor should have length 1");
  }
  if (0 != (HTuple(int(hv_EndColor<0)).TupleOr(int(hv_EndColor>255))))
  {
    throw HException(HTuple("EndColor should be in the range [0, 255]"));
  }
  if (0 != ((hv_EndColor.TupleIsInt()).TupleNot()))
  {
    throw HException("EndColor should be of type int");
  }
  //
  //Color generation.
  if (0 != (int(hv_StartColor>hv_EndColor)))
  {
    hv_EndColor += 255;
  }
  if (0 != (int(hv_NumColors!=1)))
  {
    hv_Hue = (hv_StartColor+((((hv_EndColor-hv_StartColor)*(HTuple::TupleGenSequence(0,hv_NumColors-1,1).TupleReal()))/((hv_NumColors-1).TupleReal())).TupleInt()))%255;
  }
  else
  {
    hv_Hue = (hv_StartColor.TupleConcat(hv_EndColor)).TupleMean();
  }
  if (0 != hv_Random)
  {
    hv_Hue = ((const HTuple&)hv_Hue)[HTuple::TupleRand(hv_NumColors).TupleSortIndex()];
    hv_Lightness = (((5.0+HTuple::TupleRand(hv_NumColors))*255.0)/10.0).TupleInt();
    hv_Saturation = (((9.0+HTuple::TupleRand(hv_NumColors))*255.0)/10.0).TupleInt();
  }
  else
  {
    hv_Lightness = (HTuple(hv_NumColors,0.55)*255.0).TupleInt();
    hv_Saturation = (HTuple(hv_NumColors,0.95)*255.0).TupleInt();
  }
  //
  //Write colors to a 3-channel image in order to transform easier.
  GenImageConst(&ho_HLSImageH, "byte", 1, hv_NumColors);
  GenImageConst(&ho_HLSImageL, "byte", 1, hv_NumColors);
  GenImageConst(&ho_HLSImageS, "byte", 1, hv_NumColors);
  GetRegionPoints(ho_HLSImageH, &hv_Rows, &hv_Columns);
  SetGrayval(ho_HLSImageH, hv_Rows, hv_Columns, hv_Hue);
  SetGrayval(ho_HLSImageL, hv_Rows, hv_Columns, hv_Lightness);
  SetGrayval(ho_HLSImageS, hv_Rows, hv_Columns, hv_Saturation);
  //
  //Convert from HLS to RGB.
  TransToRgb(ho_HLSImageH, ho_HLSImageL, ho_HLSImageS, &ho_ImageR, &ho_ImageG, &ho_ImageB, 
      "hls");
  //
  //Get RGB-values and transform to Hex.
  GetGrayval(ho_ImageR, hv_Rows, hv_Columns, &hv_Red);
  GetGrayval(ho_ImageG, hv_Rows, hv_Columns, &hv_Green);
  GetGrayval(ho_ImageB, hv_Rows, hv_Columns, &hv_Blue);
  (*hv_Colors) = (("#"+(hv_Red.TupleString("02x")))+(hv_Green.TupleString("02x")))+(hv_Blue.TupleString("02x"));
  return;
  //
}

// Chapter: Deep Learning / Model
// Short Description: Generates certain colors for different ClassNames 
void get_dl_class_colors (HTuple hv_ClassNames, HTuple *hv_Colors)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumColors, hv_ColorsRainbow, hv_ClassNamesGood;
  HTuple  hv_IndexFind, hv_GoodIdx, hv_CurrentColor, hv_GreenIdx;

  //
  //This procedure returns for each class a certain color.
  //
  //Define distinct colors for the classes.
  hv_NumColors = hv_ClassNames.TupleLength();
  //Get distinct colors without randomness makes neighboring colors look very similar.
  //We use a workaround to get deterministic colors where subsequent colors are distinguishable.
  get_distinct_colors_dl_visualization(hv_NumColors, 0, 0, 200, &hv_ColorsRainbow);
  TupleInverse(hv_ColorsRainbow, &hv_ColorsRainbow);
  make_neighboring_colors_distinguishable_dl_visualization(hv_ColorsRainbow, &(*hv_Colors));
  //If a class 'OK','ok', 'good' or 'GOOD' is present set this class to green.
  //Only the first occurrence found is set to a green shade.
  hv_ClassNamesGood.Clear();
  hv_ClassNamesGood[0] = "good";
  hv_ClassNamesGood[1] = "GOOD";
  hv_ClassNamesGood[2] = "ok";
  hv_ClassNamesGood[3] = "OK";
  {
  HTuple end_val13 = (hv_ClassNamesGood.TupleLength())-1;
  HTuple step_val13 = 1;
  for (hv_IndexFind=0; hv_IndexFind.Continue(end_val13, step_val13); hv_IndexFind += step_val13)
  {
    hv_GoodIdx = hv_ClassNames.TupleFindFirst(HTuple(hv_ClassNamesGood[hv_IndexFind]));
    if (0 != (HTuple(int(hv_GoodIdx!=-1)).TupleAnd(int((hv_ClassNames.TupleLength())<=8))))
    {
      //If number of classes is <= 8, swap color with a green color.
      hv_CurrentColor = HTuple((*hv_Colors)[hv_GoodIdx]);
      hv_GreenIdx = HTuple((hv_ClassNames.TupleLength())/2.0).TupleFloor();
      //Set to pure green.
      (*hv_Colors)[hv_GoodIdx] = "#00ff00";
      //Write original color to a green entry.
      (*hv_Colors)[hv_GreenIdx] = hv_CurrentColor;
      break;
    }
    else if (0 != (HTuple(int(hv_GoodIdx!=-1)).TupleAnd(int((hv_ClassNames.TupleLength())>8))))
    {
      //If number of classes is larger than 8, set the respective color to green.
      (*hv_Colors)[hv_GoodIdx] = "#00ff00";
      break;
    }
  }
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Get the image of a sample. 
void get_image (HObject *ho_Image, HTuple hv_SampleKeys, HTuple hv_DLSample)
{

  //
  //This procedure returns the image of a sample.
  //
  if (0 != (int((hv_SampleKeys.TupleFind("image"))!=-1)))
  {
    GetDictObject(&(*ho_Image), hv_DLSample, "image");
  }
  else
  {
    throw HException("Image could not be found in DLSample.");
  }
  return;
}

// Chapter: Graphics / Window
// Short Description: Get the next window that can be used for visualization. 
void get_next_window (HTuple hv_Font, HTuple hv_FontSize, HTuple hv_ShowBottomDesc, 
    HTuple hv_WidthImage, HTuple hv_HeightImage, HTuple hv_MapColorBarWidth, HTuple hv_ScaleWindows, 
    HTuple hv_ThresholdWidth, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_CurrentWindowHandle, HTuple *hv_WindowImageRatioHeight, 
    HTuple *hv_PrevWindowCoordinatesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OpenNewWindow, hv_WindowHandles, hv_Value;
  HTuple  hv_Exception, hv_Ascent, hv_Descent, hv__, hv_MarginBottom;
  HTuple  hv_WindowImageRatioWidth, hv_SetPartRow2, hv_SetPartColumn2;
  HTuple  hv_MetaInfo;

  //
  //This procedure returns the next window that
  //is used for visualization. If ReuseWindows is true
  //and WindowHandleList is suitable, the window handles
  //that are passed over are used. Else, this procedure
  //opens a new window, either next to the last ones, or
  //in a new row.
  //
  //First, check if the requested window is already available.
  hv_OpenNewWindow = 0;
  try
  {
    GetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, &hv_WindowHandles);
    (*hv_CurrentWindowHandle) = ((const HTuple&)hv_WindowHandles)[0];
    //Check if window handle is valid.
    try
    {
      GetWindowParam((*hv_CurrentWindowHandle), "flush", &hv_Value);
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      //If there is something wrong with the current window, create a new one.
      hv_OpenNewWindow = 1;
      RemoveDictKey(hv_WindowHandleDict, hv_WindowHandleKey);
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_OpenNewWindow = 1;
  }
  //
  //Get next window.
  if (0 != (hv_OpenNewWindow.TupleNot()))
  {
    //
    //If possible, reuse existing window handles.
    HDevWindowStack::SetActive((*hv_CurrentWindowHandle));
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    set_display_font((*hv_CurrentWindowHandle), hv_FontSize, hv_Font, "true", "false");
    //
    //Calculate MarginBottom.
    if (0 != hv_ShowBottomDesc)
    {
      GetStringExtents((*hv_CurrentWindowHandle), "test_string", &hv_Ascent, &hv_Descent, 
          &hv__, &hv__);
      hv_MarginBottom = ((2*12)+hv_Ascent)+hv_Descent;
    }
    else
    {
      hv_MarginBottom = 0;
    }
    //
    //Get and set meta information for current window.
    update_window_meta_information((*hv_CurrentWindowHandle), hv_WidthImage, hv_HeightImage, 
        0, 0, hv_MapColorBarWidth, hv_MarginBottom, &(*hv_WindowImageRatioHeight), 
        &hv_WindowImageRatioWidth, &hv_SetPartRow2, &hv_SetPartColumn2, &(*hv_PrevWindowCoordinatesOut));
    //
    //Update meta information.
    GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_height", (*hv_WindowImageRatioHeight));
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_width", hv_WindowImageRatioWidth);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_row2", hv_SetPartRow2);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_column2", hv_SetPartColumn2);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_margin_bottom", hv_MarginBottom);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_map_color_bar_with", hv_MapColorBarWidth);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_coordinates", (*hv_PrevWindowCoordinatesOut));
  }
  else
  {
    //
    //Open a new window.
    open_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage, 
        hv_MapColorBarWidth, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates, 
        hv_WindowHandleDict, hv_WindowHandleKey, &(*hv_CurrentWindowHandle), &(*hv_WindowImageRatioHeight), 
        &(*hv_PrevWindowCoordinatesOut));
    SetWindowParam((*hv_CurrentWindowHandle), "flush", "false");
  }
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the ground truth segmentation image. 
void get_segmentation_image_ground_truth (HObject *ho_SegmentationImagGroundTruth, 
    HTuple hv_SampleKeys, HTuple hv_DLSample)
{

  //
  //This procedure returns the ground truth segmentation image.
  //
  if (0 != (int((hv_SampleKeys.TupleFind("segmentation_image"))!=-1)))
  {
    GetDictObject(&(*ho_SegmentationImagGroundTruth), hv_DLSample, "segmentation_image");
  }
  else
  {
    throw HException("Ground truth segmentation image could not be found in DLSample.");
  }
  return;
}

// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the predicted segmentation result image. 
void get_segmentation_image_result (HObject *ho_SegmentationImageResult, HTuple hv_ResultKeys, 
    HTuple hv_DLResult)
{

  //
  //This procedure returns the predicted segmentation result image.
  //
  if (0 != (int((hv_ResultKeys.TupleFind("segmentation_image"))!=-1)))
  {
    GetDictObject(&(*ho_SegmentationImageResult), hv_DLResult, "segmentation_image");
  }
  else
  {
    throw HException("Result segmentation data could not be found in DLSample.");
  }
  return;
}

// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Get the weight image of a sample. 
void get_weight_image (HObject *ho_ImageWeight, HTuple hv_SampleKeys, HTuple hv_DLSample)
{

  //
  //This procedure returns the segmentation weight image of a sample.
  //
  if (0 != (int((hv_SampleKeys.TupleFind("weight_image"))!=-1)))
  {
    GetDictObject(&(*ho_ImageWeight), hv_DLSample, "weight_image");
  }
  else
  {
    throw HException("Weight image could not be found in DLSample.");
  }
  return;
}

// Chapter: Deep Learning / Model
// Short Description: shuffles the input colors in a deterministic way 
void make_neighboring_colors_distinguishable_dl_visualization (HTuple hv_ColorsRainbow, 
    HTuple *hv_Colors)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumColors, hv_NumChunks, hv_NumLeftOver;
  HTuple  hv_ColorsPerChunk, hv_StartIdx, hv_S, hv_EndIdx;
  HTuple  hv_IdxsLeft, hv_IdxsRight;

  //
  //Shuffle the input colors in a deterministic way
  //to make adjacent colors more distinguishable.
  //Neighboring colors from the input are distributed to every NumChunks
  //position in the output.
  //Depending on the number of colors, increase NumChunks.
  hv_NumColors = hv_ColorsRainbow.TupleLength();
  if (0 != (int(hv_NumColors>=8)))
  {
    hv_NumChunks = 3;
    if (0 != (int(hv_NumColors>=40)))
    {
      hv_NumChunks = 6;
    }
    else if (0 != (int(hv_NumColors>=20)))
    {
      hv_NumChunks = 4;
    }
    (*hv_Colors) = HTuple(hv_NumColors,-1);
    //Check if the Number of Colors is dividable by NumChunks.
    hv_NumLeftOver = hv_NumColors%hv_NumChunks;
    hv_ColorsPerChunk = (hv_NumColors/hv_NumChunks).TupleInt();
    hv_StartIdx = 0;
    {
    HTuple end_val19 = hv_NumChunks-1;
    HTuple step_val19 = 1;
    for (hv_S=0; hv_S.Continue(end_val19, step_val19); hv_S += step_val19)
    {
      hv_EndIdx = (hv_StartIdx+hv_ColorsPerChunk)-1;
      if (0 != (int(hv_S<hv_NumLeftOver)))
      {
        hv_EndIdx += 1;
      }
      hv_IdxsLeft = HTuple::TupleGenSequence(hv_S,hv_NumColors-1,hv_NumChunks);
      hv_IdxsRight = HTuple::TupleGenSequence(hv_StartIdx,hv_EndIdx,1);
      (*hv_Colors)[HTuple::TupleGenSequence(hv_S,hv_NumColors-1,hv_NumChunks)] = hv_ColorsRainbow.TupleSelectRange(hv_StartIdx,hv_EndIdx);
      hv_StartIdx = hv_EndIdx+1;
    }
    }
  }
  else
  {
    (*hv_Colors) = hv_ColorsRainbow;
  }
  return;
}

// Chapter: Graphics / Window
// Short Description: Open a window next to the given WindowHandleFather.  
void open_child_window (HTuple hv_WindowHandleFather, HTuple hv_Font, HTuple hv_FontSize, 
    HTuple hv_Text, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_WindowHandleChild, HTuple *hv_PrevWindowCoordinatesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_StringWidth, hv_IndexText, hv__, hv_TextWidth;
  HTuple  hv_WindowRow, hv_WindowColumn, hv_WindowWidth, hv_WindowHeight;
  HTuple  hv_MetaInfo;

  //
  //This procedure opens a window next to the given WindowHandleFather.
  //
  //Get the maximum width of the text to be displayed.
  //The width should be at leat 200.
  hv_StringWidth = 150;
  {
  HTuple end_val6 = (hv_Text.TupleLength())-1;
  HTuple step_val6 = 1;
  for (hv_IndexText=0; hv_IndexText.Continue(end_val6, step_val6); hv_IndexText += step_val6)
  {
    GetStringExtents(hv_WindowHandleFather, HTuple(hv_Text[hv_IndexText]), &hv__, 
        &hv__, &hv_TextWidth, &hv__);
    hv_StringWidth = hv_StringWidth.TupleMax2(hv_TextWidth);
  }
  }
  //
  //Define window coordinates.
  hv_WindowRow = ((const HTuple&)hv_PrevWindowCoordinates)[0];
  hv_WindowColumn = (HTuple(hv_PrevWindowCoordinates[1])+HTuple(hv_PrevWindowCoordinates[2]))+5;
  hv_WindowWidth = hv_StringWidth+(2*12.0);
  hv_WindowHeight = ((const HTuple&)hv_PrevWindowCoordinates)[3];
  //
  SetWindowAttr("background_color","black");
  OpenWindow(hv_WindowRow,hv_WindowColumn,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandleChild));
  HDevWindowStack::Push((*hv_WindowHandleChild));
  set_display_font((*hv_WindowHandleChild), hv_FontSize, hv_Font, "true", "false");
  //
  //Return the coordinates of the new window.
  (*hv_PrevWindowCoordinatesOut).Clear();
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowRow);
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowColumn);
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowWidth);
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowHeight);
  //
  //Set some meta information about the new child window handle.
  GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_child_window_coordinates", (*hv_PrevWindowCoordinatesOut));
  SetDictTuple(hv_WindowHandleDict, "meta_information", hv_MetaInfo);
  //
  return;
}

// Chapter: Graphics / Window
// Short Description: Open a new window, either next to the last ones, or in a new row. 
void open_next_window (HTuple hv_Font, HTuple hv_FontSize, HTuple hv_ShowBottomDesc, 
    HTuple hv_WidthImage, HTuple hv_HeightImage, HTuple hv_MapColorBarWidth, HTuple hv_ScaleWindows, 
    HTuple hv_ThresholdWidth, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict, 
    HTuple hv_WindowHandleKey, HTuple *hv_WindowHandleNew, HTuple *hv_WindowImageRatioHeight, 
    HTuple *hv_PrevWindowCoordinatesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_PrevWindowRow, hv_PrevWindowColumn;
  HTuple  hv_PrevWindowWidth, hv_PrevWindowHeight, hv_WindowRow;
  HTuple  hv_WindowColumn, hv_Ascent, hv_Descent, hv__, hv_MarginBottom;
  HTuple  hv_WindowWidth, hv_WindowHeight, hv_WindowImageRatioWidth;
  HTuple  hv_SetPartRow2, hv_SetPartColumn2, hv_MetaInfo;

  //
  //This procedure opens a new window, either next to
  //the last ones, or in a new row.
  //
  //Get coordinates of previous window.
  hv_PrevWindowRow = ((const HTuple&)hv_PrevWindowCoordinates)[0];
  hv_PrevWindowColumn = ((const HTuple&)hv_PrevWindowCoordinates)[1];
  hv_PrevWindowWidth = ((const HTuple&)hv_PrevWindowCoordinates)[2];
  hv_PrevWindowHeight = ((const HTuple&)hv_PrevWindowCoordinates)[3];
  //
  if (0 != (int((hv_PrevWindowColumn+hv_PrevWindowWidth)>hv_ThresholdWidth)))
  {
    //Open window in new row.
    hv_WindowRow = (hv_PrevWindowRow+hv_PrevWindowHeight)+55;
    hv_WindowColumn = 0;
  }
  else
  {
    //Open window in same row.
    hv_WindowRow = hv_PrevWindowRow;
    hv_WindowColumn = hv_PrevWindowColumn+hv_PrevWindowWidth;
    if (0 != (int(hv_WindowColumn!=0)))
    {
      hv_WindowColumn += 5;
    }
  }
  //
  dev_open_window_fit_size(hv_WindowRow, hv_WindowColumn, hv_WidthImage, hv_HeightImage, 
      (HTuple(500).Append(800))*hv_ScaleWindows, (HTuple(400).Append(600))*hv_ScaleWindows, 
      &(*hv_WindowHandleNew));
  set_display_font((*hv_WindowHandleNew), hv_FontSize, hv_Font, "true", "false");
  //
  //Add MarginBottom and MapColorBarWidth to window.
  if (0 != hv_ShowBottomDesc)
  {
    GetStringExtents((*hv_WindowHandleNew), "Test_string", &hv_Ascent, &hv_Descent, 
        &hv__, &hv__);
    hv_MarginBottom = ((2*12)+hv_Ascent)+hv_Descent;
  }
  else
  {
    hv_MarginBottom = 0;
  }
  GetWindowExtents((*hv_WindowHandleNew), &hv__, &hv__, &hv_WindowWidth, &hv_WindowHeight);
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_WindowRow, hv_WindowColumn, 
        hv_WindowWidth+hv_MapColorBarWidth, hv_WindowHeight+hv_MarginBottom);
  //
  //Get and set meta information of new window handle.
  update_window_meta_information((*hv_WindowHandleNew), hv_WidthImage, hv_HeightImage, 
      hv_WindowRow, hv_WindowColumn, hv_MapColorBarWidth, hv_MarginBottom, &(*hv_WindowImageRatioHeight), 
      &hv_WindowImageRatioWidth, &hv_SetPartRow2, &hv_SetPartColumn2, &(*hv_PrevWindowCoordinatesOut));
  //
  //Set window handle and some meta information about the new window handle.
  SetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, (*hv_WindowHandleNew));
  GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_height", (*hv_WindowImageRatioHeight));
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_width", hv_WindowImageRatioWidth);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_row2", hv_SetPartRow2);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_column2", hv_SetPartColumn2);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_margin_bottom", hv_MarginBottom);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_map_color_bar_with", hv_MapColorBarWidth);
  SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_coordinates", (*hv_PrevWindowCoordinatesOut));
  SetDictTuple(hv_WindowHandleDict, "meta_information", hv_MetaInfo);
  //
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess anomaly images for evaluation and visualization of the deep-learning-based anomaly detection. 
void preprocess_dl_model_anomaly (HObject ho_AnomalyImages, HObject *ho_AnomalyImagesPreprocessed, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageRangeMin;
  HTuple  hv_ImageRangeMax, hv_DomainHandling, hv_ModelType;
  HTuple  hv_ImageNumChannels, hv_Min, hv_Max, hv_Range, hv_ImageWidthInput;
  HTuple  hv_ImageHeightInput, hv_EqualWidth, hv_EqualHeight;
  HTuple  hv_Type, hv_NumMatches, hv_NumImages, hv_EqualByte;
  HTuple  hv_NumChannelsAllImages, hv_ImageNumChannelsTuple;
  HTuple  hv_IndicesWrongChannels;

  //
  //This procedure preprocesses the anomaly images given by AnomalyImages
  //according to the parameters in the dictionary DLPreprocessParam.
  //Note that depending on the images,
  //additional preprocessing steps might be beneficial.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  hv_ImageNumChannels = 1;
  //
  //Preprocess the images.
  //
  if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    FullDomain(ho_AnomalyImages, &ho_AnomalyImages);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    CropDomain(ho_AnomalyImages, &ho_AnomalyImages);
  }
  else if (0 != (HTuple(int(hv_DomainHandling==HTuple("keep_domain"))).TupleAnd(int(hv_ModelType==HTuple("anomaly_detection")))))
  {
    //Anomaly detection models accept the additional option 'keep_domain'.
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  MinMaxGray(ho_AnomalyImages, ho_AnomalyImages, 0, &hv_Min, &hv_Max, &hv_Range);
  if (0 != (int(hv_Min<0.0)))
  {
    throw HException("Values of anomaly image must not be smaller than 0.0.");
  }
  //
  //Zoom images only if they have a different size than the specified size.
  GetImageSize(ho_AnomalyImages, &hv_ImageWidthInput, &hv_ImageHeightInput);
  hv_EqualWidth = hv_ImageWidth.TupleEqualElem(hv_ImageWidthInput);
  hv_EqualHeight = hv_ImageHeight.TupleEqualElem(hv_ImageHeightInput);
  if (0 != (HTuple(int((hv_EqualWidth.TupleMin())==0)).TupleOr(int((hv_EqualHeight.TupleMin())==0))))
  {
    ZoomImageSize(ho_AnomalyImages, &ho_AnomalyImages, hv_ImageWidth, hv_ImageHeight, 
        "nearest_neighbor");
  }
  //
  //Check the type of the input images.
  GetImageType(ho_AnomalyImages, &hv_Type);
  TupleRegexpTest(hv_Type, "byte|real", &hv_NumMatches);
  CountObj(ho_AnomalyImages, &hv_NumImages);
  if (0 != (int(hv_NumMatches!=hv_NumImages)))
  {
    throw HException("Please provide only images of type 'byte' or 'real'.");
  }
  //
  //If the type is 'byte', convert it to 'real' and scale it.
  //The gray value scaling does not work on 'byte' images.
  //For 'real' images it is assumed that the range is already correct.
  hv_EqualByte = hv_Type.TupleEqualElem("byte");
  if (0 != (int((hv_EqualByte.TupleMax())==1)))
  {
    if (0 != (int((hv_EqualByte.TupleMin())==0)))
    {
      throw HException("Passing mixed type images is not supported.");
    }
    //Convert the image type from 'byte' to 'real',
    //because the model expects 'real' images.
    ConvertImageType(ho_AnomalyImages, &ho_AnomalyImages, "real");
  }
  //
  //Check the number of channels.
  CountObj(ho_AnomalyImages, &hv_NumImages);
  //Check all images for number of channels.
  CountChannels(ho_AnomalyImages, &hv_NumChannelsAllImages);
  TupleGenConst(hv_NumImages, hv_ImageNumChannels, &hv_ImageNumChannelsTuple);
  TupleFind(hv_NumChannelsAllImages.TupleNotEqualElem(hv_ImageNumChannelsTuple), 
      1, &hv_IndicesWrongChannels);
  //
  //Check for anomaly image channels.
  //Only single channel images are accepted.
  if (0 != (int(hv_IndicesWrongChannels!=-1)))
  {
    throw HException("Number of channels in anomaly image is not supported. Please check for anomaly images with a number of channels different from 1.");
  }
  //
  //Write preprocessed image to output variable.
  (*ho_AnomalyImagesPreprocessed) = ho_AnomalyImages;
  //
  return;
}

// Chapter: Deep Learning / Object Detection
// Short Description: This procedure preprocesses the bounding boxes of type 'rectangle1' for a given sample. 
void preprocess_dl_model_bbox_rect1 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_DomainRaw;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_DomainHandling;
  HTuple  hv_BBoxCol1, hv_BBoxCol2, hv_BBoxRow1, hv_BBoxRow2;
  HTuple  hv_BBoxLabel, hv_Exception, hv_ImageId, hv_ExceptionMessage;
  HTuple  hv_BoxesInvalid, hv_RowDomain1, hv_ColumnDomain1;
  HTuple  hv_RowDomain2, hv_ColumnDomain2, hv_WidthRaw, hv_HeightRaw;
  HTuple  hv_Row1, hv_Col1, hv_Row2, hv_Col2, hv_MaskDelete;
  HTuple  hv_MaskNewBbox, hv_BBoxCol1New, hv_BBoxCol2New;
  HTuple  hv_BBoxRow1New, hv_BBoxRow2New, hv_BBoxLabelNew;
  HTuple  hv_FactorResampleWidth, hv_FactorResampleHeight;

  //
  //This procedure preprocesses the bounding boxes of type 'rectangle1' for a given sample.
  //
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //
  //Get bounding box coordinates and labels.
  try
  {
    GetDictTuple(hv_DLSample, "bbox_col1", &hv_BBoxCol1);
    GetDictTuple(hv_DLSample, "bbox_col2", &hv_BBoxCol2);
    GetDictTuple(hv_DLSample, "bbox_row1", &hv_BBoxRow1);
    GetDictTuple(hv_DLSample, "bbox_row2", &hv_BBoxRow2);
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabel);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
    if (0 != (int(HTuple(hv_Exception[0])==1302)))
    {
      hv_ExceptionMessage = "A bounding box coordinate key is missing.";
    }
    else
    {
      hv_ExceptionMessage = ((const HTuple&)hv_Exception)[2];
    }
    throw HException((("An error has occurred during preprocessing image_id "+hv_ImageId)+" when getting bounding box coordinates : ")+hv_ExceptionMessage);
  }
  //
  //Check that there are no invalid boxes.
  if (0 != (int((hv_BBoxRow1.TupleLength())>0)))
  {
    hv_BoxesInvalid = (hv_BBoxRow1.TupleGreaterEqualElem(hv_BBoxRow2)).TupleOr(hv_BBoxCol1.TupleGreaterEqualElem(hv_BBoxCol2));
    if (0 != (int((hv_BoxesInvalid.TupleSum())>0)))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
      throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one box with zero-area, i.e. bbox_col1 >= bbox_col2 or bbox_row1 >= bbox_row2."));
    }
  }
  else
  {
    //There are no bounding boxes, hence nothing to do.
    return;
  }
  //
  //If the domain is cropped, crop bounding boxes.
  if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //
    //Get domain.
    GetDomain(ho_ImageRaw, &ho_DomainRaw);
    //
    //Set the size of the raw image to the domain extensions.
    SmallestRectangle1(ho_DomainRaw, &hv_RowDomain1, &hv_ColumnDomain1, &hv_RowDomain2, 
        &hv_ColumnDomain2);
    //The domain is always given as a pixel-precise region.
    hv_WidthRaw = (hv_ColumnDomain2-hv_ColumnDomain1)+1.0;
    hv_HeightRaw = (hv_RowDomain2-hv_RowDomain1)+1.0;
    //
    //Crop the bounding boxes.
    hv_Row1 = hv_BBoxRow1.TupleMax2(hv_RowDomain1-.5);
    hv_Col1 = hv_BBoxCol1.TupleMax2(hv_ColumnDomain1-.5);
    hv_Row2 = hv_BBoxRow2.TupleMin2(hv_RowDomain2+.5);
    hv_Col2 = hv_BBoxCol2.TupleMin2(hv_ColumnDomain2+.5);
    hv_MaskDelete = (hv_Row1.TupleGreaterEqualElem(hv_Row2)).TupleOr(hv_Col1.TupleGreaterEqualElem(hv_Col2));
    hv_MaskNewBbox = 1-hv_MaskDelete;
    //Store the preprocessed bounding box entries.
    hv_BBoxCol1New = (hv_Col1.TupleSelectMask(hv_MaskNewBbox))-hv_ColumnDomain1;
    hv_BBoxCol2New = (hv_Col2.TupleSelectMask(hv_MaskNewBbox))-hv_ColumnDomain1;
    hv_BBoxRow1New = (hv_Row1.TupleSelectMask(hv_MaskNewBbox))-hv_RowDomain1;
    hv_BBoxRow2New = (hv_Row2.TupleSelectMask(hv_MaskNewBbox))-hv_RowDomain1;
    hv_BBoxLabelNew = hv_BBoxLabel.TupleSelectMask(hv_MaskNewBbox);
    //
  }
  else if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    //If the entire image is used, set the variables accordingly.
    //Get the original size.
    GetImageSize(ho_ImageRaw, &hv_WidthRaw, &hv_HeightRaw);
    //Set new coordinates to input coordinates.
    hv_BBoxCol1New = hv_BBoxCol1;
    hv_BBoxCol2New = hv_BBoxCol2;
    hv_BBoxRow1New = hv_BBoxRow1;
    hv_BBoxRow2New = hv_BBoxRow2;
    hv_BBoxLabelNew = hv_BBoxLabel;
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Rescale the bounding boxes.
  //
  //Get required images width and height.
  //
  //Only rescale bounding boxes if the required image dimensions are not the raw dimensions.
  if (0 != (HTuple(int(hv_ImageHeight!=hv_HeightRaw)).TupleOr(int(hv_ImageWidth!=hv_WidthRaw))))
  {
    //Calculate rescaling factor.
    hv_FactorResampleWidth = (hv_ImageWidth.TupleReal())/hv_WidthRaw;
    hv_FactorResampleHeight = (hv_ImageHeight.TupleReal())/hv_HeightRaw;
    //Rescale the bounding box coordinates.
    //As we use XLD-coordinates we temporarily move the boxes by (.5,.5) for rescaling.
    //Doing so, the center of the XLD-coordinate system (-0.5,-0.5) is used
    //for scaling, hence the scaling is performed w.r.t. the pixel coordinate system.
    hv_BBoxCol1New = ((hv_BBoxCol1New+.5)*hv_FactorResampleWidth)-.5;
    hv_BBoxCol2New = ((hv_BBoxCol2New+.5)*hv_FactorResampleWidth)-.5;
    hv_BBoxRow1New = ((hv_BBoxRow1New+.5)*hv_FactorResampleHeight)-.5;
    hv_BBoxRow2New = ((hv_BBoxRow2New+.5)*hv_FactorResampleHeight)-.5;
    //
  }
  //
  //Make a final check and remove bounding boxes that have zero area.
  if (0 != (int((hv_BBoxRow1New.TupleLength())>0)))
  {
    hv_MaskDelete = (hv_BBoxRow1New.TupleGreaterEqualElem(hv_BBoxRow2New)).TupleOr(hv_BBoxCol1New.TupleGreaterEqualElem(hv_BBoxCol2New));
    hv_BBoxCol1New = hv_BBoxCol1New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxCol2New = hv_BBoxCol2New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxRow1New = hv_BBoxRow1New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxRow2New = hv_BBoxRow2New.TupleSelectMask(1-hv_MaskDelete);
    hv_BBoxLabelNew = hv_BBoxLabelNew.TupleSelectMask(1-hv_MaskDelete);
  }
  //
  //Set new bounding box coordinates in the dictionary.
  SetDictTuple(hv_DLSample, "bbox_col1", hv_BBoxCol1New);
  SetDictTuple(hv_DLSample, "bbox_col2", hv_BBoxCol2New);
  SetDictTuple(hv_DLSample, "bbox_row1", hv_BBoxRow1New);
  SetDictTuple(hv_DLSample, "bbox_row2", hv_BBoxRow2New);
  SetDictTuple(hv_DLSample, "bbox_label_id", hv_BBoxLabelNew);
  //
  return;
}

// Chapter: Deep Learning / Object Detection
// Short Description: This procedure preprocesses the bounding boxes of type 'rectangle2' for a given sample. 
void preprocess_dl_model_bbox_rect2 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_DomainRaw, ho_Rectangle2XLD, ho_Rectangle2XLDSheared;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_DomainHandling;
  HTuple  hv_IgnoreDirection, hv_ClassIDsNoOrientation, hv_KeyExists;
  HTuple  hv_BBoxRow, hv_BBoxCol, hv_BBoxLength1, hv_BBoxLength2;
  HTuple  hv_BBoxPhi, hv_BBoxLabel, hv_Exception, hv_ImageId;
  HTuple  hv_ExceptionMessage, hv_BoxesInvalid, hv_RowDomain1;
  HTuple  hv_ColumnDomain1, hv_RowDomain2, hv_ColumnDomain2;
  HTuple  hv_WidthRaw, hv_HeightRaw, hv_MaskDelete, hv_MaskNewBbox;
  HTuple  hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxLength1New;
  HTuple  hv_BBoxLength2New, hv_BBoxPhiNew, hv_BBoxLabelNew;
  HTuple  hv_ClassIDsNoOrientationIndices, hv_Index, hv_ClassIDsNoOrientationIndicesTmp;
  HTuple  hv_DirectionLength1Row, hv_DirectionLength1Col;
  HTuple  hv_DirectionLength2Row, hv_DirectionLength2Col;
  HTuple  hv_Corner1Row, hv_Corner1Col, hv_Corner2Row, hv_Corner2Col;
  HTuple  hv_FactorResampleWidth, hv_FactorResampleHeight;
  HTuple  hv_BBoxCol1, hv_BBoxCol1New, hv_BBoxCol2, hv_BBoxCol2New;
  HTuple  hv_BBoxCol3, hv_BBoxCol3New, hv_BBoxCol4, hv_BBoxCol4New;
  HTuple  hv_BBoxRow1, hv_BBoxRow1New, hv_BBoxRow2, hv_BBoxRow2New;
  HTuple  hv_BBoxRow3, hv_BBoxRow3New, hv_BBoxRow4, hv_BBoxRow4New;
  HTuple  hv_HomMat2DIdentity, hv_HomMat2DScale, hv_BBoxPhiTmp;
  HTuple  hv_PhiDelta, hv_PhiDeltaNegativeIndices, hv_IndicesRot90;
  HTuple  hv_IndicesRot180, hv_IndicesRot270, hv_SwapIndices;
  HTuple  hv_Tmp, hv_BBoxPhiNewIndices, hv_PhiThreshold, hv_PhiToCorrect;
  HTuple  hv_NumCorrections, hv__;

  //This procedure preprocesses the bounding boxes of type 'rectangle2' for a given sample.
  //
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get preprocess parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //The keys 'ignore_direction' and 'class_ids_no_orientation' are optional.
  hv_IgnoreDirection = 0;
  hv_ClassIDsNoOrientation = HTuple();
  GetDictParam(hv_DLPreprocessParam, "key_exists", (HTuple("ignore_direction").Append("class_ids_no_orientation")), 
      &hv_KeyExists);
  if (0 != (HTuple(hv_KeyExists[0])))
  {
    GetDictTuple(hv_DLPreprocessParam, "ignore_direction", &hv_IgnoreDirection);
    if (0 != (int(hv_IgnoreDirection==HTuple("true"))))
    {
      hv_IgnoreDirection = 1;
    }
    else if (0 != (int(hv_IgnoreDirection==HTuple("false"))))
    {
      hv_IgnoreDirection = 0;
    }
  }
  if (0 != (HTuple(hv_KeyExists[1])))
  {
    GetDictTuple(hv_DLPreprocessParam, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
  }
  //
  //Get bounding box coordinates and labels.
  try
  {
    GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
    GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
    GetDictTuple(hv_DLSample, "bbox_length1", &hv_BBoxLength1);
    GetDictTuple(hv_DLSample, "bbox_length2", &hv_BBoxLength2);
    GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabel);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
    if (0 != (int(HTuple(hv_Exception[0])==1302)))
    {
      hv_ExceptionMessage = "A bounding box coordinate key is missing.";
    }
    else
    {
      hv_ExceptionMessage = ((const HTuple&)hv_Exception)[2];
    }
    throw HException((("An error has occurred during preprocessing image_id "+hv_ImageId)+" when getting bounding box coordinates : ")+hv_ExceptionMessage);
  }
  //
  //Check that there are no invalid boxes.
  if (0 != (int((hv_BBoxRow.TupleLength())>0)))
  {
    hv_BoxesInvalid = ((hv_BBoxLength1.TupleEqualElem(0)).TupleSum())+((hv_BBoxLength2.TupleEqualElem(0)).TupleSum());
    if (0 != (int(hv_BoxesInvalid>0)))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
      throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one bounding box with zero-area, i.e. bbox_length1 == 0 or bbox_length2 == 0!"));
    }
  }
  else
  {
    //There are no bounding boxes, hence nothing to do.
    return;
  }
  //
  //If the domain is cropped, crop bounding boxes.
  if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //
    //Get domain.
    GetDomain(ho_ImageRaw, &ho_DomainRaw);
    //
    //Set the size of the raw image to the domain extensions.
    SmallestRectangle1(ho_DomainRaw, &hv_RowDomain1, &hv_ColumnDomain1, &hv_RowDomain2, 
        &hv_ColumnDomain2);
    hv_WidthRaw = (hv_ColumnDomain2-hv_ColumnDomain1)+1;
    hv_HeightRaw = (hv_RowDomain2-hv_RowDomain1)+1;
    //
    //Crop the bounding boxes.
    //Remove the boxes with center outside of the domain.
    hv_MaskDelete = HTuple(HTuple((hv_BBoxRow.TupleLessElem(hv_RowDomain1)).TupleOr(hv_BBoxCol.TupleLessElem(hv_ColumnDomain1))).TupleOr(hv_BBoxRow.TupleGreaterElem(hv_RowDomain2))).TupleOr(hv_BBoxCol.TupleGreaterElem(hv_ColumnDomain2));
    hv_MaskNewBbox = 1-hv_MaskDelete;
    //Store the preprocessed bounding box entries.
    hv_BBoxRowNew = (hv_BBoxRow.TupleSelectMask(hv_MaskNewBbox))-hv_RowDomain1;
    hv_BBoxColNew = (hv_BBoxCol.TupleSelectMask(hv_MaskNewBbox))-hv_ColumnDomain1;
    hv_BBoxLength1New = hv_BBoxLength1.TupleSelectMask(hv_MaskNewBbox);
    hv_BBoxLength2New = hv_BBoxLength2.TupleSelectMask(hv_MaskNewBbox);
    hv_BBoxPhiNew = hv_BBoxPhi.TupleSelectMask(hv_MaskNewBbox);
    hv_BBoxLabelNew = hv_BBoxLabel.TupleSelectMask(hv_MaskNewBbox);
    //
  }
  else if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    //If the entire image is used, set the variables accordingly.
    //Get the original size.
    GetImageSize(ho_ImageRaw, &hv_WidthRaw, &hv_HeightRaw);
    //Set new coordinates to input coordinates.
    hv_BBoxRowNew = hv_BBoxRow;
    hv_BBoxColNew = hv_BBoxCol;
    hv_BBoxLength1New = hv_BBoxLength1;
    hv_BBoxLength2New = hv_BBoxLength2;
    hv_BBoxPhiNew = hv_BBoxPhi;
    hv_BBoxLabelNew = hv_BBoxLabel;
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Generate smallest enclosing axis-aligned bounding box for classes in ClassIDsNoOrientation.
  hv_ClassIDsNoOrientationIndices = HTuple();
  {
  HTuple end_val94 = (hv_ClassIDsNoOrientation.TupleLength())-1;
  HTuple step_val94 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val94, step_val94); hv_Index += step_val94)
  {
    hv_ClassIDsNoOrientationIndicesTmp = (hv_BBoxLabelNew.TupleEqualElem(HTuple(hv_ClassIDsNoOrientation[hv_Index]))).TupleFind(1);
    if (0 != (int(hv_ClassIDsNoOrientationIndicesTmp!=-1)))
    {
      hv_ClassIDsNoOrientationIndices = hv_ClassIDsNoOrientationIndices.TupleConcat(hv_ClassIDsNoOrientationIndicesTmp);
    }
  }
  }
  if (0 != (int((hv_ClassIDsNoOrientationIndices.TupleLength())>0)))
  {
    //Calculate length1 and length2 using position of corners.
    hv_DirectionLength1Row = -(HTuple(hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices]).TupleSin());
    hv_DirectionLength1Col = HTuple(hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices]).TupleCos();
    hv_DirectionLength2Row = -hv_DirectionLength1Col;
    hv_DirectionLength2Col = hv_DirectionLength1Row;
    hv_Corner1Row = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Row)+(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Row);
    hv_Corner1Col = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Col)+(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Col);
    hv_Corner2Row = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Row)-(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Row);
    hv_Corner2Col = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Col)-(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Col);
    //
    hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices] = 0.0;
    hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices] = (hv_Corner1Col.TupleAbs()).TupleMax2(hv_Corner2Col.TupleAbs());
    hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices] = (hv_Corner1Row.TupleAbs()).TupleMax2(hv_Corner2Row.TupleAbs());
  }
  //
  //Rescale bounding boxes.
  //
  //Get required images width and height.
  //
  //Only rescale bounding boxes if the required image dimensions are not the raw dimensions.
  if (0 != (HTuple(int(hv_ImageHeight!=hv_HeightRaw)).TupleOr(int(hv_ImageWidth!=hv_WidthRaw))))
  {
    //Calculate rescaling factor.
    hv_FactorResampleWidth = (hv_ImageWidth.TupleReal())/hv_WidthRaw;
    hv_FactorResampleHeight = (hv_ImageHeight.TupleReal())/hv_HeightRaw;
    if (0 != (int(hv_FactorResampleHeight!=hv_FactorResampleWidth)))
    {
      //In order to preserve the correct orientation we have to transform the points individually.
      //Get the coordinates of the four corner points.
      convert_rect2_5to8param(hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxLength1New, hv_BBoxLength2New, 
          hv_BBoxPhiNew, &hv_BBoxRow1, &hv_BBoxCol1, &hv_BBoxRow2, &hv_BBoxCol2, 
          &hv_BBoxRow3, &hv_BBoxCol3, &hv_BBoxRow4, &hv_BBoxCol4);
      //
      //Rescale the coordinates.
      hv_BBoxCol1New = hv_BBoxCol1*hv_FactorResampleWidth;
      hv_BBoxCol2New = hv_BBoxCol2*hv_FactorResampleWidth;
      hv_BBoxCol3New = hv_BBoxCol3*hv_FactorResampleWidth;
      hv_BBoxCol4New = hv_BBoxCol4*hv_FactorResampleWidth;
      hv_BBoxRow1New = hv_BBoxRow1*hv_FactorResampleHeight;
      hv_BBoxRow2New = hv_BBoxRow2*hv_FactorResampleHeight;
      hv_BBoxRow3New = hv_BBoxRow3*hv_FactorResampleHeight;
      hv_BBoxRow4New = hv_BBoxRow4*hv_FactorResampleHeight;
      //
      //The rectangles will get sheared, that is why new rectangles have to be found.
      //Generate homography to scale rectangles.
      HomMat2dIdentity(&hv_HomMat2DIdentity);
      HomMat2dScale(hv_HomMat2DIdentity, hv_FactorResampleHeight, hv_FactorResampleWidth, 
          0, 0, &hv_HomMat2DScale);
      //Generate XLD contours for the rectangles.
      GenRectangle2ContourXld(&ho_Rectangle2XLD, hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxPhiNew, 
          hv_BBoxLength1New, hv_BBoxLength2New);
      //Scale the XLD contours --> results in sheared regions.
      AffineTransContourXld(ho_Rectangle2XLD, &ho_Rectangle2XLDSheared, hv_HomMat2DScale);
      SmallestRectangle2Xld(ho_Rectangle2XLDSheared, &hv_BBoxRowNew, &hv_BBoxColNew, 
          &hv_BBoxPhiNew, &hv_BBoxLength1New, &hv_BBoxLength2New);
      //
      //smallest_rectangle2_xld might change the orientation of the bounding box.
      //Hence, take the orientation that is closest to the one obtained out of the 4 corner points.
      convert_rect2_8to5param(hv_BBoxRow1New, hv_BBoxCol1New, hv_BBoxRow2New, hv_BBoxCol2New, 
          hv_BBoxRow3New, hv_BBoxCol3New, hv_BBoxRow4New, hv_BBoxCol4New, hv_IgnoreDirection, 
          &hv__, &hv__, &hv__, &hv__, &hv_BBoxPhiTmp);
      hv_PhiDelta = (hv_BBoxPhiTmp-hv_BBoxPhiNew).TupleFmod(HTuple(360).TupleRad());
      //Guarantee that angles are positive.
      hv_PhiDeltaNegativeIndices = (hv_PhiDelta.TupleLessElem(0.0)).TupleFind(1);
      if (0 != (int(hv_PhiDeltaNegativeIndices!=-1)))
      {
        hv_PhiDelta[hv_PhiDeltaNegativeIndices] = HTuple(hv_PhiDelta[hv_PhiDeltaNegativeIndices])+(HTuple(360).TupleRad());
      }
      hv_IndicesRot90 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(45).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(135).TupleRad()))).TupleFind(1);
      hv_IndicesRot180 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(135).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(225).TupleRad()))).TupleFind(1);
      hv_IndicesRot270 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(225).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(315).TupleRad()))).TupleFind(1);
      hv_SwapIndices = HTuple();
      if (0 != (int(hv_IndicesRot90!=-1)))
      {
        hv_BBoxPhiNew[hv_IndicesRot90] = HTuple(hv_BBoxPhiNew[hv_IndicesRot90])+(HTuple(90).TupleRad());
        hv_SwapIndices = hv_SwapIndices.TupleConcat(hv_IndicesRot90);
      }
      if (0 != (int(hv_IndicesRot180!=-1)))
      {
        hv_BBoxPhiNew[hv_IndicesRot180] = HTuple(hv_BBoxPhiNew[hv_IndicesRot180])+(HTuple(180).TupleRad());
      }
      if (0 != (int(hv_IndicesRot270!=-1)))
      {
        hv_BBoxPhiNew[hv_IndicesRot270] = HTuple(hv_BBoxPhiNew[hv_IndicesRot270])+(HTuple(270).TupleRad());
        hv_SwapIndices = hv_SwapIndices.TupleConcat(hv_IndicesRot270);
      }
      if (0 != (int(hv_SwapIndices!=HTuple())))
      {
        hv_Tmp = HTuple(hv_BBoxLength1New[hv_SwapIndices]);
        hv_BBoxLength1New[hv_SwapIndices] = HTuple(hv_BBoxLength2New[hv_SwapIndices]);
        hv_BBoxLength2New[hv_SwapIndices] = hv_Tmp;
      }
      //Change angles such that they lie in the range (-180, 180].
      hv_BBoxPhiNewIndices = (hv_BBoxPhiNew.TupleGreaterElem(HTuple(180).TupleRad())).TupleFind(1);
      if (0 != (int(hv_BBoxPhiNewIndices!=-1)))
      {
        hv_BBoxPhiNew[hv_BBoxPhiNewIndices] = HTuple(hv_BBoxPhiNew[hv_BBoxPhiNewIndices])-(HTuple(360).TupleRad());
      }
      //
    }
    else
    {
      hv_BBoxColNew = hv_BBoxColNew*hv_FactorResampleWidth;
      hv_BBoxRowNew = hv_BBoxRowNew*hv_FactorResampleWidth;
      hv_BBoxLength1New = hv_BBoxLength1New*hv_FactorResampleWidth;
      hv_BBoxLength2New = hv_BBoxLength2New*hv_FactorResampleWidth;
      //Phi stays the same.
    }
    //
  }
  //
  //Adapt the bounding box angles such that they are within the correct range,
  //which is (-180,180] for 'ignore_direction'==false and (-90,90] else.
  hv_PhiThreshold = (HTuple(180).TupleRad())-(hv_IgnoreDirection*(HTuple(90).TupleRad()));
  hv_PhiDelta = 2*hv_PhiThreshold;
  //Correct angles that are too large.
  hv_PhiToCorrect = (hv_BBoxPhiNew.TupleGreaterElem(hv_PhiThreshold)).TupleFind(1);
  if (0 != (HTuple(int(hv_PhiToCorrect!=-1)).TupleAnd(int(hv_PhiToCorrect!=HTuple()))))
  {
    hv_NumCorrections = (((HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])-hv_PhiThreshold)/hv_PhiDelta).TupleInt())+1;
    hv_BBoxPhiNew[hv_PhiToCorrect] = HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])-(hv_NumCorrections*hv_PhiDelta);
  }
  //Correct angles that are too small.
  hv_PhiToCorrect = (hv_BBoxPhiNew.TupleLessEqualElem(-hv_PhiThreshold)).TupleFind(1);
  if (0 != (HTuple(int(hv_PhiToCorrect!=-1)).TupleAnd(int(hv_PhiToCorrect!=HTuple()))))
  {
    hv_NumCorrections = ((((HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])+hv_PhiThreshold).TupleAbs())/hv_PhiDelta).TupleInt())+1;
    hv_BBoxPhiNew[hv_PhiToCorrect] = HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])+(hv_NumCorrections*hv_PhiDelta);
  }
  //
  //Check that there are no invalid boxes.
  if (0 != (int((hv_BBoxRowNew.TupleLength())>0)))
  {
    hv_BoxesInvalid = ((hv_BBoxLength1New.TupleEqualElem(0)).TupleSum())+((hv_BBoxLength2New.TupleEqualElem(0)).TupleSum());
    if (0 != (int(hv_BoxesInvalid>0)))
    {
      GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
      throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one box with zero-area, i.e. bbox_length1 == 0 or bbox_length2 == 0!"));
    }
  }
  SetDictTuple(hv_DLSample, "bbox_row", hv_BBoxRowNew);
  SetDictTuple(hv_DLSample, "bbox_col", hv_BBoxColNew);
  SetDictTuple(hv_DLSample, "bbox_length1", hv_BBoxLength1New);
  SetDictTuple(hv_DLSample, "bbox_length2", hv_BBoxLength2New);
  SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhiNew);
  SetDictTuple(hv_DLSample, "bbox_label_id", hv_BBoxLabelNew);
  //
  return;

}

// Chapter: Deep Learning / Model
// Short Description: Preprocess images for deep-learning-based training and inference. 
void preprocess_dl_model_images (HObject ho_Images, HObject *ho_ImagesPreprocessed, 
    HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_ImagesScaled, ho_ImageSelected, ho_ImageScaled;
  HObject  ho_Channel, ho_ChannelScaled, ho_ThreeChannelImage;
  HObject  ho_SingleChannelImage;

  // Local control variables
  HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
  HTuple  hv_NormalizationType, hv_ModelType, hv_NumImages;
  HTuple  hv_Type, hv_NumMatches, hv_InputNumChannels, hv_OutputNumChannels;
  HTuple  hv_NumChannels1, hv_NumChannels3, hv_AreInputNumChannels1;
  HTuple  hv_AreInputNumChannels3, hv_AreInputNumChannels1Or3;
  HTuple  hv_ValidNumChannels, hv_ValidNumChannelsText, hv_ImageIndex;
  HTuple  hv_NumChannels, hv_ChannelIndex, hv_Min, hv_Max;
  HTuple  hv_Range, hv_Scale, hv_Shift, hv_MeanValues, hv_DeviationValues;
  HTuple  hv_UseDefaultNormalizationValues, hv_Exception;
  HTuple  hv_Indices, hv_RescaleRange, hv_CurrentNumChannels;
  HTuple  hv_DiffNumChannelsIndices, hv_Index, hv_DiffNumChannelsIndex;

  //
  //This procedure preprocesses the provided Images according to the parameters in
  //the dictionary DLPreprocessParam. Note that depending on the images, additional
  //preprocessing steps might be beneficial.
  //
  //Validate the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  //Validate the type of the input images.
  CountObj(ho_Images, &hv_NumImages);
  if (0 != (int(hv_NumImages==0)))
  {
    throw HException("Please provide some images to preprocess.");
  }
  GetImageType(ho_Images, &hv_Type);
  TupleRegexpTest(hv_Type, "byte|int|real", &hv_NumMatches);
  if (0 != (int(hv_NumMatches!=hv_NumImages)))
  {
    throw HException(HTuple("Please provide only images of type 'byte', 'int1', 'int2', 'uint2', 'int4', 'int8', or 'real'."));
  }
  //
  //Validate the number channels of the input images.
  CountChannels(ho_Images, &hv_InputNumChannels);
  hv_OutputNumChannels = HTuple(hv_NumImages,hv_ImageNumChannels);
  //Only for 'image_num_channels' 1 and 3 combinations of 1- and 3-channel images are allowed.
  if (0 != (HTuple(int(hv_ImageNumChannels==1)).TupleOr(int(hv_ImageNumChannels==3))))
  {
    hv_NumChannels1 = HTuple(hv_NumImages,1);
    hv_NumChannels3 = HTuple(hv_NumImages,3);
    hv_AreInputNumChannels1 = hv_InputNumChannels.TupleEqualElem(hv_NumChannels1);
    hv_AreInputNumChannels3 = hv_InputNumChannels.TupleEqualElem(hv_NumChannels3);
    hv_AreInputNumChannels1Or3 = hv_AreInputNumChannels1+hv_AreInputNumChannels3;
    hv_ValidNumChannels = int(hv_AreInputNumChannels1Or3==hv_NumChannels1);
    hv_ValidNumChannelsText = "Valid numbers of channels for the specified model are 1 or 3.";
  }
  else
  {
    hv_ValidNumChannels = int(hv_InputNumChannels==hv_OutputNumChannels);
    hv_ValidNumChannelsText = ("Valid number of channels for the specified model is "+hv_ImageNumChannels)+".";
  }
  if (0 != (hv_ValidNumChannels.TupleNot()))
  {
    throw HException("Please provide images with a valid number of channels. "+hv_ValidNumChannelsText);
  }
  //Preprocess the images.
  //
  //Apply the domain to the images.
  if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    FullDomain(ho_Images, &ho_Images);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    CropDomain(ho_Images, &ho_Images);
  }
  else if (0 != (HTuple(int(hv_DomainHandling==HTuple("keep_domain"))).TupleAnd(int(hv_ModelType==HTuple("anomaly_detection")))))
  {
    //Anomaly detection models accept the additional option 'keep_domain'.
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'.");
  }
  //
  //Convert the images to real and zoom the images.
  //Zoom first to speed up if all image types are supported by zoom_image_size.
  if (0 != (int((hv_Type.TupleRegexpTest("int1|int4|int8"))==0)))
  {
    ZoomImageSize(ho_Images, &ho_Images, hv_ImageWidth, hv_ImageHeight, "constant");
    ConvertImageType(ho_Images, &ho_Images, "real");
  }
  else
  {
    ConvertImageType(ho_Images, &ho_Images, "real");
    ZoomImageSize(ho_Images, &ho_Images, hv_ImageWidth, hv_ImageHeight, "constant");
  }
  //
  if (0 != (int(hv_NormalizationType==HTuple("all_channels"))))
  {
    //Scale for each image the gray values of all channels to ImageRangeMin-ImageRangeMax.
    GenEmptyObj(&ho_ImagesScaled);
    {
    HTuple end_val74 = hv_NumImages;
    HTuple step_val74 = 1;
    for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val74, step_val74); hv_ImageIndex += step_val74)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
      CountChannels(ho_ImageSelected, &hv_NumChannels);
      GenEmptyObj(&ho_ImageScaled);
      {
      HTuple end_val78 = hv_NumChannels;
      HTuple step_val78 = 1;
      for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val78, step_val78); hv_ChannelIndex += step_val78)
      {
        AccessChannel(ho_ImageSelected, &ho_Channel, hv_ChannelIndex);
        MinMaxGray(ho_Channel, ho_Channel, 0, &hv_Min, &hv_Max, &hv_Range);
        if (0 != (int((hv_Max-hv_Min)==0)))
        {
          hv_Scale = 1;
        }
        else
        {
          hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
        }
        hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
        ScaleImage(ho_Channel, &ho_ChannelScaled, hv_Scale, hv_Shift);
        AppendChannel(ho_ImageScaled, ho_ChannelScaled, &ho_ImageScaled);
      }
      }
      ConcatObj(ho_ImagesScaled, ho_ImageScaled, &ho_ImagesScaled);
    }
    }
    ho_Images = ho_ImagesScaled;
  }
  else if (0 != (int(hv_NormalizationType==HTuple("first_channel"))))
  {
    //Scale for each image the gray values of first channel to ImageRangeMin-ImageRangeMax.
    GenEmptyObj(&ho_ImagesScaled);
    {
    HTuple end_val96 = hv_NumImages;
    HTuple step_val96 = 1;
    for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val96, step_val96); hv_ImageIndex += step_val96)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
      MinMaxGray(ho_ImageSelected, ho_ImageSelected, 0, &hv_Min, &hv_Max, &hv_Range);
      if (0 != (int((hv_Max-hv_Min)==0)))
      {
        hv_Scale = 1;
      }
      else
      {
        hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
      }
      hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
      ScaleImage(ho_ImageSelected, &ho_ImageSelected, hv_Scale, hv_Shift);
      ConcatObj(ho_ImagesScaled, ho_ImageSelected, &ho_ImagesScaled);
    }
    }
    ho_Images = ho_ImagesScaled;
  }
  else if (0 != (int(hv_NormalizationType==HTuple("constant_values"))))
  {
    //Scale for each image the gray values of all channels to the corresponding channel DeviationValues[].
    try
    {
      GetDictTuple(hv_DLPreprocessParam, "mean_values_normalization", &hv_MeanValues);
      GetDictTuple(hv_DLPreprocessParam, "deviation_values_normalization", &hv_DeviationValues);
      hv_UseDefaultNormalizationValues = 0;
    }
    // catch (Exception) 
    catch (HException &HDevExpDefaultException)
    {
      HDevExpDefaultException.ToHTuple(&hv_Exception);
      hv_MeanValues.Clear();
      hv_MeanValues[0] = 123.675;
      hv_MeanValues[1] = 116.28;
      hv_MeanValues[2] = 103.53;
      hv_DeviationValues.Clear();
      hv_DeviationValues[0] = 58.395;
      hv_DeviationValues[1] = 57.12;
      hv_DeviationValues[2] = 57.375;
      hv_UseDefaultNormalizationValues = 1;
    }
    GenEmptyObj(&ho_ImagesScaled);
    {
    HTuple end_val121 = hv_NumImages;
    HTuple step_val121 = 1;
    for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val121, step_val121); hv_ImageIndex += step_val121)
    {
      SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
      CountChannels(ho_ImageSelected, &hv_NumChannels);
      //Ensure that the number of channels is equal |DeviationValues| and |MeanValues|
      if (0 != hv_UseDefaultNormalizationValues)
      {
        if (0 != (int(hv_NumChannels==1)))
        {
          Compose3(ho_ImageSelected, ho_ImageSelected, ho_ImageSelected, &ho_ImageSelected
              );
          CountChannels(ho_ImageSelected, &hv_NumChannels);
        }
        else if (0 != (int(hv_NumChannels!=3)))
        {
          throw HException("Using default values for normalization type 'constant_values' is allowed only for 1- and 3-channel images.");
        }
      }
      if (0 != (HTuple(int((hv_MeanValues.TupleLength())!=hv_NumChannels)).TupleOr(int((hv_DeviationValues.TupleLength())!=hv_NumChannels))))
      {
        throw HException("The length of mean and deviation values for normalization type 'constant_values' have to be the same size as the number of channels of the image.");
      }
      GenEmptyObj(&ho_ImageScaled);
      {
      HTuple end_val137 = hv_NumChannels;
      HTuple step_val137 = 1;
      for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val137, step_val137); hv_ChannelIndex += step_val137)
      {
        AccessChannel(ho_ImageSelected, &ho_Channel, hv_ChannelIndex);
        hv_Scale = 1.0/HTuple(hv_DeviationValues[hv_ChannelIndex-1]);
        hv_Shift = (-hv_Scale)*HTuple(hv_MeanValues[hv_ChannelIndex-1]);
        ScaleImage(ho_Channel, &ho_ChannelScaled, hv_Scale, hv_Shift);
        AppendChannel(ho_ImageScaled, ho_ChannelScaled, &ho_ImageScaled);
      }
      }
      ConcatObj(ho_ImagesScaled, ho_ImageScaled, &ho_ImagesScaled);
    }
    }
    ho_Images = ho_ImagesScaled;
  }
  else if (0 != (int(hv_NormalizationType==HTuple("none"))))
  {
    TupleFind(hv_Type, "byte", &hv_Indices);
    if (0 != (int(hv_Indices!=-1)))
    {
      //Shift the gray values from [0-255] to the expected range for byte images.
      hv_RescaleRange = (hv_ImageRangeMax-hv_ImageRangeMin)/255.0;
      SelectObj(ho_Images, &ho_ImageSelected, hv_Indices+1);
      ScaleImage(ho_ImageSelected, &ho_ImageSelected, hv_RescaleRange, hv_ImageRangeMin);
      ReplaceObj(ho_Images, ho_ImageSelected, &ho_Images, hv_Indices+1);
    }
  }
  else if (0 != (int(hv_NormalizationType!=HTuple("none"))))
  {
    throw HException("Unsupported parameter value for 'normalization_type'");
  }
  //
  //Ensure that the number of channels of the resulting images is consistent with the
  //number of channels of the given model. The only exceptions that are adapted below
  //are combinations of 1- and 3-channel images if ImageNumChannels is either 1 or 3.
  if (0 != (HTuple(int(hv_ImageNumChannels==1)).TupleOr(int(hv_ImageNumChannels==3))))
  {
    CountChannels(ho_Images, &hv_CurrentNumChannels);
    TupleFind(hv_CurrentNumChannels.TupleNotEqualElem(hv_OutputNumChannels), 1, &hv_DiffNumChannelsIndices);
    if (0 != (int(hv_DiffNumChannelsIndices!=-1)))
    {
      {
      HTuple end_val167 = (hv_DiffNumChannelsIndices.TupleLength())-1;
      HTuple step_val167 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val167, step_val167); hv_Index += step_val167)
      {
        hv_DiffNumChannelsIndex = HTuple(hv_DiffNumChannelsIndices[hv_Index]);
        hv_ImageIndex = hv_DiffNumChannelsIndex+1;
        hv_NumChannels = HTuple(hv_CurrentNumChannels[hv_ImageIndex-1]);
        SelectObj(ho_Images, &ho_ImageSelected, hv_ImageIndex);
        if (0 != (HTuple(int(hv_NumChannels==1)).TupleAnd(int(hv_ImageNumChannels==3))))
        {
          //Conversion from 1- to 3-channel image required
          Compose3(ho_ImageSelected, ho_ImageSelected, ho_ImageSelected, &ho_ThreeChannelImage
              );
          ReplaceObj(ho_Images, ho_ThreeChannelImage, &ho_Images, hv_ImageIndex);
        }
        else if (0 != (HTuple(int(hv_NumChannels==3)).TupleAnd(int(hv_ImageNumChannels==1))))
        {
          //Conversion from 3- to 1-channel image required
          Rgb1ToGray(ho_ImageSelected, &ho_SingleChannelImage);
          ReplaceObj(ho_Images, ho_SingleChannelImage, &ho_Images, hv_ImageIndex);
        }
        else
        {
          throw HException(((("Unexpected error adapting the number of channels. The number of channels of the resulting image is "+hv_NumChannels)+HTuple(", but the number of channels of the model is "))+hv_ImageNumChannels)+".");
        }
      }
      }
    }
  }
  //
  //Write preprocessed images to output variable.
  (*ho_ImagesPreprocessed) = ho_Images;
  //
  return;
}

// Chapter: Deep Learning / Semantic Segmentation
// Short Description: Preprocess segmentation and weight images for deep-learning-based segmentation training and inference. 
void preprocess_dl_model_segmentations (HObject ho_ImagesRaw, HObject ho_Segmentations, 
    HObject *ho_SegmentationsPreprocessed, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_Domain, ho_SelectedSeg, ho_SelectedDomain;

  // Local control variables
  HTuple  hv_NumberImages, hv_NumberSegmentations;
  HTuple  hv_Width, hv_Height, hv_WidthSeg, hv_HeightSeg;
  HTuple  hv_DLModelType, hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
  HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
  HTuple  hv_SetBackgroundID, hv_ClassesToBackground, hv_IgnoreClassIDs;
  HTuple  hv_IsInt, hv_IndexImage, hv_ImageWidthRaw, hv_ImageHeightRaw;
  HTuple  hv_EqualWidth, hv_EqualHeight, hv_Type, hv_EqualReal;

  //
  //This procedure preprocesses the segmentation or weight images
  //given by Segmentations so that they can be handled by
  //train_dl_model_batch and apply_dl_model.
  //
  //Check input data.
  //Examine number of images.
  CountObj(ho_ImagesRaw, &hv_NumberImages);
  CountObj(ho_Segmentations, &hv_NumberSegmentations);
  if (0 != (int(hv_NumberImages!=hv_NumberSegmentations)))
  {
    throw HException("Equal number of images given in ImagesRaw and Segmentations required");
  }
  //Size of images.
  GetImageSize(ho_ImagesRaw, &hv_Width, &hv_Height);
  GetImageSize(ho_Segmentations, &hv_WidthSeg, &hv_HeightSeg);
  if (0 != (HTuple(int(hv_Width!=hv_WidthSeg)).TupleOr(int(hv_Height!=hv_HeightSeg))))
  {
    throw HException("Equal size of the images given in ImagesRaw and Segmentations required.");
  }
  //Check the validity of the preprocessing parameters.
  check_dl_preprocess_param(hv_DLPreprocessParam);
  //
  //Get the relevant preprocessing parameters.
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_DLModelType);
  GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
  GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
  GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
  GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
  GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
  GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
  //Segmentation specific parameters.
  GetDictTuple(hv_DLPreprocessParam, "set_background_id", &hv_SetBackgroundID);
  GetDictTuple(hv_DLPreprocessParam, "class_ids_background", &hv_ClassesToBackground);
  GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
  //
  //Check the input parameter for setting the background ID.
  if (0 != (int(hv_SetBackgroundID!=HTuple())))
  {
    //Check that the model is a segmentation model.
    if (0 != (int(hv_DLModelType!=HTuple("segmentation"))))
    {
      throw HException("Setting class IDs to background is only implemented for segmentation.");
    }
    //Check the background ID.
    TupleIsIntElem(hv_SetBackgroundID, &hv_IsInt);
    if (0 != (int((hv_SetBackgroundID.TupleLength())!=1)))
    {
      throw HException("Only one class_id as 'set_background_id' allowed.");
    }
    else if (0 != (hv_IsInt.TupleNot()))
    {
      //Given class_id has to be of type int.
      throw HException("The class_id given as 'set_background_id' has to be of type int.");
    }
    //Check the values of ClassesToBackground.
    if (0 != (int((hv_ClassesToBackground.TupleLength())==0)))
    {
      //Check that the given classes are of length > 0.
      throw HException(HTuple("If 'set_background_id' is given, 'class_ids_background' must at least contain this class ID."));
    }
    else if (0 != (int((hv_ClassesToBackground.TupleIntersection(hv_IgnoreClassIDs))!=HTuple())))
    {
      //Check that class_ids_background is not included in the ignore_class_ids of the DLModel.
      throw HException("The given 'class_ids_background' must not be included in the 'ignore_class_ids' of the model.");
    }
  }
  //
  //Domain handling of the image to be preprocessed.
  //
  if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
  {
    FullDomain(ho_Segmentations, &ho_Segmentations);
  }
  else if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
  {
    //If the domain should be cropped the domain has to be transferred
    //from the raw image to the segmentation image.
    GetDomain(ho_ImagesRaw, &ho_Domain);
    {
    HTuple end_val66 = hv_NumberImages;
    HTuple step_val66 = 1;
    for (hv_IndexImage=1; hv_IndexImage.Continue(end_val66, step_val66); hv_IndexImage += step_val66)
    {
      SelectObj(ho_Segmentations, &ho_SelectedSeg, hv_IndexImage);
      SelectObj(ho_Domain, &ho_SelectedDomain, hv_IndexImage);
      ChangeDomain(ho_SelectedSeg, ho_SelectedDomain, &ho_SelectedSeg);
      ReplaceObj(ho_Segmentations, ho_SelectedSeg, &ho_Segmentations, hv_IndexImage);
    }
    }
    CropDomain(ho_Segmentations, &ho_Segmentations);
  }
  else
  {
    throw HException("Unsupported parameter value for 'domain_handling'");
  }
  //
  //Preprocess the segmentation images.
  //
  //Set all background classes to the given background class ID.
  if (0 != (int(hv_SetBackgroundID!=HTuple())))
  {
    reassign_pixel_values(ho_Segmentations, &ho_Segmentations, hv_ClassesToBackground, 
        hv_SetBackgroundID);
  }
  //
  //Zoom images only if they have a different size than the specified size.
  GetImageSize(ho_Segmentations, &hv_ImageWidthRaw, &hv_ImageHeightRaw);
  hv_EqualWidth = hv_ImageWidth.TupleEqualElem(hv_ImageWidthRaw);
  hv_EqualHeight = hv_ImageHeight.TupleEqualElem(hv_ImageHeightRaw);
  if (0 != (HTuple(int((hv_EqualWidth.TupleMin())==0)).TupleOr(int((hv_EqualHeight.TupleMin())==0))))
  {
    ZoomImageSize(ho_Segmentations, &ho_Segmentations, hv_ImageWidth, hv_ImageHeight, 
        "nearest_neighbor");
  }
  //
  //Check the type of the input images
  //and convert if necessary.
  GetImageType(ho_Segmentations, &hv_Type);
  hv_EqualReal = hv_Type.TupleEqualElem("real");
  //
  if (0 != (int((hv_EqualReal.TupleMin())==0)))
  {
    //Convert the image type to 'real',
    //because the model expects 'real' images.
    ConvertImageType(ho_Segmentations, &ho_Segmentations, "real");
  }
  //
  //Write preprocessed Segmentations to output variable.
  (*ho_SegmentationsPreprocessed) = ho_Segmentations;
  return;
}

// Chapter: Deep Learning / Model
// Short Description: Preprocess given DLSamples according to the preprocessing parameters given in DLPreprocessParam. 
void preprocess_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_DLPreprocessParam)
{

  // Local iconic variables
  HObject  ho_ImageRaw, ho_ImagePreprocessed, ho_AnomalyImageRaw;
  HObject  ho_AnomalyImagePreprocessed, ho_SegmentationRaw;
  HObject  ho_SegmentationPreprocessed;

  // Local control variables
  HTuple  hv_ModelType, hv_SampleIndex, hv_ImageExists;
  HTuple  hv_KeysExists, hv_AnomalyParamExist, hv_Rectangle1ParamExist;
  HTuple  hv_Rectangle2ParamExist, hv_SegmentationParamExist;

  //
  //This procedure preprocesses all images of the sample dictionaries in the tuple DLSampleBatch.
  //The images are preprocessed according to the parameters provided in DLPreprocessParam.
  //
  //Check the validity of the preprocessing parameters.
  //The procedure check_dl_preprocess_param might change DLPreprocessParam. To avoid race
  //conditions when preprocess_dl_samples is used from multiple threads with the same
  //DLPreprocessParam dictionary, work on a copy.
  CopyDict(hv_DLPreprocessParam, HTuple(), HTuple(), &hv_DLPreprocessParam);
  check_dl_preprocess_param(hv_DLPreprocessParam);
  GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
  //
  //Preprocess the sample entries.
  //
  {
  HTuple end_val14 = (hv_DLSampleBatch.TupleLength())-1;
  HTuple step_val14 = 1;
  for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val14, step_val14); hv_SampleIndex += step_val14)
  {
    //
    //Check the existence of the sample keys.
    GetDictParam(HTuple(hv_DLSampleBatch[hv_SampleIndex]), "key_exists", "image", 
        &hv_ImageExists);
    //
    //Preprocess the images.
    if (0 != hv_ImageExists)
    {
      //
      //Get the image.
      GetDictObject(&ho_ImageRaw, HTuple(hv_DLSampleBatch[hv_SampleIndex]), "image");
      //
      //Preprocess the image.
      preprocess_dl_model_images(ho_ImageRaw, &ho_ImagePreprocessed, hv_DLPreprocessParam);
      //
      //Replace the image in the dictionary.
      SetDictObject(ho_ImagePreprocessed, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
          "image");
      //
      //Check existence of model specific sample keys:
      //- bbox_row1 for 'rectangle1'
      //- bbox_phi for 'rectangle2'
      //- segmentation_image for 'semantic segmentation'
      GetDictParam(HTuple(hv_DLSampleBatch[hv_SampleIndex]), "key_exists", (((HTuple("anomaly_ground_truth").Append("bbox_row1")).Append("bbox_phi")).Append("segmentation_image")), 
          &hv_KeysExists);
      hv_AnomalyParamExist = ((const HTuple&)hv_KeysExists)[0];
      hv_Rectangle1ParamExist = ((const HTuple&)hv_KeysExists)[1];
      hv_Rectangle2ParamExist = ((const HTuple&)hv_KeysExists)[2];
      hv_SegmentationParamExist = ((const HTuple&)hv_KeysExists)[3];
      //
      //Preprocess the anomaly ground truth if present.
      if (0 != hv_AnomalyParamExist)
      {
        //
        //Get the anomaly image.
        GetDictObject(&ho_AnomalyImageRaw, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
            "anomaly_ground_truth");
        //
        //Preprocess the anomaly image.
        preprocess_dl_model_anomaly(ho_AnomalyImageRaw, &ho_AnomalyImagePreprocessed, 
            hv_DLPreprocessParam);
        //
        //Set preprocessed anomaly image.
        SetDictObject(ho_AnomalyImagePreprocessed, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
            "anomaly_ground_truth");
      }
      //
      //Preprocess depending on the model type.
      //If bounding boxes are given, rescale them as well.
      if (0 != hv_Rectangle1ParamExist)
      {
        //
        //Preprocess the bounding boxes of type 'rectangle1'.
        preprocess_dl_model_bbox_rect1(ho_ImageRaw, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
            hv_DLPreprocessParam);
      }
      else if (0 != hv_Rectangle2ParamExist)
      {
        //
        //Preprocess the bounding boxes of type 'rectangle2'.
        preprocess_dl_model_bbox_rect2(ho_ImageRaw, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
            hv_DLPreprocessParam);
      }
      //
      //Preprocess the segmentation image if present.
      if (0 != hv_SegmentationParamExist)
      {
        //
        //Get the segmentation image.
        GetDictObject(&ho_SegmentationRaw, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
            "segmentation_image");
        //
        //Preprocess the segmentation image.
        preprocess_dl_model_segmentations(ho_ImageRaw, ho_SegmentationRaw, &ho_SegmentationPreprocessed, 
            hv_DLPreprocessParam);
        //
        //Set preprocessed segmentation image.
        SetDictObject(ho_SegmentationPreprocessed, HTuple(hv_DLSampleBatch[hv_SampleIndex]), 
            "segmentation_image");
      }
    }
    else
    {
      throw HException((HTuple("All samples processed need to include an image, but the sample with index ")+hv_SampleIndex)+" does not.");
    }
  }
  }
  //
  return;
}

// Chapter: Image / Manipulation
// Short Description: Changes a value of ValuesToChange in Image to NewValue. 
void reassign_pixel_values (HObject ho_Image, HObject *ho_ImageOut, HTuple hv_ValuesToChange, 
    HTuple hv_NewValue)
{

  // Local iconic variables
  HObject  ho_RegionToChange, ho_RegionClass;

  // Local control variables
  HTuple  hv_IndexReset;

  //
  //This procedure sets all pixels of Image
  //with the values given in ValuesToChange to the given value NewValue.
  //
  GenEmptyRegion(&ho_RegionToChange);
  {
  HTuple end_val5 = (hv_ValuesToChange.TupleLength())-1;
  HTuple step_val5 = 1;
  for (hv_IndexReset=0; hv_IndexReset.Continue(end_val5, step_val5); hv_IndexReset += step_val5)
  {
    Threshold(ho_Image, &ho_RegionClass, HTuple(hv_ValuesToChange[hv_IndexReset]), 
        HTuple(hv_ValuesToChange[hv_IndexReset]));
    Union2(ho_RegionToChange, ho_RegionClass, &ho_RegionToChange);
  }
  }
  OverpaintRegion(ho_Image, ho_RegionToChange, hv_NewValue, "fill");
  (*ho_ImageOut) = ho_Image;
  return;
}

// Chapter: Deep Learning / Model
// Short Description: This procedure replaces legacy preprocessing parameters. 
void replace_legacy_preprocessing_parameters (HTuple hv_DLPreprocessParam)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Exception, hv_NormalizationTypeExists;
  HTuple  hv_NormalizationType, hv_LegacyNormalizationKeyExists;
  HTuple  hv_ContrastNormalization;

  //
  //This procedure adapts the dictionary DLPreprocessParam
  //if a legacy preprocessing parameter is set.
  //
  //Map legacy value set to new parameter.
  hv_Exception = 0;
  try
  {
    GetDictParam(hv_DLPreprocessParam, "key_exists", "normalization_type", &hv_NormalizationTypeExists);
    //
    if (0 != hv_NormalizationTypeExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
      if (0 != (int(hv_NormalizationType==HTuple("true"))))
      {
        hv_NormalizationType = "first_channel";
      }
      else if (0 != (int(hv_NormalizationType==HTuple("false"))))
      {
        hv_NormalizationType = "none";
      }
      SetDictTuple(hv_DLPreprocessParam, "normalization_type", hv_NormalizationType);
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  //Map legacy parameter to new parameter and corresponding value.
  hv_Exception = 0;
  try
  {
    GetDictParam(hv_DLPreprocessParam, "key_exists", "contrast_normalization", &hv_LegacyNormalizationKeyExists);
    if (0 != hv_LegacyNormalizationKeyExists)
    {
      GetDictTuple(hv_DLPreprocessParam, "contrast_normalization", &hv_ContrastNormalization);
      //Replace 'contrast_normalization' by 'normalization_type'.
      if (0 != (int(hv_ContrastNormalization==HTuple("false"))))
      {
        SetDictTuple(hv_DLPreprocessParam, "normalization_type", "none");
      }
      else if (0 != (int(hv_ContrastNormalization==HTuple("true"))))
      {
        SetDictTuple(hv_DLPreprocessParam, "normalization_type", "first_channel");
      }
      RemoveDictKey(hv_DLPreprocessParam, "contrast_normalization");
    }
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  return;
}

// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255] 
void scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min, 
    HTuple hv_Max)
{

  // Local iconic variables
  HObject  ho_ImageSelected, ho_SelectedChannel;
  HObject  ho_LowerRegion, ho_UpperRegion, ho_ImageSelectedScaled;

  // Local control variables
  HTuple  hv_LowerLimit, hv_UpperLimit, hv_Mult;
  HTuple  hv_Add, hv_NumImages, hv_ImageIndex, hv_Channels;
  HTuple  hv_ChannelIndex, hv_MinGray, hv_MaxGray, hv_Range;

  //Convenience procedure to scale the gray values of the
  //input image Image from the interval [Min,Max]
  //to the interval [0,255] (default).
  //Gray values < 0 or > 255 (after scaling) are clipped.
  //
  //If the image shall be scaled to an interval different from [0,255],
  //this can be achieved by passing tuples with 2 values [From, To]
  //as Min and Max.
  //Example:
  //scale_image_range(Image:ImageScaled:[100,50],[200,250])
  //maps the gray values of Image from the interval [100,200] to [50,250].
  //All other gray values will be clipped.
  //
  //input parameters:
  //Image: the input image
  //Min: the minimum gray value which will be mapped to 0
  //     If a tuple with two values is given, the first value will
  //     be mapped to the second value.
  //Max: The maximum gray value which will be mapped to 255
  //     If a tuple with two values is given, the first value will
  //     be mapped to the second value.
  //
  //Output parameter:
  //ImageScale: the resulting scaled image.
  //
  if (0 != (int((hv_Min.TupleLength())==2)))
  {
    hv_LowerLimit = ((const HTuple&)hv_Min)[1];
    hv_Min = ((const HTuple&)hv_Min)[0];
  }
  else
  {
    hv_LowerLimit = 0.0;
  }
  if (0 != (int((hv_Max.TupleLength())==2)))
  {
    hv_UpperLimit = ((const HTuple&)hv_Max)[1];
    hv_Max = ((const HTuple&)hv_Max)[0];
  }
  else
  {
    hv_UpperLimit = 255.0;
  }
  //
  //Calculate scaling parameters.
  //Only scale if the scaling range is not zero.
  if (0 != (HTuple(int(((hv_Max-hv_Min).TupleAbs())<1.0E-6)).TupleNot()))
  {
    hv_Mult = ((hv_UpperLimit-hv_LowerLimit).TupleReal())/(hv_Max-hv_Min);
    hv_Add = ((-hv_Mult)*hv_Min)+hv_LowerLimit;
    //Scale image.
    ScaleImage(ho_Image, &ho_Image, hv_Mult, hv_Add);
  }
  //
  //Clip gray values if necessary.
  //This must be done for each image and channel separately.
  GenEmptyObj(&(*ho_ImageScaled));
  CountObj(ho_Image, &hv_NumImages);
  {
  HTuple end_val51 = hv_NumImages;
  HTuple step_val51 = 1;
  for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val51, step_val51); hv_ImageIndex += step_val51)
  {
    SelectObj(ho_Image, &ho_ImageSelected, hv_ImageIndex);
    CountChannels(ho_ImageSelected, &hv_Channels);
    {
    HTuple end_val54 = hv_Channels;
    HTuple step_val54 = 1;
    for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val54, step_val54); hv_ChannelIndex += step_val54)
    {
      AccessChannel(ho_ImageSelected, &ho_SelectedChannel, hv_ChannelIndex);
      MinMaxGray(ho_SelectedChannel, ho_SelectedChannel, 0, &hv_MinGray, &hv_MaxGray, 
          &hv_Range);
      Threshold(ho_SelectedChannel, &ho_LowerRegion, (hv_MinGray.TupleConcat(hv_LowerLimit)).TupleMin(), 
          hv_LowerLimit);
      Threshold(ho_SelectedChannel, &ho_UpperRegion, hv_UpperLimit, (hv_UpperLimit.TupleConcat(hv_MaxGray)).TupleMax());
      PaintRegion(ho_LowerRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_LowerLimit, 
          "fill");
      PaintRegion(ho_UpperRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_UpperLimit, 
          "fill");
      if (0 != (int(hv_ChannelIndex==1)))
      {
        CopyObj(ho_SelectedChannel, &ho_ImageSelectedScaled, 1, 1);
      }
      else
      {
        AppendChannel(ho_ImageSelectedScaled, ho_SelectedChannel, &ho_ImageSelectedScaled
            );
      }
    }
    }
    ConcatObj((*ho_ImageScaled), ho_ImageSelectedScaled, &(*ho_ImageScaled));
  }
  }
  return;
}

// Chapter: Graphics / Text
// Short Description: Set font independent of OS 
void set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold, 
    HTuple hv_Slant)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_OS, hv_Fonts, hv_Style, hv_Exception;
  HTuple  hv_AvailableFonts, hv_Fdx, hv_Indices;

  //This procedure sets the text font of the current window with
  //the specified attributes.
  //
  //Input parameters:
  //WindowHandle: The graphics window for which the font will be set
  //Size: The font size. If Size=-1, the default of 16 is used.
  //Bold: If set to 'true', a bold font is used
  //Slant: If set to 'true', a slanted font is used
  //
  GetSystem("operating_system", &hv_OS);
  if (0 != (HTuple(int(hv_Size==HTuple())).TupleOr(int(hv_Size==-1))))
  {
    hv_Size = 16;
  }
  if (0 != (int((hv_OS.TupleSubstr(0,2))==HTuple("Win"))))
  {
    //Restore previous behaviour
    hv_Size = (1.13677*hv_Size).TupleInt();
  }
  else
  {
    hv_Size = hv_Size.TupleInt();
  }
  if (0 != (int(hv_Font==HTuple("Courier"))))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Courier";
    hv_Fonts[1] = "Courier 10 Pitch";
    hv_Fonts[2] = "Courier New";
    hv_Fonts[3] = "CourierNew";
    hv_Fonts[4] = "Liberation Mono";
  }
  else if (0 != (int(hv_Font==HTuple("mono"))))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Consolas";
    hv_Fonts[1] = "Menlo";
    hv_Fonts[2] = "Courier";
    hv_Fonts[3] = "Courier 10 Pitch";
    hv_Fonts[4] = "FreeMono";
    hv_Fonts[5] = "Liberation Mono";
  }
  else if (0 != (int(hv_Font==HTuple("sans"))))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Luxi Sans";
    hv_Fonts[1] = "DejaVu Sans";
    hv_Fonts[2] = "FreeSans";
    hv_Fonts[3] = "Arial";
    hv_Fonts[4] = "Liberation Sans";
  }
  else if (0 != (int(hv_Font==HTuple("serif"))))
  {
    hv_Fonts.Clear();
    hv_Fonts[0] = "Times New Roman";
    hv_Fonts[1] = "Luxi Serif";
    hv_Fonts[2] = "DejaVu Serif";
    hv_Fonts[3] = "FreeSerif";
    hv_Fonts[4] = "Utopia";
    hv_Fonts[5] = "Liberation Serif";
  }
  else
  {
    hv_Fonts = hv_Font;
  }
  hv_Style = "";
  if (0 != (int(hv_Bold==HTuple("true"))))
  {
    hv_Style += HTuple("Bold");
  }
  else if (0 != (int(hv_Bold!=HTuple("false"))))
  {
    hv_Exception = "Wrong value of control parameter Bold";
    throw HException(hv_Exception);
  }
  if (0 != (int(hv_Slant==HTuple("true"))))
  {
    hv_Style += HTuple("Italic");
  }
  else if (0 != (int(hv_Slant!=HTuple("false"))))
  {
    hv_Exception = "Wrong value of control parameter Slant";
    throw HException(hv_Exception);
  }
  if (0 != (int(hv_Style==HTuple(""))))
  {
    hv_Style = "Normal";
  }
  QueryFont(hv_WindowHandle, &hv_AvailableFonts);
  hv_Font = "";
  {
  HTuple end_val48 = (hv_Fonts.TupleLength())-1;
  HTuple step_val48 = 1;
  for (hv_Fdx=0; hv_Fdx.Continue(end_val48, step_val48); hv_Fdx += step_val48)
  {
    hv_Indices = hv_AvailableFonts.TupleFind(HTuple(hv_Fonts[hv_Fdx]));
    if (0 != (int((hv_Indices.TupleLength())>0)))
    {
      if (0 != (int(HTuple(hv_Indices[0])>=0)))
      {
        hv_Font = HTuple(hv_Fonts[hv_Fdx]);
        break;
      }
    }
  }
  }
  if (0 != (int(hv_Font==HTuple(""))))
  {
    throw HException("Wrong value of control parameter Font");
  }
  hv_Font = (((hv_Font+"-")+hv_Style)+"-")+hv_Size;
  SetFont(hv_WindowHandle, hv_Font);
  return;
}

// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly. 
void tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShuffleIndices;

  //This procedure sorts the input tuple randomly.
  //
  if (0 != (int((hv_Tuple.TupleLength())>0)))
  {
    //Create a tuple of random numbers,
    //sort this tuple, and return the indices
    //of this sorted tuple.
    hv_ShuffleIndices = HTuple::TupleRand(hv_Tuple.TupleLength()).TupleSortIndex();
    //Assign the elements of Tuple
    //to these random positions.
    (*hv_Shuffled) = HTuple(hv_Tuple[hv_ShuffleIndices]);
  }
  else
  {
    //If the input tuple is empty,
    //an empty tuple should be returned.
    (*hv_Shuffled) = HTuple();
  }
  return;
}

// Chapter: Graphics / Window
// Short Description: This procedure sets and returns meta information to display images correctly. 
void update_window_meta_information (HTuple hv_WindowHandle, HTuple hv_WidthImage, 
    HTuple hv_HeightImage, HTuple hv_WindowRow1, HTuple hv_WindowColumn1, HTuple hv_MapColorBarWidth, 
    HTuple hv_MarginBottom, HTuple *hv_WindowImageRatioHeight, HTuple *hv_WindowImageRatioWidth, 
    HTuple *hv_SetPartRow2, HTuple *hv_SetPartColumn2, HTuple *hv_PrevWindowCoordinatesOut)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv__, hv_WindowWidth, hv_WindowHeight;
  HTuple  hv_WindowRow2, hv_WindowColumn2, hv_WindowRatio;
  HTuple  hv_ImageRow2, hv_ImageColumn2, hv_ImageRatio, hv_ImageWindowRatioHeight;
  HTuple  hv_ImageRow2InWindow, hv_ImageCol2InWindow;

  //
  //This procedure sets and returns meta information to display images correctly.
  //
  //Set part for the image to be displayed later and adapt window size (+ MarginBottom + MapColorBarWidth).
  GetWindowExtents(hv_WindowHandle, &hv__, &hv__, &hv_WindowWidth, &hv_WindowHeight);
  (*hv_WindowImageRatioHeight) = hv_WindowHeight/(hv_HeightImage*1.0);
  (*hv_WindowImageRatioWidth) = hv_WindowWidth/(hv_WidthImage*1.0);
  //
  //Set window part such that image is displayed undistorted.
  hv_WindowRow2 = hv_WindowHeight;
  hv_WindowColumn2 = hv_WindowWidth;
  hv_WindowRatio = hv_WindowColumn2/(hv_WindowRow2*1.0);
  //
  hv_ImageRow2 = hv_HeightImage+(hv_MarginBottom/(*hv_WindowImageRatioHeight));
  hv_ImageColumn2 = hv_WidthImage+(hv_MapColorBarWidth/(*hv_WindowImageRatioWidth));
  hv_ImageRatio = hv_ImageColumn2/(hv_ImageRow2*1.0);
  if (0 != (int(hv_ImageRatio>hv_WindowRatio)))
  {
    //
    //Extend image until right window border.
    (*hv_SetPartColumn2) = hv_ImageColumn2;
    hv_ImageWindowRatioHeight = hv_ImageColumn2/(hv_WindowColumn2*1.0);
    hv_ImageRow2InWindow = hv_ImageRow2/hv_ImageWindowRatioHeight;
    (*hv_SetPartRow2) = hv_ImageRow2+((hv_WindowRow2-hv_ImageRow2InWindow)/(*hv_WindowImageRatioWidth));
  }
  else
  {
    //
    //Extend image until bottom of window.
    (*hv_SetPartRow2) = hv_ImageRow2;
    hv_ImageWindowRatioHeight = hv_ImageRow2/(hv_WindowRow2*1.0);
    hv_ImageCol2InWindow = hv_ImageColumn2/hv_ImageWindowRatioHeight;
    (*hv_SetPartColumn2) = hv_ImageColumn2+((hv_WindowColumn2-hv_ImageCol2InWindow)/(*hv_WindowImageRatioHeight));
  }
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, (*hv_SetPartRow2)-1, (*hv_SetPartColumn2)-1);
  //
  //Return the coordinates of the new window.
  (*hv_PrevWindowCoordinatesOut).Clear();
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowRow1);
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowColumn1);
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowWidth);
  (*hv_PrevWindowCoordinatesOut).Append(hv_WindowHeight);
  //
  return;
}

// Local procedures 
void check_data_availability (HTuple hv_ExampleDataDir, HTuple hv_PreprocessParamFileName, 
    HTuple hv_TrainedModelFileName, HTuple hv_UsePretrainedModel)
{

  // Local control variables
  HTuple  hv_FileExists;

  //This procedure checks if all necessary files are available.
  //
  FileExists(hv_ExampleDataDir, &hv_FileExists);
  if (0 != (hv_FileExists.TupleNot()))
  {
    throw HException(hv_ExampleDataDir+" does not exist. Please run part 1 and 2 of example series.");
  }

  FileExists(hv_PreprocessParamFileName, &hv_FileExists);
  if (0 != (hv_FileExists.TupleNot()))
  {
    throw HException(hv_PreprocessParamFileName+" does not exist. Please run part 1 of example series.");
  }
  //
  FileExists(hv_TrainedModelFileName, &hv_FileExists);
  if (0 != (hv_FileExists.TupleNot()))
  {
    if (0 != hv_UsePretrainedModel)
    {
      throw HException(hv_TrainedModelFileName+" does not exist. Please run the HALCON Deep Learning installer.");
    }
    else
    {
      throw HException(hv_TrainedModelFileName+" does not exist. Please run part 2 of example series.");
    }
  }
  //
  return;
}

void create_counting_result_text (HTuple hv_NumberDetectionsPerClass, HTuple hv_ClassNames, 
    HTuple *hv_Text, HTuple *hv_TextColor, HTuple *hv_TextBoxColor)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_Indices, hv_PillsDuplicateTuple, hv_PillsDuplicateString;
  HTuple  hv_Index, hv_PillsMissingTuple, hv_PillsMissingString;
  HTuple  hv_AddTab;

  //This procedure returns a text containing the result of the counting.
  //
  (*hv_Text) = HTuple();
  if (0 != (int((hv_NumberDetectionsPerClass.TupleMax())>1)))
  {
    //Get names of duplicate pills.
    hv_Indices = (hv_NumberDetectionsPerClass.TupleGreaterElem(1)).TupleFind(1);
    hv_PillsDuplicateTuple = HTuple(hv_ClassNames[hv_Indices]);
    hv_PillsDuplicateString = ((const HTuple&)hv_PillsDuplicateTuple)[0];
    {
    HTuple end_val8 = (hv_PillsDuplicateTuple.TupleLength())-1;
    HTuple step_val8 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val8, step_val8); hv_Index += step_val8)
    {
      hv_PillsDuplicateString = (hv_PillsDuplicateString+HTuple(", "))+HTuple(hv_PillsDuplicateTuple[hv_Index]);
    }
    }
    //
    (*hv_Text)[(*hv_Text).TupleLength()] = "Duplicate pills: "+hv_PillsDuplicateString;
    (*hv_TextBoxColor) = "red";
    (*hv_TextColor) = "white";
  }
  if (0 != (int((hv_NumberDetectionsPerClass.TupleMin())==0)))
  {
    //Get names of missing pills.
    hv_Indices = hv_NumberDetectionsPerClass.TupleFind(0);
    hv_PillsMissingTuple = HTuple(hv_ClassNames[hv_Indices]);
    hv_PillsMissingString = ((const HTuple&)hv_PillsMissingTuple)[0];
    {
    HTuple end_val21 = (hv_PillsMissingTuple.TupleLength())-1;
    HTuple step_val21 = 1;
    for (hv_Index=1; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
    {
      hv_PillsMissingString = (hv_PillsMissingString+HTuple(", "))+HTuple(hv_PillsMissingTuple[hv_Index]);
    }
    }
    //Add tab for better visualization.
    hv_AddTab = "";
    if (0 != (int((*hv_Text)!=HTuple())))
    {
      hv_AddTab = "  ";
    }
    (*hv_Text)[(*hv_Text).TupleLength()] = (("Pills missing"+hv_AddTab)+": ")+hv_PillsMissingString;
    (*hv_TextBoxColor) = "red";
    (*hv_TextColor) = "white";
  }
  if (0 != (int((*hv_Text)==HTuple())))
  {
    (*hv_Text)[(*hv_Text).TupleLength()] = "Bag is fine";
    (*hv_TextBoxColor) = "green";
    (*hv_TextColor) = "black";
  }
  //
  return;
}

void create_tiny_example_dataset_with_result (HTuple *hv_DLDataset, HTuple *hv_DLResult)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ExampleDir, hv_DLSamples, hv_DLSample;

  //This procedure creates a tiny dataset out of the pill bag dataset.
  //
  GetSystem("example_dir", &hv_ExampleDir);
  //Create DLDataset
  CreateDict(&(*hv_DLDataset));
  SetDictTuple((*hv_DLDataset), "image_dir", hv_ExampleDir+"/images");
  SetDictTuple((*hv_DLDataset), "class_ids", (((((((((HTuple(1).Append(2)).Append(3)).Append(4)).Append(5)).Append(6)).Append(7)).Append(8)).Append(9)).Append(10)));
  SetDictTuple((*hv_DLDataset), "class_names", (((((((((HTuple("Omega-3").Append("KMW")).Append("Stomach tablet")).Append("Ginko")).Append("Ginseng")).Append("Glucosamine")).Append("Cognivia")).Append("Capsularum I")).Append("Iron tablet")).Append("Vitamin-B")));
  //Create Samples
  hv_DLSamples = HTuple();
  CreateDict(&hv_DLSample);
  SetDictTuple(hv_DLSample, "image_id", 36);
  SetDictTuple(hv_DLSample, "image_file_name", "pill_bag/pill_bag_036.png");
  SetDictTuple(hv_DLSample, "bbox_row1", (((((((HTuple(177).Append(242)).Append(247)).Append(240)).Append(453)).Append(127)).Append(465)).Append(372)));
  SetDictTuple(hv_DLSample, "bbox_col1", (((((((HTuple(692).Append(362)).Append(455)).Append(894)).Append(436)).Append(915)).Append(826)).Append(535)));
  SetDictTuple(hv_DLSample, "bbox_row2", (((((((HTuple(287).Append(376)).Append(458)).Append(322)).Append(554)).Append(244)).Append(561)).Append(456)));
  SetDictTuple(hv_DLSample, "bbox_col2", (((((((HTuple(933).Append(493)).Append(580)).Append(978)).Append(672)).Append(1033)).Append(1037)).Append(618)));
  SetDictTuple(hv_DLSample, "bbox_label_id", (((((((HTuple(1).Append(3)).Append(4)).Append(5)).Append(6)).Append(7)).Append(8)).Append(9)));
  hv_DLSamples = hv_DLSamples.TupleConcat(hv_DLSample);
  //
  SetDictTuple((*hv_DLDataset), "samples", hv_DLSamples);
  //
  //Create a results
  CreateDict(&(*hv_DLResult));
  SetDictTuple((*hv_DLResult), "bbox_row1", (((((((HTuple(177).Append(242)).Append(247)).Append(240)).Append(453)).Append(127)).Append(465)).Append(372)));
  SetDictTuple((*hv_DLResult), "bbox_col1", (((((((HTuple(692).Append(362)).Append(455)).Append(894)).Append(436)).Append(915)).Append(826)).Append(535)));
  SetDictTuple((*hv_DLResult), "bbox_row2", (((((((HTuple(287).Append(376)).Append(458)).Append(322)).Append(554)).Append(244)).Append(561)).Append(456)));
  SetDictTuple((*hv_DLResult), "bbox_col2", (((((((HTuple(933).Append(493)).Append(580)).Append(978)).Append(672)).Append(1033)).Append(1037)).Append(618)));
  SetDictTuple((*hv_DLResult), "bbox_class_id", (((((((HTuple(1).Append(3)).Append(4)).Append(5)).Append(6)).Append(7)).Append(8)).Append(9)));
  SetDictTuple((*hv_DLResult), "bbox_confidence", (((((((HTuple(0.99871).Append(1.0)).Append(1.0)).Append(0.97492)).Append(0.96392)).Append(1.0)).Append(1.0)).Append(0.99123)));
  //
  return;
}

void dev_close_example_image_window (HTuple hv_ExampleInternals)
{

  // Local control variables
  HTuple  hv_WindowHandleImages, hv_Exception;

  //This procedure closes the image window.
  //
  try
  {
    GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    if (HDevWindowStack::IsOpen())
      CloseWindow(HDevWindowStack::Pop());
    //Delete key.
    RemoveDictKey(hv_ExampleInternals, "window_images");
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  return;
}

void dev_close_example_legend_window (HTuple hv_ExampleInternals)
{

  // Local control variables
  HTuple  hv_WindowHandleLegend, hv_Exception;

  //This procedure closes the legend window.
  //
  try
  {
    GetDictTuple(hv_ExampleInternals, "window_legend", &hv_WindowHandleLegend);
    HDevWindowStack::SetActive(hv_WindowHandleLegend);
    if (HDevWindowStack::IsOpen())
      CloseWindow(HDevWindowStack::Pop());
    //Delete key.
    RemoveDictKey(hv_ExampleInternals, "window_legend");
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  return;
}

void dev_close_example_text_window (HTuple hv_ExampleInternals)
{

  // Local control variables
  HTuple  hv_WindowHandleImages, hv_Exception;

  //This procedure closes the text window.
  //
  try
  {
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    if (HDevWindowStack::IsOpen())
      CloseWindow(HDevWindowStack::Pop());
    //Delete key.
    RemoveDictKey(hv_ExampleInternals, "window_text");
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  return;
}

void dev_close_example_windows (HTuple hv_ExampleInternals)
{

  // Local control variables
  HTuple  hv_ShowExampleScreens;

  //This procedure closes all example windows.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  dev_close_example_text_window(hv_ExampleInternals);
  dev_close_example_image_window(hv_ExampleInternals);
  dev_close_example_legend_window(hv_ExampleInternals);
  //
  return;
}

void dev_display_example_reset_windows (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHandlesToClose, hv_Exception;
  HTuple  hv_I, hv_WindowHandleKeys, hv_Index, hv_WindowImagesNeeded;
  HTuple  hv_WindowLegendNeeded, hv_WindowHandleImages, hv_WindowHandleLegend;
  HTuple  hv_WindowHandleText;

  //This procedure resets the graphics windows.
  //
  //Close any windows that are listed in key 'window_handles_to_close'.
  try
  {
    GetDictTuple(hv_ExampleInternals, "window_handles_to_close", &hv_WindowHandlesToClose);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
    hv_WindowHandlesToClose = HTuple();
  }
  {
  HTuple end_val8 = (hv_WindowHandlesToClose.TupleLength())-1;
  HTuple step_val8 = 1;
  for (hv_I=0; hv_I.Continue(end_val8, step_val8); hv_I += step_val8)
  {
    HDevWindowStack::SetActive(HTuple(hv_WindowHandlesToClose[hv_I]));
    if (HDevWindowStack::IsOpen())
      CloseWindow(HDevWindowStack::Pop());
  }
  }
  SetDictTuple(hv_ExampleInternals, "window_handles_to_close", HTuple());
  //
  //Open image window if needed
  GetDictParam(hv_ExampleInternals, "keys", HTuple(), &hv_WindowHandleKeys);
  TupleFind(hv_WindowHandleKeys, "window_images", &hv_Index);
  GetDictTuple(hv_ExampleInternals, "window_images_needed", &hv_WindowImagesNeeded);
  if (0 != (hv_WindowImagesNeeded.TupleAnd(int(hv_Index==-1))))
  {
    //Open new window for images
    dev_open_example_image_window(hv_ExampleInternals);
  }
  else if (0 != (HTuple(hv_WindowImagesNeeded.TupleNot()).TupleAnd(int(hv_Index!=-1))))
  {
    //Window for images exists but is not needed -> close it
    dev_close_example_image_window(hv_ExampleInternals);
  }
  //
  //Open legend window if needed
  GetDictParam(hv_ExampleInternals, "keys", HTuple(), &hv_WindowHandleKeys);
  TupleFind(hv_WindowHandleKeys, "window_legend", &hv_Index);
  GetDictTuple(hv_ExampleInternals, "window_legend_needed", &hv_WindowLegendNeeded);
  if (0 != (hv_WindowLegendNeeded.TupleAnd(int(hv_Index==-1))))
  {
    //Open new window for legend
    dev_open_example_legend_window(hv_ExampleInternals, 280);
  }
  else if (0 != (HTuple(hv_WindowLegendNeeded.TupleNot()).TupleAnd(int(hv_Index!=-1))))
  {
    //Window for legend exists but is not needed -> close it
    dev_close_example_legend_window(hv_ExampleInternals);
  }
  //
  //Set the correct area (part) of the image window.
  try
  {
    GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    //Set default window extends
    if (HDevWindowStack::IsOpen())
      SetWindowExtents(HDevWindowStack::GetActive(),360, 0, 800, 500);
    if (HDevWindowStack::IsOpen())
      SetPart(HDevWindowStack::GetActive(),1, 1, -1, -1);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  //
  //Set the correct area (part) of the legend window.
  try
  {
    GetDictTuple(hv_ExampleInternals, "window_legend", &hv_WindowHandleLegend);
    HDevWindowStack::SetActive(hv_WindowHandleLegend);
    if (HDevWindowStack::IsOpen())
      ClearWindow(HDevWindowStack::GetActive());
    if (HDevWindowStack::IsOpen())
      SetPart(HDevWindowStack::GetActive(),1, 1, -1, -1);
  }
  // catch (Exception) 
  catch (HException &HDevExpDefaultException)
  {
    HDevExpDefaultException.ToHTuple(&hv_Exception);
  }
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  if (HDevWindowStack::IsOpen())
    ClearWindow(HDevWindowStack::GetActive());
  return;
}

void dev_display_screen_device (HTuple hv_ExampleInternals, HTuple hv_DLDevice)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHandleText, hv_DLDeviceType;
  HTuple  hv_DLDeviceName, hv_Text;

  //This procedure displays information about the used device.

  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);

  //Display the explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);

  GetDlDeviceParam(hv_DLDevice, "type", &hv_DLDeviceType);
  GetDlDeviceParam(hv_DLDevice, "name", &hv_DLDeviceName);

  hv_Text = "This example can be run on any deep learning device.";
  hv_Text[hv_Text.TupleLength()] = "";
  if (0 != (int(hv_DLDeviceType!=HTuple("gpu"))))
  {
    hv_Text[hv_Text.TupleLength()] = "No GPU with necessary drivers and libraries has been found.";
    hv_Text[hv_Text.TupleLength()] = "";
  }
  hv_Text[hv_Text.TupleLength()] = "This example will run the deep learning operators";
  hv_Text[hv_Text.TupleLength()] = "on the following device:";
  hv_Text[hv_Text.TupleLength()] = "Device type: "+hv_DLDeviceType;
  hv_Text[hv_Text.TupleLength()] = "Device name: "+hv_DLDeviceName;

  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());

  return;
}

void dev_display_screen_example_images (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_Image;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_UsePretrainedModel;
  HTuple  hv_PreprocessParamFileName, hv_PreprocessParamExists;
  HTuple  hv_RetrainedModelFileName, hv_ModelExists, hv_ExampleDataDir;
  HTuple  hv_DataDirectory, hv_WindowImageNeeded, hv_WindowHandleText;
  HTuple  hv_Text, hv_ExampleImageFile, hv_WindowHandleImages;
  HTuple  hv_Width, hv_Height;

  //This procedure displays an overview on the different example parts.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  GetDictTuple(hv_ExampleInternals, "use_pretrained_model", &hv_UsePretrainedModel);
  if (0 != hv_UsePretrainedModel)
  {
    //Check if the pretrained model and preprocessing parameters are available.
    //
    //File name of dict containing parameters used for preprocessing.
    hv_PreprocessParamFileName = "detect_pills_preprocess_param.hdict";
    FileExists(hv_PreprocessParamFileName, &hv_PreprocessParamExists);
    //
    //File name of dict containing parameters used for preprocessing.
    hv_RetrainedModelFileName = "detect_pills.hdl";
    FileExists(hv_RetrainedModelFileName, &hv_ModelExists);
  }
  else
  {
    //Check if the trained model and preprocessing parameters are available.
    //
    //Example data folder containing the outputs of the previous example series.
    hv_ExampleDataDir = "detect_pills_data";
    //
    //File name of dict containing parameters used for preprocessing.
    hv_DataDirectory = hv_ExampleDataDir+"/dldataset_pill_bag_512x320";
    hv_PreprocessParamFileName = hv_DataDirectory+"/dl_preprocess_param.hdict";
    FileExists(hv_PreprocessParamFileName, &hv_PreprocessParamExists);
    //
    //File name of dict containing parameters used for preprocessing.
    hv_RetrainedModelFileName = hv_ExampleDataDir+"/best_dl_model_detection.hdl";
    FileExists(hv_RetrainedModelFileName, &hv_ModelExists);
  }
  //Reset the open windows for a clean display.
  hv_WindowImageNeeded = hv_PreprocessParamExists.TupleAnd(hv_ModelExists);
  SetDictTuple(hv_ExampleInternals, "window_images_needed", hv_WindowImageNeeded);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  if (0 != (HTuple(hv_PreprocessParamExists.TupleNot()).TupleOr(hv_ModelExists.TupleNot())))
  {
    if (0 != hv_UsePretrainedModel)
    {
      hv_Text = "The pretrained model and corresponding preprocessing";
      hv_Text[hv_Text.TupleLength()] = "parameters could not be found.";
      hv_Text[hv_Text.TupleLength()] = "";
      hv_Text[hv_Text.TupleLength()] = "These files are part of a separate installer. Please";
      hv_Text[hv_Text.TupleLength()] = "refer to the Installation Guide for more information on";
      hv_Text[hv_Text.TupleLength()] = "this topic!";
    }
    else
    {
      //
      //Part 1 and/or part 2 should be run before continuing this example.
      hv_Text = "To run this example you need the output of:";
      if (0 != (hv_PreprocessParamExists.TupleNot()))
      {
        hv_Text[hv_Text.TupleLength()] = "- 'detect_pills_deep_learning_1_prepare.hdev'";
      }
      if (0 != (hv_ModelExists.TupleNot()))
      {
        hv_Text[hv_Text.TupleLength()] = "- 'detect_pills_deep_learning_2_train.hdev'";
      }
      hv_Text[hv_Text.TupleLength()] = "";
      if (0 != (HTuple(hv_PreprocessParamExists.TupleNot()).TupleAnd(hv_ModelExists.TupleNot())))
      {
        hv_Text[hv_Text.TupleLength()] = "Please run these examples first.";
      }
      else
      {
        hv_Text[hv_Text.TupleLength()] = "Please run this example first.";
      }
      hv_Text[HTuple::TupleGenSequence(hv_Text.TupleLength(),(hv_Text.TupleLength())+2,1)] = ((HTuple("Alternatively, you can set 'UsePretrainedModel := true' ").Append("at the top of the example script to use an already trained")).Append("model shipped with the HALCON installation."));
    }
    //
    set_display_font(hv_WindowHandleText, 20, "mono", "true", "false");
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "red", 
          "box", "true");
    set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
  }
  else
  {
    //
    //All parts have been run before, hence continue with the example text.
    hv_Text = "We now have a trained DL object detection model.";
    hv_Text[hv_Text.TupleLength()] = "We are ready to apply it to new images.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "These images are not part of the preprocessed dataset.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = HTuple("The images have to be preprocessed in the same way as the DLDataset,");
    hv_Text[hv_Text.TupleLength()] = "which was used for training (see example series part 1).";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "Below you see an example image.";
    //
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
          "box", "true");
    if (HDevWindowStack::IsOpen())
      DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
          "bottom", "right", "black", HTuple(), HTuple());
    //
    //Display an example image
    hv_ExampleImageFile = "/pill_bag/pill_bag_036.png";
    //Add example image to ExampleInternals reuse it later
    SetDictTuple(hv_ExampleInternals, "example_image_file", hv_ExampleImageFile);
    ReadImage(&ho_Image, hv_ExampleImageFile);
    GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    GetImageSize(ho_Image, &hv_Width, &hv_Height);
    if (HDevWindowStack::IsOpen())
      SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
    if (HDevWindowStack::IsOpen())
      DispObj(ho_Image, HDevWindowStack::GetActive());
  }
  //
  return;
}

void dev_display_screen_final (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text;

  //This procedure shows the final message of the example series.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  dev_open_example_text_window(hv_ExampleInternals);
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  //Display instruction text.
  hv_Text = "Congratulations!";
  hv_Text[hv_Text.TupleLength()] = "You have finished the series of examples for DL object detection.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "You can now train a DL object detection model on your own data.";
  hv_Text[hv_Text.TupleLength()] = "";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"End of program.", "window", "bottom", 
        "right", "black", "box", "true");
  //
  return;
}

void dev_display_screen_inference_step_1 (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_ImageRaw;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_ExampleImageFile;
  HTuple  hv_Width, hv_Height;

  //This procedure displays the second explanatory part of the inference.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Inference steps for one image:";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "1. Generate a DLSample for the image using";
  hv_Text[hv_Text.TupleLength()] = "   'gen_dl_samples_from_images'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example images,
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  //
  GetDictTuple(hv_ExampleInternals, "example_image_file", &hv_ExampleImageFile);
  ReadImage(&ho_ImageRaw, hv_ExampleImageFile);
  GetImageSize(ho_ImageRaw, &hv_Width, &hv_Height);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_ImageRaw, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Raw image", "window", "top", "left", "black", 
        HTuple(), HTuple());
  //
  FlushBuffer(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "true");
  //
  return;
}

void dev_display_screen_inference_step_2_part_1 (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_ImageRaw, ho_ImagePart, ho_ImagePart2;
  HObject  ho_ImageTrans, ho_Loupe1, ho_Loupe2, ho_LoupeLine1;
  HObject  ho_LoupeLine2;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_ExampleImageFile;
  HTuple  hv_Width, hv_Height, hv_LoupeZoom, hv_LoupeMargin;
  HTuple  hv_LoupeWindowSize, hv_LoupeRow1, hv_LoupeColumn1;
  HTuple  hv_HomMat2DIdentity, hv_HomMat2DTranslate, hv__;
  HTuple  hv_TextHeight;

  //This procedure displays the second explanatory part of the inference.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Inference steps for one image:";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "1. Generate a DLSample for the image using";
  hv_Text[hv_Text.TupleLength()] = "   'gen_dl_samples_from_images'.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "2. Preprocess the image to suit the trained model";
  hv_Text[hv_Text.TupleLength()] = "   using 'preprocess_dl_samples'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example images,
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  //
  GetDictTuple(hv_ExampleInternals, "example_image_file", &hv_ExampleImageFile);
  ReadImage(&ho_ImageRaw, hv_ExampleImageFile);
  GetImageSize(ho_ImageRaw, &hv_Width, &hv_Height);
  //
  //Create a loupe to see difference of resolution
  hv_LoupeZoom = 7.0;
  hv_LoupeMargin = 30;
  hv_LoupeWindowSize = 45;
  hv_LoupeRow1 = 368;
  hv_LoupeColumn1 = 577;
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"margin");
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"light blue");
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),2);
  //Preapare images for loupe
  CropRectangle1(ho_ImageRaw, &ho_ImagePart, hv_LoupeRow1, hv_LoupeColumn1, (hv_LoupeRow1+hv_LoupeWindowSize)-1, 
      (hv_LoupeColumn1+hv_LoupeWindowSize)-1);
  ZoomImageFactor(ho_ImagePart, &ho_ImagePart2, hv_LoupeZoom, hv_LoupeZoom, "nearest_neighbor");
  HomMat2dIdentity(&hv_HomMat2DIdentity);
  HomMat2dTranslate(hv_HomMat2DIdentity, (hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin, 
      hv_LoupeMargin, &hv_HomMat2DTranslate);
  AffineTransImage(ho_ImagePart2, &ho_ImageTrans, hv_HomMat2DTranslate, "constant", 
      "true");
  //Draw loupe rectangles
  GenRectangle1(&ho_Loupe1, hv_LoupeRow1, hv_LoupeColumn1, hv_LoupeRow1+hv_LoupeWindowSize, 
      hv_LoupeColumn1+hv_LoupeWindowSize);
  GenRectangle1(&ho_Loupe2, (hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin, 
      hv_LoupeMargin, (hv_Height-hv_LoupeMargin)-1, ((hv_LoupeZoom*hv_LoupeWindowSize)+hv_LoupeMargin)-1);
  //Draw loupe lines
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  GenRegionLine(&ho_LoupeLine1, (hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin, 
      hv_LoupeMargin, hv_LoupeRow1, hv_LoupeColumn1);
  GenRegionLine(&ho_LoupeLine2, (hv_Height-hv_LoupeMargin)-1, ((hv_LoupeZoom*hv_LoupeWindowSize)+hv_LoupeMargin)-1, 
      hv_LoupeRow1+hv_LoupeWindowSize, hv_LoupeColumn1+hv_LoupeWindowSize);
  //
  GetImageSize(ho_ImageRaw, &hv_Width, &hv_Height);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_ImageRaw, HDevWindowStack::GetActive());
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_ImageTrans, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Loupe1, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Loupe2, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_LoupeLine1, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_LoupeLine2, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Raw image", "window", "top", "left", "black", 
        HTuple(), HTuple());
  //
  GetStringExtents(hv_WindowHandleImages, "test_string", &hv__, &hv__, &hv__, &hv_TextHeight);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Original resolution", "image", ((hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin)-(3*hv_TextHeight), 
        hv_LoupeMargin, "black", HTuple(), HTuple());
  //
  FlushBuffer(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "true");
  //
  return;
}

void dev_display_screen_inference_step_2_part_2 (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_ImageRaw, ho_ImageZoomed, ho_ImagePart;
  HObject  ho_ImagePart2, ho_ImageTrans, ho_Loupe1, ho_Loupe2;
  HObject  ho_LoupeLine1, ho_LoupeLine2;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_ExampleImageFile;
  HTuple  hv_RawWidth, hv_RawHeight, hv_Width, hv_Height;
  HTuple  hv_ZoomFactor, hv_LoupeZoom, hv_LoupeMargin, hv_LoupeWindowSize;
  HTuple  hv_LoupeRow1, hv_LoupeColumn1, hv_HomMat2DIdentity;
  HTuple  hv_HomMat2DTranslate, hv__, hv_TextHeight;

  //This procedure displays the second explanatory part of the inference.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Inference steps for one image:";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "1. Generate a DLSample for the image using";
  hv_Text[hv_Text.TupleLength()] = "   'gen_dl_samples_from_images'.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "2. Preprocess the image to suit the trained model";
  hv_Text[hv_Text.TupleLength()] = "   using 'preprocess_dl_samples'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example images,
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  //
  GetDictTuple(hv_ExampleInternals, "example_image_file", &hv_ExampleImageFile);
  ReadImage(&ho_ImageRaw, hv_ExampleImageFile);
  GetImageSize(ho_ImageRaw, &hv_RawWidth, &hv_RawHeight);
  ZoomImageSize(ho_ImageRaw, &ho_ImageZoomed, 512, 320, "constant");
  GetImageSize(ho_ImageZoomed, &hv_Width, &hv_Height);
  hv_ZoomFactor = hv_Height/(hv_RawHeight.TupleReal());
  //
  //Create a loupe to see difference of resolution
  hv_LoupeZoom = 7.0;
  hv_LoupeMargin = 30*hv_ZoomFactor;
  hv_LoupeWindowSize = 45*hv_ZoomFactor;
  hv_LoupeRow1 = 368*hv_ZoomFactor;
  hv_LoupeColumn1 = 577*hv_ZoomFactor;
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"margin");
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"light blue");
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),2);
  //Preapare images for loupe
  CropRectangle1(ho_ImageZoomed, &ho_ImagePart, hv_LoupeRow1, hv_LoupeColumn1, (hv_LoupeRow1+hv_LoupeWindowSize)-1, 
      (hv_LoupeColumn1+hv_LoupeWindowSize)-1);
  ZoomImageFactor(ho_ImagePart, &ho_ImagePart2, hv_LoupeZoom, hv_LoupeZoom, "nearest_neighbor");
  HomMat2dIdentity(&hv_HomMat2DIdentity);
  HomMat2dTranslate(hv_HomMat2DIdentity, (hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin, 
      hv_LoupeMargin, &hv_HomMat2DTranslate);
  AffineTransImage(ho_ImagePart2, &ho_ImageTrans, hv_HomMat2DTranslate, "constant", 
      "true");
  //Draw loupe rectangles
  GenRectangle1(&ho_Loupe1, hv_LoupeRow1, hv_LoupeColumn1, hv_LoupeRow1+hv_LoupeWindowSize, 
      hv_LoupeColumn1+hv_LoupeWindowSize);
  GenRectangle1(&ho_Loupe2, (hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin, 
      hv_LoupeMargin, (hv_Height-hv_LoupeMargin)-5, ((hv_LoupeZoom*hv_LoupeWindowSize)+hv_LoupeMargin)-5);
  //Draw loupe lines
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  GenRegionLine(&ho_LoupeLine1, (hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin, 
      hv_LoupeMargin, hv_LoupeRow1, hv_LoupeColumn1);
  GenRegionLine(&ho_LoupeLine2, (hv_Height-hv_LoupeMargin)-5, ((hv_LoupeZoom*hv_LoupeWindowSize)+hv_LoupeMargin)-5, 
      hv_LoupeRow1+hv_LoupeWindowSize, hv_LoupeColumn1+hv_LoupeWindowSize);
  //
  GetImageSize(ho_ImageZoomed, &hv_Width, &hv_Height);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_ImageZoomed, HDevWindowStack::GetActive());
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_ImageTrans, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Loupe1, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Loupe2, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_LoupeLine1, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_LoupeLine2, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Preprocessed image for image size 512 x 320", 
        "window", "top", "left", "black", HTuple(), HTuple());
  //
  GetStringExtents(hv_WindowHandleImages, "test_string", &hv__, &hv__, &hv__, &hv_TextHeight);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Reduced resolution", "image", ((hv_Height-(hv_LoupeZoom*hv_LoupeWindowSize))-hv_LoupeMargin)-((3*hv_TextHeight)*hv_ZoomFactor), 
        hv_LoupeMargin, "black", HTuple(), HTuple());
  //
  FlushBuffer(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "true");
  //
  return;
}

void dev_display_screen_inference_step_3 (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_DLDataset, hv_DLResult;
  HTuple  hv_WindowHandleLegend, hv_WindowHandleDict, hv_GenParamValue;
  HTuple  hv_WindowImageColumn1, hv_WindowImageRow1, hv_WindowImageWidth;
  HTuple  hv_WindowImageHeight, hv_Row, hv_Column, hv_Width;
  HTuple  hv_Height, hv_DLSample;

  //This procedure displays the third explanatory part of the inference.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 1);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Inference steps for one image:";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "1. Generate a DLSample for the image using";
  hv_Text[hv_Text.TupleLength()] = "   'gen_dl_samples_from_images'.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "2. Preprocess the image to fit the trained model";
  hv_Text[hv_Text.TupleLength()] = "   using 'preprocess_dl_samples'.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "3. Apply the model using 'apply_dl_model'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example images,
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  //
  //Read a tiny dataset with a single sample from the pill bag dataset.
  create_tiny_example_dataset_with_result(&hv_DLDataset, &hv_DLResult);
  //
  //Display a temporary legend.
  GetDictTuple(hv_ExampleInternals, "window_legend", &hv_WindowHandleLegend);
  HDevWindowStack::SetActive(hv_WindowHandleLegend);
  //
  CreateDict(&hv_WindowHandleDict);
  GetDictParam(hv_ExampleInternals, "keys", HTuple(), &hv_GenParamValue);
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  //To display the Text at the bottom of the image such that the image is undistorted,
  //change size of windows.
  GetDictTuple(hv_ExampleInternals, "window_images_x", &hv_WindowImageColumn1);
  GetDictTuple(hv_ExampleInternals, "window_images_y", &hv_WindowImageRow1);
  GetDictTuple(hv_ExampleInternals, "window_images_width", &hv_WindowImageWidth);
  GetDictTuple(hv_ExampleInternals, "window_images_height", &hv_WindowImageHeight);
  hv_WindowImageHeight += 39.88;
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_WindowImageRow1, hv_WindowImageColumn1, 
        hv_WindowImageWidth, hv_WindowImageHeight);
  //Same for legend window
  GetWindowExtents(hv_WindowHandleLegend, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
  HDevWindowStack::SetActive(hv_WindowHandleLegend);
  if (HDevWindowStack::IsOpen())
    SetWindowExtents(HDevWindowStack::GetActive(),hv_WindowImageRow1, (hv_WindowImageColumn1+hv_WindowImageWidth)+5, 
        290, hv_WindowImageHeight);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  //
  SetDictTuple(hv_WindowHandleDict, "bbox_result", hv_WindowHandleImages.TupleConcat(hv_WindowHandleLegend));
  //
  //Display the sample contained in tiny dataset.
  gen_dl_samples(hv_DLDataset, 0, "detection", HTuple(), &hv_DLSample);
  dev_display_dl_data(hv_DLSample, hv_DLResult, hv_DLDataset, "bbox_result", HTuple(), 
      hv_WindowHandleDict);
  //
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Output of 'apply_dl_model'", "window", 
        "top", "left", "black", HTuple(), HTuple());
  HDevWindowStack::SetActive(hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleLegend);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  return;
}

void dev_display_screen_introduction (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text;

  //This procedure displays an overview on the different example parts.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = HTuple("This example is part of a series of examples, which summarize ");
  hv_Text[hv_Text.TupleLength()] = "the workflow for DL object detection. It uses the MVTec pill bag dataset.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "The four parts are: ";
  hv_Text[hv_Text.TupleLength()] = "1. Creation of the model and dataset preprocessing.";
  hv_Text[hv_Text.TupleLength()] = "2. Training of the model.";
  hv_Text[hv_Text.TupleLength()] = "3. Evaluation of the trained model.";
  hv_Text[hv_Text.TupleLength()] = "4. Inference on new images.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "This example covers part 4: 'Inference on new images'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  return;
}

void dev_display_screen_max_overlap (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageZoomed, ho_ImagePart;
  HObject  ho_ObjectsConcat, ho_TiledImage, ho_Line, ho_BoxGinko;
  HObject  ho_BoxCapsularumI, ho_BoxGinko2, ho_BoxCapsularumI2;
  HObject  ho_BadBox1, ho_BadBox2;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageZoomWidth, hv_ZoomedImageToImage, hv_ImageZoomHeight;
  HTuple  hv_ImageRatio, hv_Ratio, hv_CropHeight, hv_CropWidth;
  HTuple  hv_Row1, hv_Col1, hv_Row2, hv_Col2, hv_Width, hv_Height;
  HTuple  hv_ColorsRainbow, hv_Colors, hv_ColorGinko, hv_ColorCapsularumI;
  HTuple  hv_LineWidth, hv_Row, hv_Column, hv_WindowWidth;
  HTuple  hv_WindowHeight, hv__, hv_TextWidth, hv_TextHeight;
  HTuple  hv_TextCol;

  //This procedure explains the parameter 'max_overlap'.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Output optimization:";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = HTuple("Sometimes, the network finds more overlapping bounding");
  hv_Text[hv_Text.TupleLength()] = "boxes predicting the same class for the same object.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "To remove boxes that overlap with the best predicted";
  hv_Text[hv_Text.TupleLength()] = HTuple("box by a certain intersection over union (IoU), use");
  hv_Text[hv_Text.TupleLength()] = "the parameter 'max_overlap'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example image.
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  //
  //Create example image.
  ReadImage(&ho_Image, "pill_bag/pill_bag_207.png");
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  hv_ImageZoomWidth = 512;
  hv_ZoomedImageToImage = hv_ImageZoomWidth/(1.0*hv_ImageWidth);
  hv_ImageZoomHeight = (hv_ImageHeight*hv_ZoomedImageToImage).TupleRound();
  ZoomImageSize(ho_Image, &ho_ImageZoomed, hv_ImageZoomWidth, hv_ImageZoomHeight, 
      "constant");
  //
  hv_ImageRatio = (hv_ImageWidth.TupleReal())/(hv_ImageHeight.TupleReal());
  hv_Ratio = hv_ImageWidth/(1.0*hv_ImageHeight);
  hv_CropHeight = 140;
  hv_CropWidth = hv_Ratio*hv_CropHeight;
  hv_Row1 = 17;
  hv_Col1 = 335;
  hv_Row2 = hv_Row1+hv_CropHeight;
  hv_Col2 = hv_Col1+(hv_CropWidth*0.5);
  CropRectangle1(ho_ImageZoomed, &ho_ImagePart, hv_Row1, hv_Col1, hv_Row2, hv_Col2);
  //
  ConcatObj(ho_ImagePart, ho_ImagePart, &ho_ObjectsConcat);
  TileImages(ho_ObjectsConcat, &ho_TiledImage, 2, "vertical");
  GetImageSize(ho_TiledImage, &hv_Width, &hv_Height);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_TiledImage, HDevWindowStack::GetActive());
  //
  //Make line.
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"gray");
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"fill");
  GenRectangle1(&ho_Line, 0, hv_Width/2, hv_Height, (hv_Width/2)+1);
  //
  //Create result boxes.
  get_distinct_colors(10, 0, 0, 200, &hv_ColorsRainbow);
  TupleInverse(hv_ColorsRainbow, &hv_ColorsRainbow);
  make_neighboring_colors_distinguishable(hv_ColorsRainbow, &hv_Colors);
  hv_ColorGinko = ((const HTuple&)hv_Colors)[3];
  hv_ColorCapsularumI = ((const HTuple&)hv_Colors)[7];
  //Result boxes.
  GenRectangle1(&ho_BoxGinko, 30.1, 4.7, 66.2, 91.7);
  GenRectangle1(&ho_BoxCapsularumI, 56.0, 37.0, 119.8, 110.9);
  GenRectangle1(&ho_BoxGinko2, 30.1, 4.7+(hv_Width/2), 66.2, 91.7+(hv_Width/2));
  GenRectangle1(&ho_BoxCapsularumI2, 56.0, 37.0+(hv_Width/2), 119.8, 110.9+(hv_Width/2));
  //
  //Generate bad box
  GenRectangle1(&ho_BadBox1, 68, 26, 101, 102);
  GenRectangle1(&ho_BadBox2, 49, 63, 119, 95);
  //
  //Draw result box.
  if (HDevWindowStack::IsOpen())
    DispObj(ho_TiledImage, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Line, HDevWindowStack::GetActive());
  hv_LineWidth = 2.0;
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  display_result_box(ho_BoxGinko, hv_LineWidth, hv_ColorGinko, "4 (1.00)");
  display_result_box(ho_BoxCapsularumI, hv_LineWidth, hv_ColorCapsularumI, "8 (0.97)");
  display_result_box(ho_BoxGinko2, hv_LineWidth, hv_ColorGinko, "4 (1.00)");
  display_result_box(ho_BoxCapsularumI2, hv_LineWidth, hv_ColorCapsularumI, "8 (0.97)");
  display_result_box(ho_BadBox1, hv_LineWidth, hv_ColorCapsularumI, "4 (0.77)");
  display_result_box(ho_BadBox2, hv_LineWidth, hv_ColorCapsularumI, "4 (0.81)");
  //
  //Add text for image parts
  GetWindowExtents(hv_WindowHandleImages, &hv_Row, &hv_Column, &hv_WindowWidth, &hv_WindowHeight);
  hv_Text = "max_overlap = 0.5 (default)";
  GetStringExtents(hv_WindowHandleImages, hv_Text, &hv__, &hv__, &hv_TextWidth, &hv_TextHeight);
  hv_TextCol = (hv_WindowWidth*0.25)-(hv_TextWidth*0.5);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_WindowHeight-(2*hv_TextHeight), 
        hv_TextCol, "black", HTuple(), HTuple());
  hv_Text = "max_overlap = 0.4";
  GetStringExtents(hv_WindowHandleImages, hv_Text, &hv__, &hv__, &hv_TextWidth, &hv_TextHeight);
  hv_TextCol = (hv_WindowWidth*0.75)-(hv_TextWidth*0.5);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_WindowHeight-(2*hv_TextHeight), 
        hv_TextCol, "black", HTuple(), HTuple());
  //
  //Display.
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  FlushBuffer(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "true");
  //
  return;
}

void dev_display_screen_max_overlap_class_agnostic (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageZoomed, ho_ImagePart;
  HObject  ho_ObjectsConcat, ho_TiledImage, ho_Line, ho_BoxGinko;
  HObject  ho_BoxCapsularumI, ho_BoxGinko2, ho_BoxCapsularumI2;
  HObject  ho_BadBox1, ho_BadBox2;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageZoomWidth, hv_ZoomedImageToImage, hv_ImageZoomHeight;
  HTuple  hv_ImageRatio, hv_Ratio, hv_CropHeight, hv_CropWidth;
  HTuple  hv_Row1, hv_Col1, hv_Row2, hv_Col2, hv_Width, hv_Height;
  HTuple  hv_ColorsRainbow, hv_Colors, hv_ColorGinko, hv_ColorCapsularumI;
  HTuple  hv_ColorVitaminB, hv_LineWidth, hv_Row, hv_Column;
  HTuple  hv_WindowWidth, hv_WindowHeight, hv__, hv_TextWidth;
  HTuple  hv_TextHeight, hv_TextCol;

  //This procedure explains the parameter 'max_overlap_class_agnostic'.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Output optimization:";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = HTuple("For the same object, more than one class might be");
  hv_Text[hv_Text.TupleLength()] = HTuple("predicted. In this case, the network outputs several");
  hv_Text[hv_Text.TupleLength()] = "bounding boxes with different classes for one object.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "To suppress all overlapping bounding boxes other than";
  hv_Text[hv_Text.TupleLength()] = HTuple("the one with the highest confidence,");
  hv_Text[hv_Text.TupleLength()] = HTuple("'max_overlap_class_agnostic' can be used. As default,");
  hv_Text[hv_Text.TupleLength()] = "this class agnostic bounding box suppression is not performed.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example image.
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  //
  //Create example image.
  ReadImage(&ho_Image, "pill_bag/pill_bag_207.png");
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  hv_ImageZoomWidth = 512;
  hv_ZoomedImageToImage = hv_ImageZoomWidth/(1.0*hv_ImageWidth);
  hv_ImageZoomHeight = (hv_ImageHeight*hv_ZoomedImageToImage).TupleRound();
  ZoomImageSize(ho_Image, &ho_ImageZoomed, hv_ImageZoomWidth, hv_ImageZoomHeight, 
      "constant");
  //
  hv_ImageRatio = (hv_ImageWidth.TupleReal())/(hv_ImageHeight.TupleReal());
  hv_Ratio = hv_ImageWidth/(1.0*hv_ImageHeight);
  hv_CropHeight = 140;
  hv_CropWidth = hv_Ratio*hv_CropHeight;
  hv_Row1 = 17;
  hv_Col1 = 335;
  hv_Row2 = hv_Row1+hv_CropHeight;
  hv_Col2 = hv_Col1+(hv_CropWidth*0.5);
  CropRectangle1(ho_ImageZoomed, &ho_ImagePart, hv_Row1, hv_Col1, hv_Row2, hv_Col2);
  //
  ConcatObj(ho_ImagePart, ho_ImagePart, &ho_ObjectsConcat);
  TileImages(ho_ObjectsConcat, &ho_TiledImage, 2, "vertical");
  GetImageSize(ho_TiledImage, &hv_Width, &hv_Height);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_TiledImage, HDevWindowStack::GetActive());
  //
  //Make line.
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"gray");
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"fill");
  GenRectangle1(&ho_Line, 0, hv_Width/2, hv_Height, (hv_Width/2)+1);
  //
  //Create result boxes.
  get_distinct_colors(10, 0, 0, 200, &hv_ColorsRainbow);
  TupleInverse(hv_ColorsRainbow, &hv_ColorsRainbow);
  make_neighboring_colors_distinguishable(hv_ColorsRainbow, &hv_Colors);
  hv_ColorGinko = ((const HTuple&)hv_Colors)[3];
  hv_ColorCapsularumI = ((const HTuple&)hv_Colors)[7];
  hv_ColorVitaminB = ((const HTuple&)hv_Colors)[9];
  //Result boxes.
  GenRectangle1(&ho_BoxGinko, 30.1, 4.7, 66.2, 91.7);
  GenRectangle1(&ho_BoxCapsularumI, 56.0, 37.0, 119.8, 110.9);
  GenRectangle1(&ho_BoxGinko2, 30.1, 4.7+(hv_Width/2), 66.2, 91.7+(hv_Width/2));
  GenRectangle1(&ho_BoxCapsularumI2, 56.0, 37.0+(hv_Width/2), 119.8, 110.9+(hv_Width/2));
  //
  //Generate bad box
  GenRectangle1(&ho_BadBox1, 25, 3, 61, 88);
  GenRectangle1(&ho_BadBox2, 63, 36, 124, 103);
  //
  //Draw result box.
  if (HDevWindowStack::IsOpen())
    DispObj(ho_TiledImage, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Line, HDevWindowStack::GetActive());
  hv_LineWidth = 2.0;
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  display_result_box(ho_BoxGinko, hv_LineWidth, hv_ColorGinko, "4 (1.00)");
  display_result_box(ho_BoxCapsularumI, hv_LineWidth, hv_ColorCapsularumI, "8 (0.97)");
  display_result_box(ho_BoxGinko2, hv_LineWidth, hv_ColorGinko, "4 (1.00)");
  display_result_box(ho_BoxCapsularumI2, hv_LineWidth, hv_ColorCapsularumI, "8 (0.97)");
  display_result_box(ho_BadBox1, hv_LineWidth, hv_ColorCapsularumI, "8 (0.82)");
  display_result_box(ho_BadBox2, hv_LineWidth, hv_ColorVitaminB, "9 (0.76)");
  //
  //Add text for image parts
  GetWindowExtents(hv_WindowHandleImages, &hv_Row, &hv_Column, &hv_WindowWidth, &hv_WindowHeight);
  hv_Text = "max_overlap_class_agnostic = 1.0 (default)";
  GetStringExtents(hv_WindowHandleImages, hv_Text, &hv__, &hv__, &hv_TextWidth, &hv_TextHeight);
  hv_TextCol = (hv_WindowWidth*0.25)-(hv_TextWidth*0.5);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_WindowHeight-(2*hv_TextHeight), 
        hv_TextCol, "black", HTuple(), HTuple());
  hv_Text = "max_overlap_class_agnostic = 0.7";
  GetStringExtents(hv_WindowHandleImages, hv_Text, &hv__, &hv__, &hv_TextWidth, &hv_TextHeight);
  hv_TextCol = (hv_WindowWidth*0.75)-(hv_TextWidth*0.5);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_WindowHeight-(2*hv_TextHeight), 
        hv_TextCol, "black", HTuple(), HTuple());
  //
  //Display.
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  FlushBuffer(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "true");
  //
  return;
}

void dev_display_screen_min_confidence (HTuple hv_ExampleInternals)
{

  // Local iconic variables
  HObject  ho_Image, ho_ImageZoomed, ho_ImagePart;
  HObject  ho_ObjectsConcat, ho_TiledImage, ho_Line, ho_BoxGinko;
  HObject  ho_BoxCapsularumI, ho_BoxGinko2, ho_BoxCapsularumI2;
  HObject  ho_BadBox;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text, hv_WindowHandleImages, hv_ImageWidth, hv_ImageHeight;
  HTuple  hv_ImageZoomWidth, hv_ZoomedImageToImage, hv_ImageZoomHeight;
  HTuple  hv_ImageRatio, hv_Ratio, hv_CropHeight, hv_CropWidth;
  HTuple  hv_Row1, hv_Col1, hv_Row2, hv_Col2, hv_Width, hv_Height;
  HTuple  hv_ColorsRainbow, hv_Colors, hv_ColorGinko, hv_ColorCapsularumI;
  HTuple  hv_LineWidth, hv_Row, hv_Column, hv_WindowWidth;
  HTuple  hv_WindowHeight, hv__, hv_TextWidth, hv_TextHeight;
  HTuple  hv_TextCol;

  //This procedure explains the parameter 'min_confidence'.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "Output optimization:";
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = "The output of 'apply_dl_model' can be optimized with";
  hv_Text[hv_Text.TupleLength()] = "some parameters that can be set with 'set_dl_model_param'.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = HTuple("To suppress result bounding boxes with a low confidence, use");
  hv_Text[hv_Text.TupleLength()] = "the parameter 'min_confidence'.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  //Display example image.
  GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
  HDevWindowStack::SetActive(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  //
  //Create example image.
  ReadImage(&ho_Image, "pill_bag/pill_bag_207.png");
  GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
  hv_ImageZoomWidth = 512;
  hv_ZoomedImageToImage = hv_ImageZoomWidth/(1.0*hv_ImageWidth);
  hv_ImageZoomHeight = (hv_ImageHeight*hv_ZoomedImageToImage).TupleRound();
  ZoomImageSize(ho_Image, &ho_ImageZoomed, hv_ImageZoomWidth, hv_ImageZoomHeight, 
      "constant");
  //
  hv_ImageRatio = (hv_ImageWidth.TupleReal())/(hv_ImageHeight.TupleReal());
  hv_Ratio = hv_ImageWidth/(1.0*hv_ImageHeight);
  hv_CropHeight = 140;
  hv_CropWidth = hv_Ratio*hv_CropHeight;
  hv_Row1 = 17;
  hv_Col1 = 335;
  hv_Row2 = hv_Row1+hv_CropHeight;
  hv_Col2 = hv_Col1+(hv_CropWidth*0.5);
  CropRectangle1(ho_ImageZoomed, &ho_ImagePart, hv_Row1, hv_Col1, hv_Row2, hv_Col2);
  //
  ConcatObj(ho_ImagePart, ho_ImagePart, &ho_ObjectsConcat);
  TileImages(ho_ObjectsConcat, &ho_TiledImage, 2, "vertical");
  GetImageSize(ho_TiledImage, &hv_Width, &hv_Height);
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_TiledImage, HDevWindowStack::GetActive());
  //
  //Make line.
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"gray");
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"fill");
  GenRectangle1(&ho_Line, 0, hv_Width/2, hv_Height, (hv_Width/2)+1);
  //
  //Create result boxes.
  get_distinct_colors(10, 0, 0, 200, &hv_ColorsRainbow);
  TupleInverse(hv_ColorsRainbow, &hv_ColorsRainbow);
  make_neighboring_colors_distinguishable(hv_ColorsRainbow, &hv_Colors);
  hv_ColorGinko = ((const HTuple&)hv_Colors)[3];
  hv_ColorCapsularumI = ((const HTuple&)hv_Colors)[7];
  //Result boxes.
  GenRectangle1(&ho_BoxGinko, 30.1, 4.7, 66.2, 91.7);
  GenRectangle1(&ho_BoxCapsularumI, 56.0, 37.0, 119.8, 110.9);
  GenRectangle1(&ho_BoxGinko2, 30.1, 4.7+(hv_Width/2), 66.2, 91.7+(hv_Width/2));
  GenRectangle1(&ho_BoxCapsularumI2, 56.0, 37.0+(hv_Width/2), 119.8, 110.9+(hv_Width/2));
  //
  //Generate bad box
  GenRectangle1(&ho_BadBox, 40, 49, 92, 105);
  //
  //Draw result box.
  if (HDevWindowStack::IsOpen())
    DispObj(ho_TiledImage, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Line, HDevWindowStack::GetActive());
  hv_LineWidth = 2.0;
  SetWindowParam(hv_WindowHandleImages, "flush", "false");
  display_result_box(ho_BoxGinko, hv_LineWidth, hv_ColorGinko, "4 (1.00)");
  display_result_box(ho_BoxCapsularumI, hv_LineWidth, hv_ColorCapsularumI, "8 (0.97)");
  display_result_box(ho_BoxGinko2, hv_LineWidth, hv_ColorGinko, "4 (1.00)");
  display_result_box(ho_BoxCapsularumI2, hv_LineWidth, hv_ColorCapsularumI, "8 (0.97)");
  display_result_box(ho_BadBox, hv_LineWidth, hv_ColorGinko, "4 (0.55)");
  //
  //Add text for image parts
  GetWindowExtents(hv_WindowHandleImages, &hv_Row, &hv_Column, &hv_WindowWidth, &hv_WindowHeight);
  hv_Text = "min_confidence = 0.5 (default)";
  GetStringExtents(hv_WindowHandleImages, hv_Text, &hv__, &hv__, &hv_TextWidth, &hv_TextHeight);
  hv_TextCol = (hv_WindowWidth*0.25)-(hv_TextWidth*0.5);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_WindowHeight-(2*hv_TextHeight), 
        hv_TextCol, "black", HTuple(), HTuple());
  hv_Text = "min_confidence = 0.6";
  GetStringExtents(hv_WindowHandleImages, hv_Text, &hv__, &hv__, &hv_TextWidth, &hv_TextHeight);
  hv_TextCol = (hv_WindowWidth*0.75)-(hv_TextWidth*0.5);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_WindowHeight-(2*hv_TextHeight), 
        hv_TextCol, "black", HTuple(), HTuple());
  //
  //Display.
  if (HDevWindowStack::IsOpen())
    SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
  FlushBuffer(hv_WindowHandleImages);
  SetWindowParam(hv_WindowHandleImages, "flush", "true");
  //
  return;
}

void dev_display_screen_run_program (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
  HTuple  hv_Text;

  //This procedure shows a final text before running the program.
  //
  GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  //Reset the open windows for a clean display.
  SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
  SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
  dev_display_example_reset_windows(hv_ExampleInternals);
  //
  //Display explanatory text.
  GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
  HDevWindowStack::SetActive(hv_WindowHandleText);
  //
  hv_Text = "We will now apply the trained model from example part 2";
  hv_Text[hv_Text.TupleLength()] = "'detect_pills_deep_learning_2_train.hdev'";
  hv_Text[hv_Text.TupleLength()] = "to some new images using 'apply_dl_model'.";
  hv_Text[hv_Text.TupleLength()] = "";
  hv_Text[hv_Text.TupleLength()] = HTuple("In the consequent example application, it is checked");
  hv_Text[hv_Text.TupleLength()] = HTuple("if the bags have been filled up correctly, which means:");
  hv_Text[hv_Text.TupleLength()] = "- The bag contains all pill types.";
  hv_Text[hv_Text.TupleLength()] = "- There are no duplicates in the bag.";
  //
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black", 
        "box", "true");
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
        "bottom", "right", "black", HTuple(), HTuple());
  //
  return;
}

void dev_example_init (HTuple hv_ShowExampleScreens, HTuple hv_UsePretrainedModel, 
    HTuple *hv_ExampleInternals)
{

  //This procedure initializes the graphic windows that are used for explanations during the example.
  //
  //A dict that will be used/adapted by other example procedures.
  CreateDict(&(*hv_ExampleInternals));
  SetDictTuple((*hv_ExampleInternals), "show_example_screens", hv_ShowExampleScreens);
  SetDictTuple((*hv_ExampleInternals), "use_pretrained_model", hv_UsePretrainedModel);
  if (0 != (hv_ShowExampleScreens.TupleNot()))
  {
    return;
  }
  //
  if (HDevWindowStack::IsOpen())
    CloseWindow(HDevWindowStack::Pop());
  dev_open_example_text_window((*hv_ExampleInternals));
  //
  SetDictTuple((*hv_ExampleInternals), "window_images_needed", 0);
  SetDictTuple((*hv_ExampleInternals), "window_legend_needed", 0);
  //
  return;
}

void dev_open_example_image_window (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowHeightText, hv_WindowWidthImage;
  HTuple  hv_WindowHeightImages, hv_WindowBGColor, hv_WindowYImages;
  HTuple  hv_WindowXImages, hv_WindowHandleImages;

  //This procedure initializes the graphic windows that are used to display example images.
  //
  hv_WindowHeightText = 300;
  hv_WindowWidthImage = 800;
  hv_WindowHeightImages = 500;
  hv_WindowBGColor = "gray";
  //
  hv_WindowYImages = hv_WindowHeightText+60;
  hv_WindowXImages = 0;
  SetWindowAttr("background_color",hv_WindowBGColor);
  OpenWindow(hv_WindowYImages,hv_WindowXImages,hv_WindowWidthImage,hv_WindowHeightImages,0,"visible","",&hv_WindowHandleImages);
  HDevWindowStack::Push(hv_WindowHandleImages);
  set_display_font(hv_WindowHandleImages, 16, "mono", "true", "false");
  SetDictTuple(hv_ExampleInternals, "window_images", hv_WindowHandleImages);
  SetDictTuple(hv_ExampleInternals, "window_images_width", hv_WindowWidthImage);
  SetDictTuple(hv_ExampleInternals, "window_images_height", hv_WindowHeightImages);
  SetDictTuple(hv_ExampleInternals, "window_images_x", hv_WindowXImages);
  SetDictTuple(hv_ExampleInternals, "window_images_y", hv_WindowYImages);
  return;
}

void dev_open_example_legend_window (HTuple hv_ExampleInternals, HTuple hv_WindowWidth)
{

  // Local control variables
  HTuple  hv_WindowImagesHeight, hv_WindowImagesWidth;
  HTuple  hv_WindowImagesX, hv_WindowImagesY, hv_WindowHandleLegend;

  //This procedure initializes the graphic windows that are used to display a legend.
  //
  GetDictTuple(hv_ExampleInternals, "window_images_height", &hv_WindowImagesHeight);
  GetDictTuple(hv_ExampleInternals, "window_images_width", &hv_WindowImagesWidth);
  GetDictTuple(hv_ExampleInternals, "window_images_x", &hv_WindowImagesX);
  GetDictTuple(hv_ExampleInternals, "window_images_y", &hv_WindowImagesY);
  SetWindowAttr("background_color","black");
  OpenWindow(hv_WindowImagesY,(hv_WindowImagesX+hv_WindowImagesWidth)+5,hv_WindowWidth,hv_WindowImagesHeight,0,"visible","",&hv_WindowHandleLegend);
  HDevWindowStack::Push(hv_WindowHandleLegend);
  set_display_font(hv_WindowHandleLegend, 14, "mono", "true", "false");
  SetDictTuple(hv_ExampleInternals, "window_legend", hv_WindowHandleLegend);
  return;
}

void dev_open_example_text_window (HTuple hv_ExampleInternals)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_WindowWidthText, hv_WindowHeightText;
  HTuple  hv_WindowBGColor, hv_WindowHandleText;

  hv_WindowWidthText = 800;
  hv_WindowHeightText = 300;
  hv_WindowBGColor = "gray";
  SetWindowAttr("background_color",hv_WindowBGColor);
  OpenWindow(0,0,hv_WindowWidthText,hv_WindowHeightText,0,"visible","",&hv_WindowHandleText);
  HDevWindowStack::Push(hv_WindowHandleText);
  set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
  SetDictTuple(hv_ExampleInternals, "window_text", hv_WindowHandleText);
  SetDictTuple(hv_ExampleInternals, "window_text_width", hv_WindowWidthText);
  SetDictTuple(hv_ExampleInternals, "window_text_height", hv_WindowHeightText);
  return;
}

void display_result_box (HObject ho_Box, HTuple hv_LineWidth, HTuple hv_Colors, HTuple hv_Text)
{

  // Local control variables
  HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2;

  //This helper procedure displays result bounding boxes.
  //
  //Draw result box.
  if (HDevWindowStack::IsOpen())
    SetDraw(HDevWindowStack::GetActive(),"margin");
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),(hv_LineWidth+2).TupleInt());
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),"black");
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Box, HDevWindowStack::GetActive());
  if (HDevWindowStack::IsOpen())
    SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth.TupleInt());
  if (HDevWindowStack::IsOpen())
    SetColor(HDevWindowStack::GetActive(),hv_Colors);
  if (HDevWindowStack::IsOpen())
    DispObj(ho_Box, HDevWindowStack::GetActive());
  //Display text.
  SmallestRectangle1(ho_Box, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
  if (HDevWindowStack::IsOpen())
    DispText(HDevWindowStack::GetActive(),hv_Text, "image", hv_Row1, hv_Column1, 
        "white", ((HTuple("box_color").Append("shadow")).Append("border_radius")), 
        ((HTuple("black").Append("false")).Append(0)));
  return;
}

// Short Description: Generates NumColors distinct colors 
void get_distinct_colors (HTuple hv_NumColors, HTuple hv_Random, HTuple hv_StartColor, 
    HTuple hv_EndColor, HTuple *hv_Colors)
{

  // Local iconic variables
  HObject  ho_HLSImageH, ho_HLSImageL, ho_HLSImageS;
  HObject  ho_ImageR, ho_ImageG, ho_ImageB;

  // Local control variables
  HTuple  hv_IsString, hv_Hue, hv_Lightness, hv_Saturation;
  HTuple  hv_Rows, hv_Columns, hv_Red, hv_Green, hv_Blue;

  //
  //We get distinct color-values first in HLS color-space.
  //Assumes hue [0, EndColor), lightness [0, 1), saturation [0, 1).
  //
  //Parameter checks.
  //NumColors.
  if (0 != (int(hv_NumColors<1)))
  {
    throw HException("NumColors should be at least 1");
  }
  if (0 != ((hv_NumColors.TupleIsInt()).TupleNot()))
  {
    throw HException("NumColors should be of type int");
  }
  if (0 != (int((hv_NumColors.TupleLength())!=1)))
  {
    throw HException("NumColors should have length 1");
  }
  //Random.
  if (0 != (HTuple(int(hv_Random!=0)).TupleAnd(int(hv_Random!=1))))
  {
    TupleIsString(hv_Random, &hv_IsString);
    if (0 != hv_IsString)
    {
      hv_Random = HTuple(int(hv_Random==HTuple("true"))).TupleOr("false");
    }
    else
    {
      throw HException("Random should be either true or false");
    }
  }
  //StartColor.
  if (0 != (int((hv_StartColor.TupleLength())!=1)))
  {
    throw HException("StartColor should have length 1");
  }
  if (0 != (HTuple(int(hv_StartColor<0)).TupleOr(int(hv_StartColor>255))))
  {
    throw HException(HTuple("StartColor should be in the range [0, 255]"));
  }
  if (0 != ((hv_StartColor.TupleIsInt()).TupleNot()))
  {
    throw HException("StartColor should be of type int");
  }
  //EndColor.
  if (0 != (int((hv_EndColor.TupleLength())!=1)))
  {
    throw HException("EndColor should have length 1");
  }
  if (0 != (HTuple(int(hv_EndColor<0)).TupleOr(int(hv_EndColor>255))))
  {
    throw HException(HTuple("EndColor should be in the range [0, 255]"));
  }
  if (0 != ((hv_EndColor.TupleIsInt()).TupleNot()))
  {
    throw HException("EndColor should be of type int");
  }
  //
  //Color generation.
  if (0 != (int(hv_StartColor>hv_EndColor)))
  {
    hv_EndColor += 255;
  }
  if (0 != (int(hv_NumColors!=1)))
  {
    hv_Hue = (hv_StartColor+((((hv_EndColor-hv_StartColor)*(HTuple::TupleGenSequence(0,hv_NumColors-1,1).TupleReal()))/((hv_NumColors-1).TupleReal())).TupleInt()))%255;
  }
  else
  {
    hv_Hue = (hv_StartColor.TupleConcat(hv_EndColor)).TupleMean();
  }
  if (0 != hv_Random)
  {
    hv_Hue = ((const HTuple&)hv_Hue)[HTuple::TupleRand(hv_NumColors).TupleSortIndex()];
    hv_Lightness = (((5.0+HTuple::TupleRand(hv_NumColors))*255.0)/10.0).TupleInt();
    hv_Saturation = (((9.0+HTuple::TupleRand(hv_NumColors))*255.0)/10.0).TupleInt();
  }
  else
  {
    hv_Lightness = (HTuple(hv_NumColors,0.55)*255.0).TupleInt();
    hv_Saturation = (HTuple(hv_NumColors,0.95)*255.0).TupleInt();
  }
  //
  //Write colors to a 3-channel image in order to transform easier.
  GenImageConst(&ho_HLSImageH, "byte", 1, hv_NumColors);
  GenImageConst(&ho_HLSImageL, "byte", 1, hv_NumColors);
  GenImageConst(&ho_HLSImageS, "byte", 1, hv_NumColors);
  GetRegionPoints(ho_HLSImageH, &hv_Rows, &hv_Columns);
  SetGrayval(ho_HLSImageH, hv_Rows, hv_Columns, hv_Hue);
  SetGrayval(ho_HLSImageL, hv_Rows, hv_Columns, hv_Lightness);
  SetGrayval(ho_HLSImageS, hv_Rows, hv_Columns, hv_Saturation);
  //
  //Convert from HLS to RGB.
  TransToRgb(ho_HLSImageH, ho_HLSImageL, ho_HLSImageS, &ho_ImageR, &ho_ImageG, &ho_ImageB, 
      "hls");
  //
  //Get RGB-values and transform to Hex.
  GetGrayval(ho_ImageR, hv_Rows, hv_Columns, &hv_Red);
  GetGrayval(ho_ImageG, hv_Rows, hv_Columns, &hv_Green);
  GetGrayval(ho_ImageB, hv_Rows, hv_Columns, &hv_Blue);
  (*hv_Colors) = (("#"+(hv_Red.TupleString("02x")))+(hv_Green.TupleString("02x")))+(hv_Blue.TupleString("02x"));
  return;

}

void get_example_inference_images (HTuple hv_ImageDir, HTuple *hv_ImageFiles)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumSamples, hv_ImageFilesIndices, hv_Index;

  //This procedure creates a list of images used for this example.
  //
  hv_NumSamples = 10;
  TupleGenConst(hv_NumSamples, "", &(*hv_ImageFiles));
  //
  //bags containing all pills.
  hv_ImageFilesIndices.Clear();
  hv_ImageFilesIndices[0] = 152;
  hv_ImageFilesIndices[1] = 41;
  hv_ImageFilesIndices[2] = 164;
  hv_ImageFilesIndices[3] = 49;
  //bags containing only duplicates.
  hv_ImageFilesIndices = hv_ImageFilesIndices.TupleConcat((HTuple(121).Append(59)));
  //bags containing only missing pills.
  hv_ImageFilesIndices = hv_ImageFilesIndices.TupleConcat((HTuple(178).Append(18)));
  //bags containing both, duplicates and missing pills
  hv_ImageFilesIndices = hv_ImageFilesIndices.TupleConcat((HTuple(146).Append(294)));
  //
  {
  HTuple end_val14 = hv_NumSamples-1;
  HTuple step_val14 = 1;
  for (hv_Index=0; hv_Index.Continue(end_val14, step_val14); hv_Index += step_val14)
  {
    (*hv_ImageFiles)[hv_Index] = ((hv_ImageDir+"/pill_bag_")+(HTuple(hv_ImageFilesIndices[hv_Index]).TupleString("03")))+".png";
  }
  }
  //
  tuple_shuffle((*hv_ImageFiles), &(*hv_ImageFiles));
  //
  return;
}

// Short Description: shuffles the input colors in a deterministic way 
void make_neighboring_colors_distinguishable (HTuple hv_ColorsRainbow, HTuple *hv_Colors)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_NumColors, hv_NumChunks, hv_NumLeftOver;
  HTuple  hv_ColorsPerChunk, hv_StartIdx, hv_S, hv_EndIdx;
  HTuple  hv_IdxsLeft, hv_IdxsRight;

  //Shuffle the input colors in a deterministic way
  //to make adjacent colors more distinguishable.
  //Neighboring colors from the input are distributed to every NumChunks
  //position in the output.
  //Depending on the number of colors, increase NumChunks.
  hv_NumColors = hv_ColorsRainbow.TupleLength();
  if (0 != (int(hv_NumColors>=8)))
  {
    hv_NumChunks = 3;
    if (0 != (int(hv_NumColors>=40)))
    {
      hv_NumChunks = 6;
    }
    else if (0 != (int(hv_NumColors>=20)))
    {
      hv_NumChunks = 4;
    }
    (*hv_Colors) = HTuple(hv_NumColors,-1);
    //Check if the Number of Colors is dividable by NumChunks.
    hv_NumLeftOver = hv_NumColors%hv_NumChunks;
    hv_ColorsPerChunk = (hv_NumColors/hv_NumChunks).TupleInt();
    hv_StartIdx = 0;
    {
    HTuple end_val18 = hv_NumChunks-1;
    HTuple step_val18 = 1;
    for (hv_S=0; hv_S.Continue(end_val18, step_val18); hv_S += step_val18)
    {
      hv_EndIdx = (hv_StartIdx+hv_ColorsPerChunk)-1;
      if (0 != (int(hv_S<hv_NumLeftOver)))
      {
        hv_EndIdx += 1;
      }
      hv_IdxsLeft = HTuple::TupleGenSequence(hv_S,hv_NumColors-1,hv_NumChunks);
      hv_IdxsRight = HTuple::TupleGenSequence(hv_StartIdx,hv_EndIdx,1);
      (*hv_Colors)[HTuple::TupleGenSequence(hv_S,hv_NumColors-1,hv_NumChunks)] = hv_ColorsRainbow.TupleSelectRange(hv_StartIdx,hv_EndIdx);
      hv_StartIdx = hv_EndIdx+1;
    }
    }
  }
  else
  {
    (*hv_Colors) = hv_ColorsRainbow;
  }
  return;
}

#ifndef NO_EXPORT_MAIN
// Main procedure 
void action()
{

  // Local iconic variables
  HObject  ho_ImageBatch;

  // Local control variables
  HTuple  hv_ShowExampleScreens, hv_UsePretrainedModel;
  HTuple  hv_DLDeviceHandles, hv_DLDevice, hv_ExampleInternals;
  HTuple  hv_ExampleDir, hv_ImageDir, hv_ExampleDataDir, hv_PreprocessParamFileName;
  HTuple  hv_RetrainedModelFileName, hv_DataDirectory, hv_ClassNames;
  HTuple  hv_ClassIDs, hv_BatchSizeInference, hv_MinConfidence;
  HTuple  hv_MaxOverlap, hv_MaxOverlapClassAgnostic, hv_DLModelHandle;
  HTuple  hv_DLPreprocessParam, hv_WindowHandleDict, hv_DLDataInfo;
  HTuple  hv_GenParam, hv_ImageFiles, hv_BatchIndex, hv_Batch;
  HTuple  hv_DLSampleBatch, hv_DLResultBatch, hv_SampleIndex;
  HTuple  hv_DLSample, hv_DLResult, hv_DetectedClassIDs, hv_NumberDetectionsPerClass;
  HTuple  hv_Index, hv_Text, hv_TextColor, hv_TextBoxColor;
  HTuple  hv_WindowHandles;

  //
  //This example is part of a series of examples, which summarizes
  //the workflow for DL object detection. It uses the MVTec pill bag dataset.
  //
  //The four parts are:
  //1. Creation of the model and dataset preprocessing.
  //2. Training of the model.
  //3. Evaluation of the trained model.
  //4. Inference on new images.
  //
  //This examples covers part 4: 'Inference on new images'
  //
  //It explains how to apply a trained model on new images and shows
  //an application based on the pill bag dataset.
  //
  //Please note: This script uses a pretrained model. To use the output
  //of part 1 and part 2 of this example series, set UsePretrainedModel
  //to false below.
  //
  dev_update_off();
  //
  //In this example, the inference steps are explained in graphics windows,
  //before they are executed. Set the following parameter to false in order to
  //skip this visualization.
  hv_ShowExampleScreens = 1;
  //
  //By default, this example uses a model pretrained by MVTec. To use the model
  //which was trained in part 2 of this example series, set the following
  //variable to false.
  hv_UsePretrainedModel = 1;
  //
  //Inference can be done on a GPU or CPU.
  //See the respective system requirements in the Installation Guide.
  //If possible a GPU is used in this example.
  //In case you explicitely wish to run this example on the CPU,
  //choose the CPU device instead.
  QueryAvailableDlDevices((HTuple("runtime").Append("runtime")), (HTuple("gpu").Append("cpu")), 
      &hv_DLDeviceHandles);
  if (0 != (int((hv_DLDeviceHandles.TupleLength())==0)))
  {
    throw HException("No supported device found to continue this example.");
  }
  //Due to the filter used in query_available_dl_devices, the first device is a GPU, if available.
  hv_DLDevice = ((const HTuple&)hv_DLDeviceHandles)[0];
  //
  if (0 != hv_ShowExampleScreens)
  {
    //
    //Initial example windows and parameters etc.
    dev_example_init(hv_ShowExampleScreens, hv_UsePretrainedModel, &hv_ExampleInternals);
    //
    //Introduction text of example series.
    dev_display_screen_introduction(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Show example image.
    dev_display_screen_example_images(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Explain inference steps.
    dev_display_screen_inference_step_1(hv_ExampleInternals);
    // stop(...); only in hdevelop
    dev_display_screen_inference_step_2_part_1(hv_ExampleInternals);
    // stop(...); only in hdevelop
    dev_display_screen_inference_step_2_part_2(hv_ExampleInternals);
    // stop(...); only in hdevelop
    dev_display_screen_inference_step_3(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Explain parameter 'min_confidence'.
    dev_display_screen_min_confidence(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Explain parameter 'max_overlap'.
    dev_display_screen_max_overlap(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Explain parameter 'max_overlap_class_agnostic'.
    dev_display_screen_max_overlap_class_agnostic(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Mention on which device the deep learning operators will run.
    dev_display_screen_device(hv_ExampleInternals, hv_DLDevice);
    // stop(...); only in hdevelop
    //
    //Run the program showing inference by means of an application.
    dev_display_screen_run_program(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //
    //Terminate example screens.
    dev_close_example_windows(hv_ExampleInternals);
  }

  //*************************************************
  //**   Set paths and parameters for inference   ***
  //*************************************************
  //
  //We will demonstrate the inference on the example images.
  //In a real application newly incoming images (not used for training or evaluation)
  //would be used here.
  //
  //In this example, we read the images from file.
  //Directory name with the images of the pill bag dataset.
  GetSystem("example_dir", &hv_ExampleDir);
  hv_ImageDir = hv_ExampleDir+"/images/pill_bag";
  //
  //Set the paths of the retrained model and the corresponding preprocessing parameters.
  //Example data folder containing the outputs of the previous example series.
  hv_ExampleDataDir = "detect_pills_data";
  if (0 != hv_UsePretrainedModel)
  {
    //Use the pretrained model and preprocessing parameters shipping with HALCON.
    hv_PreprocessParamFileName = "detect_pills_preprocess_param.hdict";
    hv_RetrainedModelFileName = "detect_pills.hdl";
  }
  else
  {
    //File name of the dict containing parameters used for preprocessing.
    //Note: Adapt DataDirectory after preprocessing with another image size.
    hv_DataDirectory = hv_ExampleDataDir+"/dldataset_pill_bag_512x320";
    hv_PreprocessParamFileName = hv_DataDirectory+"/dl_preprocess_param.hdict";
    //File name of the finetuned object detection model.
    hv_RetrainedModelFileName = hv_ExampleDataDir+"/best_dl_model_detection.hdl";
  }
  //
  //Provide the class names and IDs.
  //Class names.
  hv_ClassNames.Clear();
  hv_ClassNames[0] = "Omega-3";
  hv_ClassNames[1] = "KMW";
  hv_ClassNames[2] = "Stomach tablet";
  hv_ClassNames[3] = "Ginko";
  hv_ClassNames[4] = "Ginseng";
  hv_ClassNames[5] = "Glucosamine";
  hv_ClassNames[6] = "Cognivia";
  hv_ClassNames[7] = "Capsularum I";
  hv_ClassNames[8] = "Iron tablet";
  hv_ClassNames[9] = "Vitamin-B";
  //Respective class ids.
  hv_ClassIDs.Clear();
  hv_ClassIDs[0] = 1;
  hv_ClassIDs[1] = 2;
  hv_ClassIDs[2] = 3;
  hv_ClassIDs[3] = 4;
  hv_ClassIDs[4] = 5;
  hv_ClassIDs[5] = 6;
  hv_ClassIDs[6] = 7;
  hv_ClassIDs[7] = 8;
  hv_ClassIDs[8] = 9;
  hv_ClassIDs[9] = 10;
  //
  //Batch Size used during inference.
  hv_BatchSizeInference = 1;
  //
  //Postprocessing parameters for the detection model.
  hv_MinConfidence = 0.6;
  hv_MaxOverlap = 0.2;
  hv_MaxOverlapClassAgnostic = 0.7;
  //
  //********************
  //**   Inference   ***
  //********************
  //
  //Check if all necessary files exist.
  check_data_availability(hv_ExampleDataDir, hv_PreprocessParamFileName, hv_RetrainedModelFileName, 
      hv_UsePretrainedModel);
  //
  //Read in the retrained model.
  ReadDlModel(hv_RetrainedModelFileName, &hv_DLModelHandle);
  //
  //Set the batch size.
  SetDlModelParam(hv_DLModelHandle, "batch_size", hv_BatchSizeInference);
  //
  //Initialize the model for inference.
  SetDlModelParam(hv_DLModelHandle, "device", hv_DLDevice);
  //
  //Set postprocessing parameters for model.
  SetDlModelParam(hv_DLModelHandle, "min_confidence", hv_MinConfidence);
  SetDlModelParam(hv_DLModelHandle, "max_overlap", hv_MaxOverlap);
  SetDlModelParam(hv_DLModelHandle, "max_overlap_class_agnostic", hv_MaxOverlapClassAgnostic);
  //
  //Get the parameters used for preprocessing.
  ReadDict(hv_PreprocessParamFileName, HTuple(), HTuple(), &hv_DLPreprocessParam);
  //
  //Create window dictionary for displaying results.
  CreateDict(&hv_WindowHandleDict);
  //Create dictionary with dataset parameters necessary for displaying.
  CreateDict(&hv_DLDataInfo);
  SetDictTuple(hv_DLDataInfo, "class_names", hv_ClassNames);
  SetDictTuple(hv_DLDataInfo, "class_ids", hv_ClassIDs);
  //Set generic parameters for visualization.
  CreateDict(&hv_GenParam);
  SetDictTuple(hv_GenParam, "scale_windows", 1.2);
  //
  //List the files, the model should be applied to (e.g. using list_image_files).
  //For this example, we select some images manually.
  get_example_inference_images(hv_ImageDir, &hv_ImageFiles);
  //
  //Loop over all images in batches of size BatchSizeInference for inference.
  {
  HTuple end_val172 = (((hv_ImageFiles.TupleLength())/(hv_BatchSizeInference.TupleReal())).TupleFloor())-1;
  HTuple step_val172 = 1;
  for (hv_BatchIndex=0; hv_BatchIndex.Continue(end_val172, step_val172); hv_BatchIndex += step_val172)
  {
    //
    //Get the paths to the images of the batch.
    hv_Batch = hv_ImageFiles.TupleSelectRange(hv_BatchIndex*hv_BatchSizeInference,((hv_BatchIndex+1)*hv_BatchSizeInference)-1);
    //Read the images of the batch.
    ReadImage(&ho_ImageBatch, hv_Batch);
    //
    //Generate the DLSampleBatch.
    gen_dl_samples_from_images(ho_ImageBatch, &hv_DLSampleBatch);
    //
    //Preprocess the DLSampleBatch.
    preprocess_dl_samples(hv_DLSampleBatch, hv_DLPreprocessParam);
    //
    //Apply the DL model on the DLSampleBatch.
    ApplyDlModel(hv_DLModelHandle, hv_DLSampleBatch, HTuple(), &hv_DLResultBatch);
    //
    //Postprocessing and visualization.
    //Loop over each sample in the batch.
    {
    HTuple end_val190 = hv_BatchSizeInference-1;
    HTuple step_val190 = 1;
    for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val190, step_val190); hv_SampleIndex += step_val190)
    {
      //
      //Get sample and according results.
      hv_DLSample = HTuple(hv_DLSampleBatch[hv_SampleIndex]);
      hv_DLResult = HTuple(hv_DLResultBatch[hv_SampleIndex]);
      //
      //Count detected pills for each class.
      GetDictTuple(hv_DLResult, "bbox_class_id", &hv_DetectedClassIDs);
      TupleGenConst(hv_ClassIDs.TupleLength(), 0, &hv_NumberDetectionsPerClass);
      {
      HTuple end_val199 = (hv_ClassIDs.TupleLength())-1;
      HTuple step_val199 = 1;
      for (hv_Index=0; hv_Index.Continue(end_val199, step_val199); hv_Index += step_val199)
      {
        hv_NumberDetectionsPerClass[hv_Index] = (hv_DetectedClassIDs.TupleEqualElem(HTuple(hv_ClassIDs[hv_Index]))).TupleSum();
      }
      }
      //
      //Create output text based on counted pills.
      create_counting_result_text(hv_NumberDetectionsPerClass, hv_ClassNames, &hv_Text, 
          &hv_TextColor, &hv_TextBoxColor);
      //
      //Display results and text.
      dev_display_dl_data(hv_DLSample, hv_DLResult, hv_DLDataInfo, "bbox_result", 
          hv_GenParam, hv_WindowHandleDict);
      GetDictTuple(hv_WindowHandleDict, "bbox_result", &hv_WindowHandles);
      HDevWindowStack::SetActive(HTuple(hv_WindowHandles[0]));
      set_display_font(HTuple(hv_WindowHandles[0]), 16, "mono", "true", "false");
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", hv_TextColor, 
            (HTuple("box_color").Append("shadow")), hv_TextBoxColor.TupleConcat("false"));
      if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window", 
            "bottom", "right", "black", HTuple(), HTuple());
      // stop(...); only in hdevelop
    }
    }
  }
  }
  //
  //Close windows used for visualization.
  dev_close_window_dict(hv_WindowHandleDict);
  //
  //
  if (0 != hv_ShowExampleScreens)
  {
    //Final explanations.
    dev_display_screen_final(hv_ExampleInternals);
    // stop(...); only in hdevelop
    //Close example windows.
    dev_close_example_windows(hv_ExampleInternals);
  }
}


#ifndef NO_EXPORT_APP_MAIN

#ifdef __APPLE__
// On OS X systems, we must have a CFRunLoop running on the main thread in
// order for the HALCON graphics operators to work correctly, and run the
// action function in a separate thread. A CFRunLoopTimer is used to make sure
// the action function is not called before the CFRunLoop is running.
// Note that starting with macOS 10.12, the run loop may be stopped when a
// window is closed, so we need to put the call to CFRunLoopRun() into a loop
// of its own.
static HMutex*     sStartMutex;
static H_pthread_t sActionThread;
static bool        sTerminate = false;

static void timer_callback(CFRunLoopTimerRef timer, void *info)
{
  sStartMutex->UnlockMutex();
}

static Herror apple_action(void **parameters)
{
  // Wait until the timer has fired to start processing.
  sStartMutex->LockMutex();
  sStartMutex->UnlockMutex();

  try
  {
    action();
  }
  catch (HException &exception)
  {
    fprintf(stderr,"  Error #%u in %s: %s\n", exception.ErrorCode(),
            exception.ProcName().TextA(),
            exception.ErrorMessage().TextA());
  }

  // Tell the main thread to terminate itself.
  sStartMutex->LockMutex();
  sTerminate = true;
  sStartMutex->UnlockMutex();
  CFRunLoopStop(CFRunLoopGetMain());
  return H_MSG_OK;
}

static int apple_main(int argc, char *argv[])
{
  Herror                error;
  CFRunLoopTimerRef     Timer;
  CFRunLoopTimerContext TimerContext = { 0, 0, 0, 0, 0 };

  sStartMutex = new HMutex("type","sleep");
  sStartMutex->LockMutex();

  error = HpThreadHandleAlloc(&sActionThread);
  if (H_MSG_OK != error)
  {
    fprintf(stderr,"HpThreadHandleAlloc failed: %d\n", error);
    exit(1);
  }

  error = HpThreadCreate(sActionThread,0,apple_action);
  if (H_MSG_OK != error)
  {
    fprintf(stderr,"HpThreadCreate failed: %d\n", error);
    exit(1);
  }

  Timer = CFRunLoopTimerCreate(kCFAllocatorDefault,
                               CFAbsoluteTimeGetCurrent(),0,0,0,
                               timer_callback,&TimerContext);
  if (!Timer)
  {
    fprintf(stderr,"CFRunLoopTimerCreate failed\n");
    exit(1);
  }
  CFRunLoopAddTimer(CFRunLoopGetCurrent(),Timer,kCFRunLoopCommonModes);

  for (;;)
  {
    bool terminate;

    CFRunLoopRun();

    sStartMutex->LockMutex();
    terminate = sTerminate;
    sStartMutex->UnlockMutex();

    if (terminate)
      break;
  }

  CFRunLoopRemoveTimer(CFRunLoopGetCurrent(),Timer,kCFRunLoopCommonModes);
  CFRelease(Timer);

  error = HpThreadHandleFree(sActionThread);
  if (H_MSG_OK != error)
  {
    fprintf(stderr,"HpThreadHandleFree failed: %d\n", error);
    exit(1);
  }

  delete sStartMutex;
  return 0;
}
#endif

int main(int argc, char *argv[])
{
  int ret = 0;

  try
  {
#if defined(_WIN32)
    SetSystem("use_window_thread", "true");
#endif

    // file was stored with local-8-bit encoding
    //   -> set the interface encoding accordingly
    SetHcppInterfaceStringEncodingIsUtf8(false);

    // Default settings used in HDevelop (can be omitted)
    SetSystem("width", 512);
    SetSystem("height", 512);

#ifndef __APPLE__
    action();
#else
    ret = apple_main(argc,argv);
#endif
  }
  catch (HException &exception)
  {
    fprintf(stderr,"  Error #%u in %s: %s\n", exception.ErrorCode(),
            exception.ProcName().TextA(),
            exception.ErrorMessage().TextA());
    ret = 1;
  }
  return ret;
}

#endif


#endif


